{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56dbad60-8ceb-4f2f-a570-7fffead564bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T13:46:04.114081+0000][31803][CRITICAL] load failed: \n",
      "GReaT is not installed. Please install it with pip install GReaT.\n",
      "Please be aware that GReaT is only available for python >= 3.9.\n",
      "\n",
      "[2023-12-17T13:46:04.115400+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T13:46:04.116063+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T13:46:04.123670+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['marginal_distributions',\n",
       " 'ctgan',\n",
       " 'dummy_sampler',\n",
       " 'uniform_sampler',\n",
       " 'ddpm',\n",
       " 'rtvae',\n",
       " 'bayesian_network',\n",
       " 'tvae',\n",
       " 'nflow',\n",
       " 'arf']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "from synthcity.metrics.eval_performance import (\n",
    "    PerformanceEvaluatorMLP,\n",
    "    PerformanceEvaluatorXGB,\n",
    ")\n",
    "from synthcity.utils import reproducibility\n",
    "from synthcity.plugins import Plugins\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
    "from DGE_utils import metric_different_datasets, mean_across_pandas, add_std, get_folder_names\n",
    "\n",
    "reproducibility.clear_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "assert device.type == 'cuda'\n",
    "Plugins(categories=[\"generic\"]).list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3c5842-a8da-474d-8185-0f67fbe6f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up params for boosting experiment\n",
    "from DGE_data import get_real_and_synthetic, get_real_and_synthetic_with_multiple_models\n",
    "\n",
    "# let's restrict ourselves to classification datasets\n",
    "datasets = ['moons', 'circles', 'breast_cancer',\n",
    "            'adult', 'covid']\n",
    "# ['moons', 'circles','cal_housing', 'adult', 'diabetes', 'breast_cancer',  'seer', 'cutract' ]\n",
    "model_name = 'ctgan'  # synthetic data model\n",
    "# model_names = ['tvae', 'nflow', 'ctgan', 'adsgan']\n",
    "# model_name = model_names[0]\n",
    "# for m in model_names[1:]:\n",
    "#     model_name += \"_\" + m\n",
    "\n",
    "n_models = 20  # number of models in ensemble, for each run. 20\n",
    "max_n = 2000  # maximum number of data points to use for training generative model.\n",
    "nsyn = 2000  # number of synthetic data points per synthetic dataset. Defaults to same as generative training size if None\n",
    "\n",
    "num_runs = 3 # Number of runs. Don't choose to large, since total number of synthetic datasets is num_runs*n_models. 10\n",
    "\n",
    "# Per section 4.1, 10 runs with different seeds\n",
    "\n",
    "# Whether to load and save models and synthetic datasets\n",
    "load = True  # results\n",
    "load_syn = True  # data\n",
    "save = True  # save results and data\n",
    "\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2053090-09fb-4d24-9816-9543e08ce640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model to run:  ctgan\n",
      "Downstream classifier model type:  deepish_mlp\n",
      "boosting method:  SAMME\n",
      "n_models:  20\n",
      "num_runs:  3\n",
      "datasets:  ['covid', 'breast_cancer']\n",
      "model string:  ctgan\n",
      "verbose:  True\n",
      "Dataset covid\n",
      "\n",
      "workspace_folder:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe\n",
      "results_folder:  results/covid_ctgan_nmax_2000_nsyn_2000_SAMME_observe\n",
      "Boosting DGE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T13:57:22.594172+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T13:57:22.595050+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T13:57:22.595844+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T13:57:22.596629+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.unique(y):  [1 2]\n",
      "n_train: 2000, nsyn: 2000\n",
      "targettype:  classification\n",
      "Run 1 / 3\n",
      "Boosting iter: 1 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 1/20\n",
      "random state: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T13:57:23.613962+0000][31803][CRITICAL] load failed: libcudart.so.12: cannot open shared object file: No such file or directory\n",
      "[2023-12-17T13:57:23.615347+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T13:57:23.616018+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  None\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████████████████████████████████████████████▎                                                                          | 1049/2000 [07:20<06:39,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_0__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T14:05:26.338720+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T14:05:26.340860+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T14:05:26.342632+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T14:05:26.344732+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T14:05:26.348534+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T14:05:26.350308+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T14:05:26.352015+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 0 accuracy:  0.9255\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049991 0.00049991 0.00049991 ... 0.00049991 0.00049991 0.00049991]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0025195350066280387\n",
      "Boosting iter: 2 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 2/20\n",
      "random state: 1\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049991 0.00049991 0.00049991 ... 0.00049991 0.00049991 0.00049991]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([870, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████████████████▉                                                                               | 999/2000 [08:27<08:28,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_1__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T14:14:04.784548+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T14:14:04.786657+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T14:14:04.788357+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T14:14:04.790411+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T14:14:04.794140+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T14:14:04.795898+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T14:14:04.797580+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 1 accuracy:  0.9055\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.0004998  0.0004998  0.0004998  ... 0.0004998  0.00050093 0.0004998 ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0022588721318872462\n",
      "Boosting iter: 3 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 3/20\n",
      "random state: 2\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.0004998  0.0004998  0.0004998  ... 0.0004998  0.00050093 0.0004998 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([870, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████████████████████████████████                                                                                           | 849/2000 [07:05<09:36,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_2__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T14:21:19.432461+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T14:21:19.434597+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T14:21:19.436266+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T14:21:19.438356+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T14:21:19.442062+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T14:21:19.443790+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T14:21:19.445466+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 2 accuracy:  0.9165\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.0004997  0.0004997  0.0004997  ... 0.0004997  0.00050203 0.0004997 ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0023933504489159862\n",
      "Boosting iter: 4 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 4/20\n",
      "random state: 3\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.0004997  0.0004997  0.0004997  ... 0.0004997  0.00050203 0.0004997 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([867, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████████████████████████▎                                                                                                                  | 549/2000 [04:36<12:11,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_3__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T14:26:06.062797+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T14:26:06.064821+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T14:26:06.066481+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T14:26:06.068470+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T14:26:06.072115+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T14:26:06.073799+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T14:26:06.075457+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 3 accuracy:  0.9225\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.0004996  0.0004996  0.0004996  ... 0.0004996  0.00050318 0.0004996 ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024733278801342723\n",
      "Boosting iter: 5 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 5/20\n",
      "random state: 4\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.0004996  0.0004996  0.0004996  ... 0.0004996  0.00050318 0.0004996 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([870, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████████████████████████████████████████████▎                                                                          | 1049/2000 [08:48<07:59,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_4__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T14:35:05.261315+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T14:35:05.262999+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T14:35:05.264269+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T14:35:05.265952+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T14:35:05.268823+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T14:35:05.270180+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T14:35:05.271508+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 4 accuracy:  0.916\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.0004995  0.0004995  0.0004995  ... 0.00050069 0.00050428 0.0004995 ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002385034962729386\n",
      "Boosting iter: 6 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 6/20\n",
      "random state: 5\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.0004995  0.0004995  0.0004995  ... 0.00050069 0.00050428 0.0004995 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([872, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████████████████████████████▏                                                                                                      | 699/2000 [05:44<10:41,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_5__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T14:40:59.208964+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T14:40:59.211093+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T14:40:59.212782+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T14:40:59.214830+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T14:40:59.218540+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T14:40:59.220261+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T14:40:59.221964+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 5 accuracy:  0.923\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049941 0.00049941 0.00049941 ... 0.00050184 0.00050543 0.00049941]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002478113559873431\n",
      "Boosting iter: 7 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 7/20\n",
      "random state: 6\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049941 0.00049941 0.00049941 ... 0.00050184 0.00050543 0.00049941]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([868, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                   | 1349/2000 [11:15<05:26,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_6__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T14:52:24.548480+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T14:52:24.550609+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T14:52:24.552324+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T14:52:24.554419+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T14:52:24.558198+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T14:52:24.559928+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T14:52:24.561631+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 6 accuracy:  0.921\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049931 0.00049931 0.00049931 ... 0.00050174 0.00050533 0.00049931]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024490686230714685\n",
      "Boosting iter: 8 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 8/20\n",
      "random state: 7\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049931 0.00049931 0.00049931 ... 0.00050174 0.00050533 0.00049931]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([869, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 1549/2000 [12:56<03:46,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_7__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T15:05:30.846941+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:05:30.849069+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:05:30.850787+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T15:05:30.852830+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T15:05:30.856632+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:05:30.858401+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:05:30.860108+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 7 accuracy:  0.9185\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049921 0.00049921 0.00049921 ... 0.00050164 0.00050523 0.00049921]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024148440961876\n",
      "Boosting iter: 9 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 9/20\n",
      "random state: 8\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049921 0.00049921 0.00049921 ... 0.00050164 0.00050523 0.00049921]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([871, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████████████████████████████████████████████▎                                                                          | 1049/2000 [08:47<07:58,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_8__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T15:14:27.830946+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:14:27.832971+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:14:27.834656+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T15:14:27.836656+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T15:14:27.840349+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:14:27.842074+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:14:27.843726+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 8 accuracy:  0.9165\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049911 0.00049911 0.00049911 ... 0.00050154 0.00050513 0.00049911]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0023871738436906727\n",
      "Boosting iter: 10 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 10/20\n",
      "random state: 9\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049911 0.00049911 0.00049911 ... 0.00050154 0.00050513 0.00049911]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([869, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████████████████████████████████████████████▎                                                                          | 1049/2000 [08:41<07:53,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_9__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T15:23:19.215081+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:23:19.217140+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:23:19.218840+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T15:23:19.220878+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T15:23:19.224615+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:23:19.226367+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:23:19.228024+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 9 accuracy:  0.901\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.000499   0.000499   0.000499   ... 0.00050254 0.00050613 0.000499  ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.00219956937402228\n",
      "Boosting iter: 11 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 11/20\n",
      "random state: 10\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.000499   0.000499   0.000499   ... 0.00050254 0.00050613 0.000499  ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([867, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████████████████████████████▏                                                                                                      | 699/2000 [05:47<10:46,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_10__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T15:29:15.896667+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:29:15.898784+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:29:15.900455+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T15:29:15.902537+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T15:29:15.906279+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:29:15.908001+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:29:15.909693+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 10 accuracy:  0.917\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.0004989  0.0004989  0.0004989  ... 0.00050364 0.00050603 0.0004989 ]\n",
      "are all weights equal?:  27\n",
      "estimator weight:  0.0023916015074647717\n",
      "Boosting iter: 12 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 12/20\n",
      "random state: 11\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.0004989  0.0004989  0.0004989  ... 0.00050364 0.00050603 0.0004989 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([872, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████████████████▎                                                                                                              | 599/2000 [04:55<11:31,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_11__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T15:34:20.926176+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:34:20.928255+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:34:20.929942+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T15:34:20.931978+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T15:34:20.935661+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:34:20.937381+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:34:20.939084+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 11 accuracy:  0.9295\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049881 0.00049881 0.00049881 ... 0.00050355 0.00050594 0.00049881]\n",
      "are all weights equal?:  80\n",
      "estimator weight:  0.002566220137456705\n",
      "Boosting iter: 13 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 13/20\n",
      "random state: 12\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049881 0.00049881 0.00049881 ... 0.00050355 0.00050594 0.00049881]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([871, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████████████████████████████▏                                                                                                      | 699/2000 [05:49<10:50,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_12__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T15:40:19.805928+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:40:19.808009+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:40:19.809708+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T15:40:19.811750+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T15:40:19.815433+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:40:19.817153+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:40:19.818847+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 12 accuracy:  0.9255\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049871 0.00049871 0.00049871 ... 0.00050345 0.00050584 0.00049871]\n",
      "are all weights equal?:  4\n",
      "estimator weight:  0.0025054727196763458\n",
      "Boosting iter: 14 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 14/20\n",
      "random state: 13\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049871 0.00049871 0.00049871 ... 0.00050345 0.00050584 0.00049871]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([866, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████████████████▉                                                                               | 999/2000 [08:17<08:18,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_13__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T15:48:46.362893+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:48:46.364974+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:48:46.366677+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T15:48:46.368700+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T15:48:46.372403+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:48:46.374153+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:48:46.375828+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 13 accuracy:  0.9155\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049861 0.00049861 0.00049861 ... 0.00050454 0.00050574 0.00049861]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0023686416440694682\n",
      "Boosting iter: 15 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 15/20\n",
      "random state: 14\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049861 0.00049861 0.00049861 ... 0.00050454 0.00050574 0.00049861]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([864, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████████████████████████████████                                                                                               | 799/2000 [06:38<09:58,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_14__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T15:55:33.920247+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:55:33.922326+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T15:55:33.924015+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T15:55:33.926162+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T15:55:33.929847+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:55:33.931605+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T15:55:33.933295+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 14 accuracy:  0.9145\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049851 0.00049851 0.00049851 ... 0.00050563 0.00050683 0.00049851]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002354422763800816\n",
      "Boosting iter: 16 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 16/20\n",
      "random state: 15\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049851 0.00049851 0.00049851 ... 0.00050563 0.00050683 0.00049851]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([866, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████████████████████████████████████████████▎                                                                          | 1049/2000 [08:36<07:48,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_15__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T16:04:20.125137+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:04:20.127181+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:04:20.128841+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T16:04:20.130893+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T16:04:20.134599+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:04:20.136328+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:04:20.138034+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 15 accuracy:  0.9165\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049841 0.00049841 0.00049841 ... 0.00050673 0.00050793 0.00049841]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002379158876709291\n",
      "Boosting iter: 17 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 17/20\n",
      "random state: 16\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049841 0.00049841 0.00049841 ... 0.00050673 0.00050793 0.00049841]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([866, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████████████████████████████████▏                                                                                                  | 749/2000 [06:14<10:25,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_16__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T16:10:43.758748+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:10:43.760882+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:10:43.762638+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T16:10:43.764752+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T16:10:43.768638+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:10:43.770440+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:10:43.772161+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 16 accuracy:  0.9215\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049831 0.00049831 0.00049831 ... 0.00050663 0.00050907 0.00049831]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002444253559562585\n",
      "Boosting iter: 18 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 18/20\n",
      "random state: 17\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049831 0.00049831 0.00049831 ... 0.00050663 0.00050907 0.00049831]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([867, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████████████████▍                                                                                                                      | 499/2000 [04:09<12:30,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_17__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T16:15:02.075316+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:15:02.077336+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:15:02.078544+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T16:15:02.080024+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T16:15:02.082639+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:15:02.084061+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:15:02.085302+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 17 accuracy:  0.9215\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049822 0.00049822 0.00049822 ... 0.00050777 0.00050897 0.00049822]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024423107913224577\n",
      "Boosting iter: 19 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 19/20\n",
      "random state: 18\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049822 0.00049822 0.00049822 ... 0.00050777 0.00050897 0.00049822]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([868, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████████████████▎                                                                                                              | 599/2000 [04:57<11:35,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_18__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T16:20:09.726196+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:20:09.728448+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:20:09.730218+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T16:20:09.732287+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T16:20:09.736061+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:20:09.737805+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:20:09.739562+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 18 accuracy:  0.9265\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049812 0.00049812 0.00049812 ... 0.00050768 0.00050888 0.00049812]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.00251368427668859\n",
      "Boosting iter: 20 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 20/20\n",
      "random state: 19\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049812 0.00049812 0.00049812 ... 0.00050768 0.00050888 0.00049812]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([869, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████████████████████████████▎                                                                                                          | 649/2000 [05:23<11:14,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_19__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T16:25:43.092284+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:25:43.094279+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:25:43.095477+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T16:25:43.096974+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T16:25:43.099653+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:25:43.101178+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:25:43.102458+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 19 accuracy:  0.92\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049802 0.00049802 0.00049802 ... 0.00050881 0.00051001 0.00049802]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024205886104410428\n",
      "Finished run 0 / 3\n",
      "Run 2 / 3\n",
      "Boosting iter: 1 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 21/20\n",
      "random state: 20\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  None\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████████████████████████████████████████████▎                                                                          | 1049/2000 [07:01<06:22,  2.49it/s]\n",
      "[2023-12-17T16:32:46.610432+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:32:46.612500+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:32:46.614158+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T16:32:46.616132+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T16:32:46.619786+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:32:46.621421+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:32:46.623054+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_0__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 0 accuracy:  0.9255\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049991 0.00049991 0.00049991 ... 0.00049991 0.00049991 0.00049991]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0025195350066280387\n",
      "Boosting iter: 2 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 22/20\n",
      "random state: 21\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049991 0.00049991 0.00049991 ... 0.00049991 0.00049991 0.00049991]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([870, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████████████████▎                                                                                                              | 599/2000 [04:59<11:41,  2.00it/s]\n",
      "[2023-12-17T16:37:48.336336+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:37:48.338414+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:37:48.340051+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T16:37:48.342048+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T16:37:48.345665+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:37:48.347345+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:37:48.348933+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_1__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 1 accuracy:  0.9055\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.0004998  0.0004998  0.0004998  ... 0.0004998  0.00050093 0.0004998 ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0022588721318872462\n",
      "Boosting iter: 3 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 23/20\n",
      "random state: 22\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.0004998  0.0004998  0.0004998  ... 0.0004998  0.00050093 0.0004998 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([870, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████████████████▎                                                                                                              | 599/2000 [04:57<11:35,  2.01it/s]\n",
      "[2023-12-17T16:42:47.719098+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:42:47.721167+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:42:47.722839+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T16:42:47.724851+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T16:42:47.728502+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:42:47.730193+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:42:47.731805+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_2__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 2 accuracy:  0.9165\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.0004997  0.0004997  0.0004997  ... 0.0004997  0.00050203 0.0004997 ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0023933504489159862\n",
      "Boosting iter: 4 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 24/20\n",
      "random state: 23\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.0004997  0.0004997  0.0004997  ... 0.0004997  0.00050203 0.0004997 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([867, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████████████████████████████▏                                                                                                      | 699/2000 [05:40<10:32,  2.06it/s]\n",
      "[2023-12-17T16:48:29.753443+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:48:29.755525+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:48:29.757143+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T16:48:29.759120+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T16:48:29.762732+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:48:29.764369+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:48:29.765988+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_3__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 3 accuracy:  0.9225\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.0004996  0.0004996  0.0004996  ... 0.0004996  0.00050318 0.0004996 ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024733278801342723\n",
      "Boosting iter: 5 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 25/20\n",
      "random state: 24\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.0004996  0.0004996  0.0004996  ... 0.0004996  0.00050318 0.0004996 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([870, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████████████████████████████████                                                                                               | 799/2000 [06:34<09:53,  2.02it/s]\n",
      "[2023-12-17T16:55:06.437134+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:55:06.439259+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T16:55:06.440938+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T16:55:06.442967+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T16:55:06.446711+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:55:06.448391+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T16:55:06.450042+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_4__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 4 accuracy:  0.916\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.0004995  0.0004995  0.0004995  ... 0.00050069 0.00050428 0.0004995 ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002385034962729386\n",
      "Boosting iter: 6 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 26/20\n",
      "random state: 25\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.0004995  0.0004995  0.0004995  ... 0.00050069 0.00050428 0.0004995 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([872, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████████████████████████████▏                                                                                                      | 699/2000 [05:42<10:37,  2.04it/s]\n",
      "[2023-12-17T17:00:51.125648+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:00:51.127783+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:00:51.129434+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T17:00:51.131471+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T17:00:51.135174+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:00:51.136883+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:00:51.138558+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_5__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 5 accuracy:  0.923\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049941 0.00049941 0.00049941 ... 0.00050184 0.00050543 0.00049941]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002478113559873431\n",
      "Boosting iter: 7 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 27/20\n",
      "random state: 26\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049941 0.00049941 0.00049941 ... 0.00050184 0.00050543 0.00049941]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([868, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████████████████████████████▎                                                                                                          | 649/2000 [05:19<11:05,  2.03it/s]\n",
      "[2023-12-17T17:06:12.546833+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:06:12.548873+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:06:12.550558+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T17:06:12.552545+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T17:06:12.556241+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:06:12.557961+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:06:12.559586+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_6__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 6 accuracy:  0.921\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049931 0.00049931 0.00049931 ... 0.00050174 0.00050533 0.00049931]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024490686230714685\n",
      "Boosting iter: 8 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 28/20\n",
      "random state: 27\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049931 0.00049931 0.00049931 ... 0.00050174 0.00050533 0.00049931]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([869, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████████████████▉                                                                               | 999/2000 [08:16<08:17,  2.01it/s]\n",
      "[2023-12-17T17:14:30.564074+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:14:30.566231+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:14:30.567873+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T17:14:30.569868+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T17:14:30.573528+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:14:30.575213+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:14:30.576841+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_7__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 7 accuracy:  0.9185\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049921 0.00049921 0.00049921 ... 0.00050164 0.00050523 0.00049921]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024148440961876\n",
      "Boosting iter: 9 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 29/20\n",
      "random state: 28\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049921 0.00049921 0.00049921 ... 0.00050164 0.00050523 0.00049921]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([871, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████████████████████████████▎                                                                                                          | 649/2000 [05:21<11:09,  2.02it/s]\n",
      "[2023-12-17T17:19:54.088617+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:19:54.090160+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:19:54.091489+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T17:19:54.095840+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T17:19:54.100749+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:19:54.102629+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:19:54.106168+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_8__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 8 accuracy:  0.9165\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049911 0.00049911 0.00049911 ... 0.00050154 0.00050513 0.00049911]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0023871738436906727\n",
      "Boosting iter: 10 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 30/20\n",
      "random state: 29\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049911 0.00049911 0.00049911 ... 0.00050154 0.00050513 0.00049911]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([869, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████████████████▉                                                                               | 999/2000 [08:17<08:18,  2.01it/s]\n",
      "[2023-12-17T17:28:13.694745+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:28:13.696811+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:28:13.698473+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T17:28:13.700418+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T17:28:13.704000+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:28:13.705657+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:28:13.707277+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_9__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 9 accuracy:  0.901\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.000499   0.000499   0.000499   ... 0.00050254 0.00050613 0.000499  ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.00219956937402228\n",
      "Boosting iter: 11 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 31/20\n",
      "random state: 30\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.000499   0.000499   0.000499   ... 0.00050254 0.00050613 0.000499  ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([867, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████████████████▍                                                                                                                      | 499/2000 [04:07<12:23,  2.02it/s]\n",
      "[2023-12-17T17:32:22.769482+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:32:22.771600+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:32:22.773290+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T17:32:22.775383+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T17:32:22.779095+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:32:22.781044+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:32:22.782754+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_10__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 10 accuracy:  0.917\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.0004989  0.0004989  0.0004989  ... 0.00050364 0.00050603 0.0004989 ]\n",
      "are all weights equal?:  27\n",
      "estimator weight:  0.0023916015074647717\n",
      "Boosting iter: 12 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 32/20\n",
      "random state: 31\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.0004989  0.0004989  0.0004989  ... 0.00050364 0.00050603 0.0004989 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([872, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                               | 1399/2000 [11:36<04:59,  2.01it/s]\n",
      "[2023-12-17T17:44:00.735135+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:44:00.737446+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:44:00.739141+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T17:44:00.741154+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T17:44:00.744865+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:44:00.746578+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:44:00.748231+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_11__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 11 accuracy:  0.9295\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049881 0.00049881 0.00049881 ... 0.00050355 0.00050594 0.00049881]\n",
      "are all weights equal?:  80\n",
      "estimator weight:  0.002566220137456705\n",
      "Boosting iter: 13 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 33/20\n",
      "random state: 32\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049881 0.00049881 0.00049881 ... 0.00050355 0.00050594 0.00049881]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([871, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████████████████████████████████████████████████████████████▉                                                                                   | 949/2000 [07:48<08:38,  2.03it/s]\n",
      "[2023-12-17T17:51:51.015603+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:51:51.017644+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:51:51.019325+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T17:51:51.021321+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T17:51:51.025015+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:51:51.026705+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:51:51.028314+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_12__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 12 accuracy:  0.9255\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049871 0.00049871 0.00049871 ... 0.00050345 0.00050584 0.00049871]\n",
      "are all weights equal?:  4\n",
      "estimator weight:  0.0025054727196763458\n",
      "Boosting iter: 14 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 34/20\n",
      "random state: 33\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049871 0.00049871 0.00049871 ... 0.00050345 0.00050584 0.00049871]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([866, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████████████████████████████████                                                                                               | 799/2000 [06:33<09:50,  2.03it/s]\n",
      "[2023-12-17T17:58:25.998460+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:58:26.000580+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T17:58:26.002312+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T17:58:26.004352+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T17:58:26.008041+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:58:26.009772+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T17:58:26.011475+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_13__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 13 accuracy:  0.9155\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049861 0.00049861 0.00049861 ... 0.00050454 0.00050574 0.00049861]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0023686416440694682\n",
      "Boosting iter: 15 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 35/20\n",
      "random state: 34\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049861 0.00049861 0.00049861 ... 0.00050454 0.00050574 0.00049861]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([864, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████████████████████████▎                                                                                                                  | 549/2000 [04:32<12:00,  2.01it/s]\n",
      "[2023-12-17T18:03:00.576497+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:03:00.578603+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:03:00.580240+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T18:03:00.582213+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T18:03:00.585853+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:03:00.587516+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:03:00.589107+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_14__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 14 accuracy:  0.9145\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049851 0.00049851 0.00049851 ... 0.00050563 0.00050683 0.00049851]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002354422763800816\n",
      "Boosting iter: 16 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 36/20\n",
      "random state: 35\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049851 0.00049851 0.00049851 ... 0.00050563 0.00050683 0.00049851]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([866, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 1149/2000 [09:31<07:03,  2.01it/s]\n",
      "[2023-12-17T18:12:34.049840+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:12:34.051924+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:12:34.053576+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T18:12:34.055591+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T18:12:34.059271+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:12:34.060972+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:12:34.062603+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_15__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 15 accuracy:  0.9165\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049841 0.00049841 0.00049841 ... 0.00050673 0.00050793 0.00049841]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002379158876709291\n",
      "Boosting iter: 17 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 37/20\n",
      "random state: 36\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049841 0.00049841 0.00049841 ... 0.00050673 0.00050793 0.00049841]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([866, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████████████████████████████▏                                                                                                      | 699/2000 [05:42<10:37,  2.04it/s]\n",
      "[2023-12-17T18:18:18.668816+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:18:18.670439+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:18:18.675060+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T18:18:18.678479+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T18:18:18.682172+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:18:18.683599+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:18:18.685000+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_16__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 16 accuracy:  0.9215\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049831 0.00049831 0.00049831 ... 0.00050663 0.00050907 0.00049831]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002444253559562585\n",
      "Boosting iter: 18 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 38/20\n",
      "random state: 37\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049831 0.00049831 0.00049831 ... 0.00050663 0.00050907 0.00049831]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([867, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████████████████████████████████▏                                                                                                  | 749/2000 [06:13<10:23,  2.01it/s]\n",
      "[2023-12-17T18:24:34.019431+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:24:34.021554+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:24:34.023190+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T18:24:34.025183+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T18:24:34.028811+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:24:34.030474+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:24:34.032076+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_17__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 17 accuracy:  0.9215\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049822 0.00049822 0.00049822 ... 0.00050777 0.00050897 0.00049822]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024423107913224577\n",
      "Boosting iter: 19 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 39/20\n",
      "random state: 38\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049822 0.00049822 0.00049822 ... 0.00050777 0.00050897 0.00049822]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([868, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████████████████████████████████                                                                                               | 799/2000 [06:35<09:54,  2.02it/s]\n",
      "[2023-12-17T18:31:11.236478+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:31:11.238624+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:31:11.240262+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T18:31:11.242252+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T18:31:11.245893+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:31:11.247535+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:31:11.249133+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_18__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 18 accuracy:  0.9265\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049812 0.00049812 0.00049812 ... 0.00050768 0.00050888 0.00049812]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.00251368427668859\n",
      "Boosting iter: 20 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 40/20\n",
      "random state: 39\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049812 0.00049812 0.00049812 ... 0.00050768 0.00050888 0.00049812]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([869, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████▌                                                                                                                              | 399/2000 [03:13<12:58,  2.06it/s]\n",
      "[2023-12-17T18:34:27.098001+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:34:27.100085+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:34:27.101699+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T18:34:27.103662+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T18:34:27.107300+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:34:27.108927+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:34:27.110541+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_19__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 19 accuracy:  0.92\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049802 0.00049802 0.00049802 ... 0.00050881 0.00051001 0.00049802]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024205886104410428\n",
      "Finished run 1 / 3\n",
      "Run 3 / 3\n",
      "Boosting iter: 1 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 41/20\n",
      "random state: 40\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  None\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████████████████████████████████████████████▎                                                                          | 1049/2000 [07:02<06:22,  2.48it/s]\n",
      "[2023-12-17T18:41:31.234283+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:41:31.236492+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:41:31.238189+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T18:41:31.240224+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T18:41:31.243969+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:41:31.245702+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:41:31.247374+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_0__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 0 accuracy:  0.9255\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049991 0.00049991 0.00049991 ... 0.00049991 0.00049991 0.00049991]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0025195350066280387\n",
      "Boosting iter: 2 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 42/20\n",
      "random state: 41\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049991 0.00049991 0.00049991 ... 0.00049991 0.00049991 0.00049991]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([870, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████████████████████████████████                                                                                               | 799/2000 [06:29<09:45,  2.05it/s]\n",
      "[2023-12-17T18:48:02.471426+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:48:02.473185+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:48:02.474641+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T18:48:02.476619+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T18:48:02.479510+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:48:02.480795+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:48:02.482653+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_1__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 1 accuracy:  0.9055\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.0004998  0.0004998  0.0004998  ... 0.0004998  0.00050093 0.0004998 ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0022588721318872462\n",
      "Boosting iter: 3 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 43/20\n",
      "random state: 42\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.0004998  0.0004998  0.0004998  ... 0.0004998  0.00050093 0.0004998 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([870, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████████████████████████████▏                                                                                                      | 699/2000 [05:42<10:37,  2.04it/s]\n",
      "[2023-12-17T18:53:46.724023+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:53:46.726140+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:53:46.727731+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T18:53:46.729687+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T18:53:46.733268+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:53:46.734900+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:53:46.736488+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_2__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 2 accuracy:  0.9165\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.0004997  0.0004997  0.0004997  ... 0.0004997  0.00050203 0.0004997 ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0023933504489159862\n",
      "Boosting iter: 4 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 44/20\n",
      "random state: 43\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.0004997  0.0004997  0.0004997  ... 0.0004997  0.00050203 0.0004997 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([867, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████████████████▎                                                                                                              | 599/2000 [04:51<11:22,  2.05it/s]\n",
      "[2023-12-17T18:58:40.251043+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:58:40.253122+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T18:58:40.254804+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T18:58:40.256792+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T18:58:40.260472+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:58:40.262191+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T18:58:40.263818+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_3__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 3 accuracy:  0.9225\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.0004996  0.0004996  0.0004996  ... 0.0004996  0.00050318 0.0004996 ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024733278801342723\n",
      "Boosting iter: 5 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 45/20\n",
      "random state: 44\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.0004996  0.0004996  0.0004996  ... 0.0004996  0.00050318 0.0004996 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([870, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████████████████████████████████                                                                                           | 849/2000 [06:59<09:28,  2.03it/s]\n",
      "[2023-12-17T19:05:41.394794+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:05:41.396885+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:05:41.398606+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T19:05:41.400593+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T19:05:41.404216+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:05:41.405905+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:05:41.407523+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_4__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 4 accuracy:  0.916\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.0004995  0.0004995  0.0004995  ... 0.00050069 0.00050428 0.0004995 ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002385034962729386\n",
      "Boosting iter: 6 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 46/20\n",
      "random state: 45\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.0004995  0.0004995  0.0004995  ... 0.00050069 0.00050428 0.0004995 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([872, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████████████████▎                                                                                                              | 599/2000 [04:48<11:14,  2.08it/s]\n",
      "[2023-12-17T19:10:31.808241+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:10:31.810495+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:10:31.812163+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T19:10:31.814196+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T19:10:31.817855+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:10:31.819565+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:10:31.821366+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_5__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 5 accuracy:  0.923\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049941 0.00049941 0.00049941 ... 0.00050184 0.00050543 0.00049941]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002478113559873431\n",
      "Boosting iter: 7 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 47/20\n",
      "random state: 46\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049941 0.00049941 0.00049941 ... 0.00050184 0.00050543 0.00049941]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1258 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([868, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████████████████▉                                                                               | 999/2000 [08:12<08:13,  2.03it/s]\n",
      "[2023-12-17T19:18:46.498358+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:18:46.500638+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:18:46.502333+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T19:18:46.504317+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T19:18:46.507985+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:18:46.509698+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:18:46.511471+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_6__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 6 accuracy:  0.921\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049931 0.00049931 0.00049931 ... 0.00050174 0.00050533 0.00049931]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024490686230714685\n",
      "Boosting iter: 8 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 48/20\n",
      "random state: 47\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049931 0.00049931 0.00049931 ... 0.00050174 0.00050533 0.00049931]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([869, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████▌                                                                                                                              | 399/2000 [03:14<13:00,  2.05it/s]\n",
      "[2023-12-17T19:22:02.888790+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:22:02.899347+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:22:02.900685+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T19:22:02.902427+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T19:22:02.905709+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:22:02.908567+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:22:02.909683+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_7__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 7 accuracy:  0.9185\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049921 0.00049921 0.00049921 ... 0.00050164 0.00050523 0.00049921]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024148440961876\n",
      "Boosting iter: 9 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 49/20\n",
      "random state: 48\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049921 0.00049921 0.00049921 ... 0.00050164 0.00050523 0.00049921]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([871, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████████████████████████████▎                                                                                                          | 649/2000 [05:15<10:56,  2.06it/s]\n",
      "[2023-12-17T19:27:20.266416+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:27:20.268455+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:27:20.270113+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T19:27:20.272095+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T19:27:20.275716+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:27:20.277369+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:27:20.278988+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_8__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 8 accuracy:  0.9165\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049911 0.00049911 0.00049911 ... 0.00050154 0.00050513 0.00049911]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0023871738436906727\n",
      "Boosting iter: 10 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 50/20\n",
      "random state: 49\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049911 0.00049911 0.00049911 ... 0.00050154 0.00050513 0.00049911]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([869, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                           | 1249/2000 [10:16<06:10,  2.03it/s]\n",
      "[2023-12-17T19:37:38.557375+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:37:38.559451+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:37:38.561127+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T19:37:38.563174+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T19:37:38.566951+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:37:38.568685+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:37:38.570340+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_9__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 9 accuracy:  0.901\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.000499   0.000499   0.000499   ... 0.00050254 0.00050613 0.000499  ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.00219956937402228\n",
      "Boosting iter: 11 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 51/20\n",
      "random state: 50\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.000499   0.000499   0.000499   ... 0.00050254 0.00050613 0.000499  ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([867, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████████████████████████████████                                                                                           | 849/2000 [07:02<09:32,  2.01it/s]\n",
      "[2023-12-17T19:44:42.790625+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:44:42.792736+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:44:42.794424+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T19:44:42.796452+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T19:44:42.800184+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:44:42.801872+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:44:42.803543+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_10__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 10 accuracy:  0.917\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.0004989  0.0004989  0.0004989  ... 0.00050364 0.00050603 0.0004989 ]\n",
      "are all weights equal?:  27\n",
      "estimator weight:  0.0023916015074647717\n",
      "Boosting iter: 12 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 52/20\n",
      "random state: 51\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.0004989  0.0004989  0.0004989  ... 0.00050364 0.00050603 0.0004989 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([872, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████████████████████████████████████                                                                                       | 899/2000 [07:18<08:56,  2.05it/s]\n",
      "[2023-12-17T19:52:03.295796+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:52:03.298153+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:52:03.299336+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T19:52:03.300988+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T19:52:03.304338+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:52:03.306981+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:52:03.308269+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_11__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 11 accuracy:  0.9295\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049881 0.00049881 0.00049881 ... 0.00050355 0.00050594 0.00049881]\n",
      "are all weights equal?:  80\n",
      "estimator weight:  0.002566220137456705\n",
      "Boosting iter: 13 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 53/20\n",
      "random state: 52\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049881 0.00049881 0.00049881 ... 0.00050355 0.00050594 0.00049881]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([871, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████████████████████████████████████                                                                                       | 899/2000 [07:19<08:58,  2.05it/s]\n",
      "[2023-12-17T19:59:24.690599+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:59:24.692722+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T19:59:24.694516+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T19:59:24.696515+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T19:59:24.700163+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:59:24.701894+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T19:59:24.703496+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_12__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 12 accuracy:  0.9255\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049871 0.00049871 0.00049871 ... 0.00050345 0.00050584 0.00049871]\n",
      "are all weights equal?:  4\n",
      "estimator weight:  0.0025054727196763458\n",
      "Boosting iter: 14 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 54/20\n",
      "random state: 53\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049871 0.00049871 0.00049871 ... 0.00050345 0.00050584 0.00049871]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([866, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 1499/2000 [12:21<04:07,  2.02it/s]\n",
      "[2023-12-17T20:11:48.016244+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T20:11:48.018353+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T20:11:48.020000+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T20:11:48.022002+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T20:11:48.025689+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T20:11:48.027351+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T20:11:48.028972+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_13__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 13 accuracy:  0.9155\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049861 0.00049861 0.00049861 ... 0.00050454 0.00050574 0.00049861]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0023686416440694682\n",
      "Boosting iter: 15 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 55/20\n",
      "random state: 54\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049861 0.00049861 0.00049861 ... 0.00050454 0.00050574 0.00049861]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([864, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████████████████████████▎                                                                                                                  | 549/2000 [04:23<11:35,  2.09it/s]\n",
      "[2023-12-17T20:16:13.039607+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T20:16:13.041573+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T20:16:13.042762+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T20:16:13.044210+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T20:16:13.046846+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T20:16:13.048256+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T20:16:13.049438+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_14__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 14 accuracy:  0.9145\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049851 0.00049851 0.00049851 ... 0.00050563 0.00050683 0.00049851]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002354422763800816\n",
      "Boosting iter: 16 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 56/20\n",
      "random state: 55\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049851 0.00049851 0.00049851 ... 0.00050563 0.00050683 0.00049851]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([866, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████████████████████████████████▏                                                                                                  | 749/2000 [06:06<10:12,  2.04it/s]\n",
      "[2023-12-17T20:22:21.953605+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T20:22:21.954890+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T20:22:21.956380+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T20:22:21.957611+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T20:22:21.960656+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T20:22:21.961686+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T20:22:21.962852+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_15__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 15 accuracy:  0.9165\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049841 0.00049841 0.00049841 ... 0.00050673 0.00050793 0.00049841]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002379158876709291\n",
      "Boosting iter: 17 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 57/20\n",
      "random state: 56\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049841 0.00049841 0.00049841 ... 0.00050673 0.00050793 0.00049841]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([866, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████████████████████████████▏                                                                                                      | 699/2000 [05:40<10:34,  2.05it/s]\n",
      "[2023-12-17T20:28:04.774442+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T20:28:04.776522+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T20:28:04.778180+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T20:28:04.780157+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T20:28:04.783787+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T20:28:04.785451+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T20:28:04.787059+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_16__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 16 accuracy:  0.9215\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049831 0.00049831 0.00049831 ... 0.00050663 0.00050907 0.00049831]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002444253559562585\n",
      "Boosting iter: 18 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 58/20\n",
      "random state: 57\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049831 0.00049831 0.00049831 ... 0.00050663 0.00050907 0.00049831]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([867, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████████████████████████████████████                                                                                       | 899/2000 [07:23<09:03,  2.03it/s]\n",
      "[2023-12-17T20:35:30.002412+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T20:35:30.004514+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T20:35:30.006161+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T20:35:30.008108+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T20:35:30.011691+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T20:35:30.013494+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T20:35:30.015147+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_17__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 17 accuracy:  0.9215\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049822 0.00049822 0.00049822 ... 0.00050777 0.00050897 0.00049822]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024423107913224577\n",
      "Boosting iter: 19 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 59/20\n",
      "random state: 58\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049822 0.00049822 0.00049822 ... 0.00050777 0.00050897 0.00049822]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([868, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████████████████████████████████████████████▎                                                                          | 1049/2000 [08:31<07:43,  2.05it/s]\n",
      "[2023-12-17T20:44:02.960722+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T20:44:02.962322+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T20:44:02.963638+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T20:44:02.967997+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T20:44:02.973174+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T20:44:02.974922+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T20:44:02.976499+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_18__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 18 accuracy:  0.9265\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049812 0.00049812 0.00049812 ... 0.00050768 0.00050888 0.00049812]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.00251368427668859\n",
      "Boosting iter: 20 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 60/20\n",
      "random state: 59\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00049812 0.00049812 0.00049812 ... 0.00050768 0.00050888 0.00049812]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([2000, 62]), X_train shape: torch.Size([1626, 62]), X_val shape: torch.Size([400, 62])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([1940, 1415,  918,  ...,  273,  854, 1896])\n",
      "np version train indices:  [1097 1430 1205 ... 1259 1464 1780]\n",
      "val indices:  tensor([False, False, False,  ..., False,  True,  True])\n",
      "X_train after sampling: torch.Size([1626, 62]) and X_val: torch.Size([869, 62])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████████████████▌                                                                                                                                      | 299/2000 [02:21<13:27,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_19__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (2000,)\n",
      "Boosting iter 19 accuracy:  0.92\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00049802 0.00049802 0.00049802 ... 0.00050881 0.00051001 0.00049802]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024205886104410428\n",
      "Finished run 2 / 3\n",
      "Start final evaluation...\n",
      "run:  0\n",
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__1.pkl\n",
      "Train model in aggregate\n",
      "Train model 2/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__2.pkl\n",
      "Train model in aggregate\n",
      "Train model 3/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__3.pkl\n",
      "Train model in aggregate\n",
      "Train model 4/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__4.pkl\n",
      "Train model in aggregate\n",
      "Train model 5/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__5.pkl\n",
      "Train model in aggregate\n",
      "Train model 6/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__6.pkl\n",
      "Train model in aggregate\n",
      "Train model 7/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__7.pkl\n",
      "Train model in aggregate\n",
      "Train model 8/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__8.pkl\n",
      "Train model in aggregate\n",
      "Train model 9/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__9.pkl\n",
      "Train model in aggregate\n",
      "Train model 10/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__10.pkl\n",
      "Train model in aggregate\n",
      "Train model 11/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__11.pkl\n",
      "Train model in aggregate\n",
      "Train model 12/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__12.pkl\n",
      "Train model in aggregate\n",
      "Train model 13/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__13.pkl\n",
      "Train model in aggregate\n",
      "Train model 14/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__14.pkl\n",
      "Train model in aggregate\n",
      "Train model 15/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__15.pkl\n",
      "Train model in aggregate\n",
      "Train model 16/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__16.pkl\n",
      "Train model in aggregate\n",
      "Train model 17/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__17.pkl\n",
      "Train model in aggregate\n",
      "Train model 18/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__18.pkl\n",
      "Train model in aggregate\n",
      "Train model 19/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__19.pkl\n",
      "Train model in aggregate\n",
      "Train model 20/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__1.pkl\n",
      "Train model in aggregate\n",
      "Train model 2/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__2.pkl\n",
      "Train model in aggregate\n",
      "Train model 3/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__3.pkl\n",
      "Train model in aggregate\n",
      "Train model 4/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__4.pkl\n",
      "Train model in aggregate\n",
      "Train model 5/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__5.pkl\n",
      "Train model in aggregate\n",
      "Train model 6/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__6.pkl\n",
      "Train model in aggregate\n",
      "Train model 7/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__7.pkl\n",
      "Train model in aggregate\n",
      "Train model 8/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__8.pkl\n",
      "Train model in aggregate\n",
      "Train model 9/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__9.pkl\n",
      "Train model in aggregate\n",
      "Train model 10/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__10.pkl\n",
      "Train model in aggregate\n",
      "Train model 11/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__11.pkl\n",
      "Train model in aggregate\n",
      "Train model 12/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__12.pkl\n",
      "Train model in aggregate\n",
      "Train model 13/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__13.pkl\n",
      "Train model in aggregate\n",
      "Train model 14/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__14.pkl\n",
      "Train model in aggregate\n",
      "Train model 15/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__15.pkl\n",
      "Train model in aggregate\n",
      "Train model 16/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__16.pkl\n",
      "Train model in aggregate\n",
      "Train model 17/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__17.pkl\n",
      "Train model in aggregate\n",
      "Train model 18/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__18.pkl\n",
      "Train model in aggregate\n",
      "Train model 19/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__19.pkl\n",
      "Train model in aggregate\n",
      "Train model 20/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Test accuracy for individual downstream model 0 / 20: 0.9232777777777778\n",
      "Test accuracy for individual downstream model 1 / 20: 0.9040555555555555\n",
      "Test accuracy for individual downstream model 2 / 20: 0.9148888888888889\n",
      "Test accuracy for individual downstream model 3 / 20: 0.9127777777777778\n",
      "Test accuracy for individual downstream model 4 / 20: 0.9071111111111111\n",
      "Test accuracy for individual downstream model 5 / 20: 0.9171111111111111\n",
      "Test accuracy for individual downstream model 6 / 20: 0.911\n",
      "Test accuracy for individual downstream model 7 / 20: 0.9182222222222223\n",
      "Test accuracy for individual downstream model 8 / 20: 0.9112777777777777\n",
      "Test accuracy for individual downstream model 9 / 20: 0.904\n",
      "Test accuracy for individual downstream model 10 / 20: 0.9125\n",
      "Test accuracy for individual downstream model 11 / 20: 0.9266111111111112\n",
      "Test accuracy for individual downstream model 12 / 20: 0.925\n",
      "Test accuracy for individual downstream model 13 / 20: 0.9152222222222223\n",
      "Test accuracy for individual downstream model 14 / 20: 0.9097777777777778\n",
      "Test accuracy for individual downstream model 15 / 20: 0.9182777777777777\n",
      "Test accuracy for individual downstream model 16 / 20: 0.9208333333333333\n",
      "Test accuracy for individual downstream model 17 / 20: 0.9138333333333334\n",
      "Test accuracy for individual downstream model 18 / 20: 0.9161666666666667\n",
      "Test accuracy for individual downstream model 19 / 20: 0.9172777777777777\n",
      "shape of 20 DGE y predictions:  (18000,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 20, weight shape: 20\n",
      "weighted means:  [0.50676438 0.9958459  0.99489401 ... 0.99649778 0.5819769  0.98979793]\n",
      "Test accuracy for individual downstream model 0 / 10: 0.9232777777777778\n",
      "Test accuracy for individual downstream model 1 / 10: 0.9040555555555555\n",
      "Test accuracy for individual downstream model 2 / 10: 0.9148888888888889\n",
      "Test accuracy for individual downstream model 3 / 10: 0.9127777777777778\n",
      "Test accuracy for individual downstream model 4 / 10: 0.9071111111111111\n",
      "Test accuracy for individual downstream model 5 / 10: 0.9171111111111111\n",
      "Test accuracy for individual downstream model 6 / 10: 0.911\n",
      "Test accuracy for individual downstream model 7 / 10: 0.9182222222222223\n",
      "Test accuracy for individual downstream model 8 / 10: 0.9112777777777777\n",
      "Test accuracy for individual downstream model 9 / 10: 0.904\n",
      "shape of 10 DGE y predictions:  (18000,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 10, weight shape: 10\n",
      "weighted means:  [0.50752557 0.99984321 0.99915464 ... 0.99661566 0.38731989 0.98093961]\n",
      "Test accuracy for individual downstream model 0 / 5: 0.9232777777777778\n",
      "Test accuracy for individual downstream model 1 / 5: 0.9040555555555555\n",
      "Test accuracy for individual downstream model 2 / 5: 0.9148888888888889\n",
      "Test accuracy for individual downstream model 3 / 5: 0.9127777777777778\n",
      "Test accuracy for individual downstream model 4 / 5: 0.9071111111111111\n",
      "shape of 5 DGE y predictions:  (18000,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 5, weight shape: 5\n",
      "weighted means:  [0.40245314 0.99982687 0.99878994 ... 0.99993857 0.33749474 0.9845015 ]\n",
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_concat_run0_0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "run:  1\n",
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__1.pkl\n",
      "Train model in aggregate\n",
      "Train model 2/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__2.pkl\n",
      "Train model in aggregate\n",
      "Train model 3/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__3.pkl\n",
      "Train model in aggregate\n",
      "Train model 4/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__4.pkl\n",
      "Train model in aggregate\n",
      "Train model 5/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__5.pkl\n",
      "Train model in aggregate\n",
      "Train model 6/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__6.pkl\n",
      "Train model in aggregate\n",
      "Train model 7/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__7.pkl\n",
      "Train model in aggregate\n",
      "Train model 8/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__8.pkl\n",
      "Train model in aggregate\n",
      "Train model 9/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__9.pkl\n",
      "Train model in aggregate\n",
      "Train model 10/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__10.pkl\n",
      "Train model in aggregate\n",
      "Train model 11/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__11.pkl\n",
      "Train model in aggregate\n",
      "Train model 12/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__12.pkl\n",
      "Train model in aggregate\n",
      "Train model 13/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__13.pkl\n",
      "Train model in aggregate\n",
      "Train model 14/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__14.pkl\n",
      "Train model in aggregate\n",
      "Train model 15/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__15.pkl\n",
      "Train model in aggregate\n",
      "Train model 16/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__16.pkl\n",
      "Train model in aggregate\n",
      "Train model 17/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__17.pkl\n",
      "Train model in aggregate\n",
      "Train model 18/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__18.pkl\n",
      "Train model in aggregate\n",
      "Train model 19/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__19.pkl\n",
      "Train model in aggregate\n",
      "Train model 20/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__1.pkl\n",
      "Train model in aggregate\n",
      "Train model 2/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__2.pkl\n",
      "Train model in aggregate\n",
      "Train model 3/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__3.pkl\n",
      "Train model in aggregate\n",
      "Train model 4/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__4.pkl\n",
      "Train model in aggregate\n",
      "Train model 5/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__5.pkl\n",
      "Train model in aggregate\n",
      "Train model 6/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__6.pkl\n",
      "Train model in aggregate\n",
      "Train model 7/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__7.pkl\n",
      "Train model in aggregate\n",
      "Train model 8/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__8.pkl\n",
      "Train model in aggregate\n",
      "Train model 9/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__9.pkl\n",
      "Train model in aggregate\n",
      "Train model 10/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__10.pkl\n",
      "Train model in aggregate\n",
      "Train model 11/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__11.pkl\n",
      "Train model in aggregate\n",
      "Train model 12/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__12.pkl\n",
      "Train model in aggregate\n",
      "Train model 13/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__13.pkl\n",
      "Train model in aggregate\n",
      "Train model 14/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__14.pkl\n",
      "Train model in aggregate\n",
      "Train model 15/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__15.pkl\n",
      "Train model in aggregate\n",
      "Train model 16/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__16.pkl\n",
      "Train model in aggregate\n",
      "Train model 17/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__17.pkl\n",
      "Train model in aggregate\n",
      "Train model 18/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__18.pkl\n",
      "Train model in aggregate\n",
      "Train model 19/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__19.pkl\n",
      "Train model in aggregate\n",
      "Train model 20/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Test accuracy for individual downstream model 0 / 20: 0.9232777777777778\n",
      "Test accuracy for individual downstream model 1 / 20: 0.9040555555555555\n",
      "Test accuracy for individual downstream model 2 / 20: 0.9148888888888889\n",
      "Test accuracy for individual downstream model 3 / 20: 0.9127777777777778\n",
      "Test accuracy for individual downstream model 4 / 20: 0.9071111111111111\n",
      "Test accuracy for individual downstream model 5 / 20: 0.9171111111111111\n",
      "Test accuracy for individual downstream model 6 / 20: 0.911\n",
      "Test accuracy for individual downstream model 7 / 20: 0.9182222222222223\n",
      "Test accuracy for individual downstream model 8 / 20: 0.9112777777777777\n",
      "Test accuracy for individual downstream model 9 / 20: 0.904\n",
      "Test accuracy for individual downstream model 10 / 20: 0.9125\n",
      "Test accuracy for individual downstream model 11 / 20: 0.9266111111111112\n",
      "Test accuracy for individual downstream model 12 / 20: 0.925\n",
      "Test accuracy for individual downstream model 13 / 20: 0.9152222222222223\n",
      "Test accuracy for individual downstream model 14 / 20: 0.9097777777777778\n",
      "Test accuracy for individual downstream model 15 / 20: 0.9182777777777777\n",
      "Test accuracy for individual downstream model 16 / 20: 0.9208333333333333\n",
      "Test accuracy for individual downstream model 17 / 20: 0.9138333333333334\n",
      "Test accuracy for individual downstream model 18 / 20: 0.9161666666666667\n",
      "Test accuracy for individual downstream model 19 / 20: 0.9172777777777777\n",
      "shape of 20 DGE y predictions:  (18000,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 20, weight shape: 20\n",
      "weighted means:  [0.50676438 0.9958459  0.99489401 ... 0.99649778 0.5819769  0.98979793]\n",
      "Test accuracy for individual downstream model 0 / 10: 0.9232777777777778\n",
      "Test accuracy for individual downstream model 1 / 10: 0.9040555555555555\n",
      "Test accuracy for individual downstream model 2 / 10: 0.9148888888888889\n",
      "Test accuracy for individual downstream model 3 / 10: 0.9127777777777778\n",
      "Test accuracy for individual downstream model 4 / 10: 0.9071111111111111\n",
      "Test accuracy for individual downstream model 5 / 10: 0.9171111111111111\n",
      "Test accuracy for individual downstream model 6 / 10: 0.911\n",
      "Test accuracy for individual downstream model 7 / 10: 0.9182222222222223\n",
      "Test accuracy for individual downstream model 8 / 10: 0.9112777777777777\n",
      "Test accuracy for individual downstream model 9 / 10: 0.904\n",
      "shape of 10 DGE y predictions:  (18000,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 10, weight shape: 10\n",
      "weighted means:  [0.50752557 0.99984321 0.99915464 ... 0.99661566 0.38731989 0.98093961]\n",
      "Test accuracy for individual downstream model 0 / 5: 0.9232777777777778\n",
      "Test accuracy for individual downstream model 1 / 5: 0.9040555555555555\n",
      "Test accuracy for individual downstream model 2 / 5: 0.9148888888888889\n",
      "Test accuracy for individual downstream model 3 / 5: 0.9127777777777778\n",
      "Test accuracy for individual downstream model 4 / 5: 0.9071111111111111\n",
      "shape of 5 DGE y predictions:  (18000,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 5, weight shape: 5\n",
      "weighted means:  [0.40245314 0.99982687 0.99878994 ... 0.99993857 0.33749474 0.9845015 ]\n",
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_concat_run1_0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "run:  2\n",
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__1.pkl\n",
      "Train model in aggregate\n",
      "Train model 2/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__2.pkl\n",
      "Train model in aggregate\n",
      "Train model 3/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__3.pkl\n",
      "Train model in aggregate\n",
      "Train model 4/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__4.pkl\n",
      "Train model in aggregate\n",
      "Train model 5/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__5.pkl\n",
      "Train model in aggregate\n",
      "Train model 6/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__6.pkl\n",
      "Train model in aggregate\n",
      "Train model 7/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__7.pkl\n",
      "Train model in aggregate\n",
      "Train model 8/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__8.pkl\n",
      "Train model in aggregate\n",
      "Train model 9/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__9.pkl\n",
      "Train model in aggregate\n",
      "Train model 10/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__10.pkl\n",
      "Train model in aggregate\n",
      "Train model 11/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__11.pkl\n",
      "Train model in aggregate\n",
      "Train model 12/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__12.pkl\n",
      "Train model in aggregate\n",
      "Train model 13/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__13.pkl\n",
      "Train model in aggregate\n",
      "Train model 14/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__14.pkl\n",
      "Train model in aggregate\n",
      "Train model 15/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__15.pkl\n",
      "Train model in aggregate\n",
      "Train model 16/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__16.pkl\n",
      "Train model in aggregate\n",
      "Train model 17/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__17.pkl\n",
      "Train model in aggregate\n",
      "Train model 18/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__18.pkl\n",
      "Train model in aggregate\n",
      "Train model 19/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__19.pkl\n",
      "Train model in aggregate\n",
      "Train model 20/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__1.pkl\n",
      "Train model in aggregate\n",
      "Train model 2/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__2.pkl\n",
      "Train model in aggregate\n",
      "Train model 3/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__3.pkl\n",
      "Train model in aggregate\n",
      "Train model 4/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__4.pkl\n",
      "Train model in aggregate\n",
      "Train model 5/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__5.pkl\n",
      "Train model in aggregate\n",
      "Train model 6/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__6.pkl\n",
      "Train model in aggregate\n",
      "Train model 7/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__7.pkl\n",
      "Train model in aggregate\n",
      "Train model 8/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__8.pkl\n",
      "Train model in aggregate\n",
      "Train model 9/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__9.pkl\n",
      "Train model in aggregate\n",
      "Train model 10/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__10.pkl\n",
      "Train model in aggregate\n",
      "Train model 11/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__11.pkl\n",
      "Train model in aggregate\n",
      "Train model 12/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__12.pkl\n",
      "Train model in aggregate\n",
      "Train model 13/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__13.pkl\n",
      "Train model in aggregate\n",
      "Train model 14/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__14.pkl\n",
      "Train model in aggregate\n",
      "Train model 15/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__15.pkl\n",
      "Train model in aggregate\n",
      "Train model 16/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__16.pkl\n",
      "Train model in aggregate\n",
      "Train model 17/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__17.pkl\n",
      "Train model in aggregate\n",
      "Train model 18/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__18.pkl\n",
      "Train model in aggregate\n",
      "Train model 19/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__19.pkl\n",
      "Train model in aggregate\n",
      "Train model 20/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "Test accuracy for individual downstream model 0 / 20: 0.9232777777777778\n",
      "Test accuracy for individual downstream model 1 / 20: 0.9040555555555555\n",
      "Test accuracy for individual downstream model 2 / 20: 0.9148888888888889\n",
      "Test accuracy for individual downstream model 3 / 20: 0.9127777777777778\n",
      "Test accuracy for individual downstream model 4 / 20: 0.9071111111111111\n",
      "Test accuracy for individual downstream model 5 / 20: 0.9171111111111111\n",
      "Test accuracy for individual downstream model 6 / 20: 0.911\n",
      "Test accuracy for individual downstream model 7 / 20: 0.9182222222222223\n",
      "Test accuracy for individual downstream model 8 / 20: 0.9112777777777777\n",
      "Test accuracy for individual downstream model 9 / 20: 0.904\n",
      "Test accuracy for individual downstream model 10 / 20: 0.9125\n",
      "Test accuracy for individual downstream model 11 / 20: 0.9266111111111112\n",
      "Test accuracy for individual downstream model 12 / 20: 0.925\n",
      "Test accuracy for individual downstream model 13 / 20: 0.9152222222222223\n",
      "Test accuracy for individual downstream model 14 / 20: 0.9097777777777778\n",
      "Test accuracy for individual downstream model 15 / 20: 0.9182777777777777\n",
      "Test accuracy for individual downstream model 16 / 20: 0.9208333333333333\n",
      "Test accuracy for individual downstream model 17 / 20: 0.9138333333333334\n",
      "Test accuracy for individual downstream model 18 / 20: 0.9161666666666667\n",
      "Test accuracy for individual downstream model 19 / 20: 0.9172777777777777\n",
      "shape of 20 DGE y predictions:  (18000,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 20, weight shape: 20\n",
      "weighted means:  [0.50676438 0.9958459  0.99489401 ... 0.99649778 0.5819769  0.98979793]\n",
      "Test accuracy for individual downstream model 0 / 10: 0.9232777777777778\n",
      "Test accuracy for individual downstream model 1 / 10: 0.9040555555555555\n",
      "Test accuracy for individual downstream model 2 / 10: 0.9148888888888889\n",
      "Test accuracy for individual downstream model 3 / 10: 0.9127777777777778\n",
      "Test accuracy for individual downstream model 4 / 10: 0.9071111111111111\n",
      "Test accuracy for individual downstream model 5 / 10: 0.9171111111111111\n",
      "Test accuracy for individual downstream model 6 / 10: 0.911\n",
      "Test accuracy for individual downstream model 7 / 10: 0.9182222222222223\n",
      "Test accuracy for individual downstream model 8 / 10: 0.9112777777777777\n",
      "Test accuracy for individual downstream model 9 / 10: 0.904\n",
      "shape of 10 DGE y predictions:  (18000,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 10, weight shape: 10\n",
      "weighted means:  [0.50752557 0.99984321 0.99915464 ... 0.99661566 0.38731989 0.98093961]\n",
      "Test accuracy for individual downstream model 0 / 5: 0.9232777777777778\n",
      "Test accuracy for individual downstream model 1 / 5: 0.9040555555555555\n",
      "Test accuracy for individual downstream model 2 / 5: 0.9148888888888889\n",
      "Test accuracy for individual downstream model 3 / 5: 0.9127777777777778\n",
      "Test accuracy for individual downstream model 4 / 5: 0.9071111111111111\n",
      "shape of 5 DGE y predictions:  (18000,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 5, weight shape: 5\n",
      "weighted means:  [0.40245314 0.99982687 0.99878994 ... 0.99993857 0.33749474 0.9845015 ]\n",
      "fileroot in aggregate:  workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/covid/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_concat_run2_0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (18000,)\n",
      "printing weighted avg means to latex:\n",
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "{} &       AUC &       Acc &        F1 &  Precision &    Recall &       NLL &     Brier \\\\\n",
      "\\midrule\n",
      "Oracle            &  0.928156 &  0.925148 &  0.959738 &   0.958078 &  0.961404 &  0.319109 &  0.060262 \\\\\n",
      "Naive (S)         &  0.820455 &  0.924185 &  0.959542 &   0.950396 &  0.968868 &  0.394969 &  0.064285 \\\\\n",
      "Naive (E)         &  0.861325 &  0.926056 &  0.960576 &   0.950581 &  0.970784 &  0.275404 &  0.058792 \\\\\n",
      "DGE\\$\\_\\{5\\}\\$         &  0.914892 &  0.928833 &  0.961655 &   0.961626 &  0.961684 &  0.177052 &  0.049332 \\\\\n",
      "DGE\\$\\_\\{10\\}\\$        &  0.933471 &  0.929333 &  0.961893 &   0.962643 &  0.961145 &  0.155448 &  0.046644 \\\\\n",
      "DGE\\$\\_\\{20\\}\\$        &  0.938531 &  0.933667 &  0.964504 &   0.957898 &  0.971203 &  0.147787 &  0.044732 \\\\\n",
      "DGE\\$\\_20\\$ (concat) &  0.872396 &  0.924907 &  0.959745 &   0.954931 &  0.964617 &  0.225798 &  0.056238 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "printing weighted stds to latex:\n",
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "{} &       AUC &           Acc &            F1 &  Precision &    Recall &       NLL &         Brier \\\\\n",
      "\\midrule\n",
      "Oracle            &  0.000827 &  5.218149e-04 &  2.673532e-04 &   0.000585 &  0.000075 &  0.001357 &  1.303107e-04 \\\\\n",
      "Naive (S)         &  0.000491 &  8.429486e-04 &  4.798199e-04 &   0.000898 &  0.001527 &  0.013223 &  9.745245e-04 \\\\\n",
      "Naive (E)         &  0.001690 &  9.072184e-05 &  7.132186e-05 &   0.000475 &  0.000641 &  0.001267 &  7.879696e-05 \\\\\n",
      "DGE\\$\\_\\{5\\}\\$         &  0.000000 &  0.000000e+00 &  1.110223e-16 &   0.000000 &  0.000000 &  0.000000 &  0.000000e+00 \\\\\n",
      "DGE\\$\\_\\{10\\}\\$        &  0.000000 &  1.110223e-16 &  0.000000e+00 &   0.000000 &  0.000000 &  0.000000 &  0.000000e+00 \\\\\n",
      "DGE\\$\\_\\{20\\}\\$        &  0.000000 &  1.110223e-16 &  0.000000e+00 &   0.000000 &  0.000000 &  0.000000 &  6.938894e-18 \\\\\n",
      "DGE\\$\\_20\\$ (concat) &  0.012988 &  2.549241e-03 &  1.292204e-03 &   0.003241 &  0.001186 &  0.006570 &  1.345226e-03 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "size of means:  (7, 7)\n",
      "mean elements:                          AUC       Acc        F1  Precision    Recall  \\\n",
      "Oracle             0.928156  0.925148  0.959738   0.958078  0.961404   \n",
      "Naive (S)          0.820455  0.924185  0.959542   0.950396  0.968868   \n",
      "Naive (E)          0.861325  0.926056  0.960576   0.950581  0.970784   \n",
      "DGE$_{5}$          0.914892  0.928833  0.961655   0.961626  0.961684   \n",
      "DGE$_{10}$         0.933471  0.929333  0.961893   0.962643  0.961145   \n",
      "DGE$_{20}$         0.938531  0.933667  0.964504   0.957898  0.971203   \n",
      "DGE$_20$ (concat)  0.872396  0.924907  0.959745   0.954931  0.964617   \n",
      "\n",
      "                        NLL     Brier  \n",
      "Oracle             0.319109  0.060262  \n",
      "Naive (S)          0.394969  0.064285  \n",
      "Naive (E)          0.275404  0.058792  \n",
      "DGE$_{5}$          0.177052  0.049332  \n",
      "DGE$_{10}$         0.155448  0.046644  \n",
      "DGE$_{20}$         0.147787  0.044732  \n",
      "DGE$_20$ (concat)  0.225798  0.056238  \n",
      "Dataset breast_cancer\n",
      "\n",
      "workspace_folder:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe\n",
      "results_folder:  results/breast_cancer_ctgan_nmax_2000_nsyn_2000_SAMME_observe\n",
      "Boosting DGE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:09:23.410706+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:09:23.411513+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:09:23.412249+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:09:23.413058+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:09:23.414416+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:09:23.415245+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:09:23.415849+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.unique(y):  [0 1]\n",
      "n_train: 455, nsyn: 2000\n",
      "targettype:  classification\n",
      "Run 1 / 3\n",
      "Boosting iter: 1 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 1/20\n",
      "random state: 0\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  None\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████        | 1899/2000 [03:01<00:09, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_0__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:12:36.203562+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:12:36.205701+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:12:36.207413+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:12:36.209419+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:12:36.213052+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:12:36.214770+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:12:36.216432+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 0 accuracy:  0.9252747252747253\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220292 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00220292 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00220292\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.00251627230906622\n",
      "Boosting iter: 2 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 2/20\n",
      "random state: 1\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220292 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00220292 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00220292\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 253, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 232, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 293 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True, False,  True, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False,  True, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([215, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████████████████████████████▎                                                                                                          | 649/2000 [01:21<02:49,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_1__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:14:09.299401+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:14:09.301500+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:14:09.303244+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:14:09.305337+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:14:09.309013+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:14:09.310757+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:14:09.312443+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 1 accuracy:  0.8879120879120879\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220241 0.00219688 0.00219688 0.00220698 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00220241\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00220143 0.00219688 0.00220241 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00220241 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00220698\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00220698 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00220241 0.00220241 0.00220143\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00220143\n",
      " 0.00220698 0.00220143 0.00219688 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241\n",
      " 0.00219688 0.00219688 0.00220241 0.00220143 0.00219688 0.00220241\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00220143 0.00220143\n",
      " 0.00219688 0.00220143 0.00219688 0.00220698 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00220241 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002069523106334788\n",
      "Boosting iter: 3 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 3/20\n",
      "random state: 2\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220241 0.00219688 0.00219688 0.00220698 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00220241\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00220143 0.00219688 0.00220241 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00220241 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00220698\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00220698 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00220241 0.00220241 0.00220143\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00220143\n",
      " 0.00220698 0.00220143 0.00219688 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241\n",
      " 0.00219688 0.00219688 0.00220241 0.00220143 0.00219688 0.00220241\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00220143 0.00220143\n",
      " 0.00219688 0.00220143 0.00219688 0.00220698 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00220241 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 152, 397, 449,  70,  85,  97, 181,\n",
      "         83, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 232, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 293 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  91   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 158  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 123  59  25 137\n",
      " 119 207 310 316 129 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True,  True, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True, False,  True, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([215, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████▌                                                                                                                              | 399/2000 [00:53<03:36,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_2__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:15:14.499094+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:15:14.501139+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:15:14.502891+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:15:14.504930+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:15:14.508621+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:15:14.510357+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:15:14.512027+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 2 accuracy:  0.9296703296703297\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220201 0.00219648 0.00219648 0.00220657 0.00219648 0.00220215\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220215\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00219648\n",
      " 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220201 0.00220215 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00219648 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220215 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.0022077  0.00219648\n",
      " 0.00219648 0.00219648 0.00220672 0.00220103 0.00219648 0.00220201\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201 0.00219648\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220201 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220201 0.00220103 0.00219648 0.00220201 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.0022077  0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220215 0.00220201 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00220103 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00221228\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220201 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00221228 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.0022077  0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00220201 0.00220201 0.00220103\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00219648 0.00220672 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00220103 0.00219648 0.00219648 0.00220672\n",
      " 0.00220657 0.00220103 0.00219648 0.00219648 0.00220672 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.0022077  0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220215 0.00219648 0.00220215 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.0022077  0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220201 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201\n",
      " 0.00219648 0.00219648 0.0022077  0.00220103 0.00219648 0.00220201\n",
      " 0.0022077  0.00219648 0.00219648 0.00219648 0.00220103 0.00220103\n",
      " 0.00219648 0.00220103 0.00219648 0.00220657 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648 0.00220215\n",
      " 0.00219648 0.00220103 0.0022077  0.00219648 0.00220103 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220215\n",
      " 0.00220201 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002580824186467436\n",
      "Boosting iter: 4 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 4/20\n",
      "random state: 3\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220201 0.00219648 0.00219648 0.00220657 0.00219648 0.00220215\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220215\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00219648\n",
      " 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220201 0.00220215 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00219648 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220215 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.0022077  0.00219648\n",
      " 0.00219648 0.00219648 0.00220672 0.00220103 0.00219648 0.00220201\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201 0.00219648\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220201 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220201 0.00220103 0.00219648 0.00220201 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.0022077  0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220215 0.00220201 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00220103 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00221228\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220201 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00221228 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.0022077  0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00220201 0.00220201 0.00220103\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00219648 0.00220672 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00220103 0.00219648 0.00219648 0.00220672\n",
      " 0.00220657 0.00220103 0.00219648 0.00219648 0.00220672 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.0022077  0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220215 0.00219648 0.00220215 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.0022077  0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220201 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201\n",
      " 0.00219648 0.00219648 0.0022077  0.00220103 0.00219648 0.00220201\n",
      " 0.0022077  0.00219648 0.00219648 0.00219648 0.00220103 0.00220103\n",
      " 0.00219648 0.00220103 0.00219648 0.00220657 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648 0.00220215\n",
      " 0.00219648 0.00220103 0.0022077  0.00219648 0.00220103 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220215\n",
      " 0.00220201 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 152, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 293 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 158  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 129 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True,  True, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([215, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████████████████████████▎                                                                                                                  | 549/2000 [01:12<03:12,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_3__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:16:38.677532+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:16:38.679691+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:16:38.681399+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:16:38.683488+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:16:38.687259+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:16:38.689021+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:16:38.690755+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 3 accuracy:  0.9098901098901099\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220155 0.00219602 0.00219602 0.00220611 0.00219602 0.0022017\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220679\n",
      " 0.0022011  0.00219602 0.00220665 0.00219602 0.00219602 0.00219602\n",
      " 0.00220679 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220155 0.00220679 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220679 0.00219602 0.0022011  0.00220566 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.0022017  0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220665 0.00219602 0.00220724 0.00219602\n",
      " 0.00219602 0.00219602 0.00221136 0.00220057 0.00219602 0.00220155\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00220155 0.00219602\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220155 0.00220057 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220155 0.00220057 0.00219602 0.00220665 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00221235 0.00220566 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.0022011  0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.0022011  0.00219602 0.0022017  0.00220155 0.00219602\n",
      " 0.00219602 0.0022017  0.00219602 0.00220057 0.00219602 0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00219602 0.00219602 0.00221181\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220155 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00221693 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00220057 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00221235 0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00220155 0.00220665 0.00220057\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602\n",
      " 0.0022011  0.0022017  0.00220566 0.00219602 0.00219602 0.00219602\n",
      " 0.0022017  0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00219602 0.00219602 0.00219602 0.00221136 0.00219602 0.00219602\n",
      " 0.00219602 0.00220679 0.00220057 0.00219602 0.00219602 0.00221136\n",
      " 0.00220611 0.00220057 0.00219602 0.00219602 0.00221136 0.00219602\n",
      " 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00219602 0.0022011  0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00219602 0.0022011  0.00219602\n",
      " 0.00219602 0.00219602 0.00220566 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00220724 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022017  0.00219602 0.00220679 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00221235 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220155 0.00219602 0.00220566 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220155\n",
      " 0.00219602 0.00219602 0.00220724 0.00220057 0.00219602 0.00220665\n",
      " 0.00220724 0.00219602 0.00219602 0.00219602 0.00220057 0.00220566\n",
      " 0.00219602 0.00220566 0.00219602 0.00220611 0.00220057 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00220057 0.00219602 0.00220679\n",
      " 0.00219602 0.00220057 0.00220724 0.00219602 0.00220057 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.0022017\n",
      " 0.00220155 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00220155 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220566 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.0022011\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0023105879357532355\n",
      "Boosting iter: 5 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 5/20\n",
      "random state: 4\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220155 0.00219602 0.00219602 0.00220611 0.00219602 0.0022017\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220679\n",
      " 0.0022011  0.00219602 0.00220665 0.00219602 0.00219602 0.00219602\n",
      " 0.00220679 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220155 0.00220679 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220679 0.00219602 0.0022011  0.00220566 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.0022017  0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220665 0.00219602 0.00220724 0.00219602\n",
      " 0.00219602 0.00219602 0.00221136 0.00220057 0.00219602 0.00220155\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00220155 0.00219602\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220155 0.00220057 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220155 0.00220057 0.00219602 0.00220665 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00221235 0.00220566 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.0022011  0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.0022011  0.00219602 0.0022017  0.00220155 0.00219602\n",
      " 0.00219602 0.0022017  0.00219602 0.00220057 0.00219602 0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00219602 0.00219602 0.00221181\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220155 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00221693 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00220057 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00221235 0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00220155 0.00220665 0.00220057\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602\n",
      " 0.0022011  0.0022017  0.00220566 0.00219602 0.00219602 0.00219602\n",
      " 0.0022017  0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00219602 0.00219602 0.00219602 0.00221136 0.00219602 0.00219602\n",
      " 0.00219602 0.00220679 0.00220057 0.00219602 0.00219602 0.00221136\n",
      " 0.00220611 0.00220057 0.00219602 0.00219602 0.00221136 0.00219602\n",
      " 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00219602 0.0022011  0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00219602 0.0022011  0.00219602\n",
      " 0.00219602 0.00219602 0.00220566 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00220724 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022017  0.00219602 0.00220679 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00221235 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220155 0.00219602 0.00220566 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220155\n",
      " 0.00219602 0.00219602 0.00220724 0.00220057 0.00219602 0.00220665\n",
      " 0.00220724 0.00219602 0.00219602 0.00219602 0.00220057 0.00220566\n",
      " 0.00219602 0.00220566 0.00219602 0.00220611 0.00220057 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00220057 0.00219602 0.00220679\n",
      " 0.00219602 0.00220057 0.00220724 0.00219602 0.00220057 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.0022017\n",
      " 0.00220155 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00220155 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220566 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.0022011\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 293 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 129 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([214, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████████████████████▍                                                                                                                          | 449/2000 [00:59<03:26,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_4__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:17:49.557012+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:17:49.559191+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:17:49.560928+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:17:49.563021+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:17:49.566846+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:17:49.568599+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:17:49.570331+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 4 accuracy:  0.9208791208791208\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220112 0.00219559 0.00219559 0.00220568 0.00219559 0.00220127\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00221178\n",
      " 0.00220067 0.00219559 0.00220622 0.00219559 0.00219559 0.00219559\n",
      " 0.00221178 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220112 0.00220636 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220636 0.00219559 0.00220067 0.00221065 0.00220099\n",
      " 0.00219559 0.00219559 0.00219559 0.00220127 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220622 0.00219559 0.00220681 0.00219559\n",
      " 0.00219559 0.00219559 0.00221093 0.00220014 0.00219559 0.00220112\n",
      " 0.00220099 0.00219559 0.00220067 0.00219559 0.00220112 0.00219559\n",
      " 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220112 0.00220014 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220112 0.00220014 0.00219559 0.00221164 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220608 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220555 0.00219559 0.00221192 0.00220523 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220067 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220067 0.00219559 0.00220127 0.00220653 0.00219559\n",
      " 0.00219559 0.00220127 0.00219559 0.00220014 0.00219559 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00220099 0.00219559 0.00221682\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220112 0.00219559 0.00219559 0.00220067 0.00219559 0.00219559\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00220099\n",
      " 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00222194 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00220014 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00221192 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00220112 0.00221164 0.00220014\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220555 0.00219559 0.00220099 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220067 0.00219559 0.00220099 0.00219559\n",
      " 0.00220608 0.00220127 0.00220523 0.00219559 0.00220099 0.00219559\n",
      " 0.00220127 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00219559 0.00219559 0.00219559 0.00221093 0.00219559 0.00220099\n",
      " 0.00219559 0.00221178 0.00220555 0.00219559 0.00219559 0.00221093\n",
      " 0.00220568 0.00220014 0.00219559 0.00219559 0.00221093 0.00220099\n",
      " 0.00219559 0.00220067 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220014 0.00219559 0.00220067 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00219559 0.00220608 0.00219559\n",
      " 0.00219559 0.00219559 0.00220523 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00220681 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220127 0.00219559 0.00220636 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220099 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00220099 0.00219559\n",
      " 0.00221192 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220112 0.00219559 0.00220523 0.00219559 0.00220099\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220112\n",
      " 0.00219559 0.00219559 0.00220681 0.00220014 0.00219559 0.00220622\n",
      " 0.00220681 0.00219559 0.00219559 0.00219559 0.00220014 0.00220523\n",
      " 0.00219559 0.00220523 0.00219559 0.0022111  0.00220014 0.00219559\n",
      " 0.00219559 0.00219559 0.00220555 0.00220014 0.00219559 0.00220636\n",
      " 0.00219559 0.00220014 0.00220681 0.00219559 0.00220014 0.00220099\n",
      " 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220127\n",
      " 0.00220112 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220099 0.00219559 0.00219559 0.00220112 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220523 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220608\n",
      " 0.00219559 0.00219559 0.00220099 0.00219559 0.00219559]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024531187774958023\n",
      "Boosting iter: 6 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 6/20\n",
      "random state: 5\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220112 0.00219559 0.00219559 0.00220568 0.00219559 0.00220127\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00221178\n",
      " 0.00220067 0.00219559 0.00220622 0.00219559 0.00219559 0.00219559\n",
      " 0.00221178 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220112 0.00220636 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220636 0.00219559 0.00220067 0.00221065 0.00220099\n",
      " 0.00219559 0.00219559 0.00219559 0.00220127 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220622 0.00219559 0.00220681 0.00219559\n",
      " 0.00219559 0.00219559 0.00221093 0.00220014 0.00219559 0.00220112\n",
      " 0.00220099 0.00219559 0.00220067 0.00219559 0.00220112 0.00219559\n",
      " 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220112 0.00220014 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220112 0.00220014 0.00219559 0.00221164 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220608 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220555 0.00219559 0.00221192 0.00220523 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220067 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220067 0.00219559 0.00220127 0.00220653 0.00219559\n",
      " 0.00219559 0.00220127 0.00219559 0.00220014 0.00219559 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00220099 0.00219559 0.00221682\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220112 0.00219559 0.00219559 0.00220067 0.00219559 0.00219559\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00220099\n",
      " 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00222194 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00220014 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00221192 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00220112 0.00221164 0.00220014\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220555 0.00219559 0.00220099 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220067 0.00219559 0.00220099 0.00219559\n",
      " 0.00220608 0.00220127 0.00220523 0.00219559 0.00220099 0.00219559\n",
      " 0.00220127 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00219559 0.00219559 0.00219559 0.00221093 0.00219559 0.00220099\n",
      " 0.00219559 0.00221178 0.00220555 0.00219559 0.00219559 0.00221093\n",
      " 0.00220568 0.00220014 0.00219559 0.00219559 0.00221093 0.00220099\n",
      " 0.00219559 0.00220067 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220014 0.00219559 0.00220067 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00219559 0.00220608 0.00219559\n",
      " 0.00219559 0.00219559 0.00220523 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00220681 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220127 0.00219559 0.00220636 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220099 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00220099 0.00219559\n",
      " 0.00221192 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220112 0.00219559 0.00220523 0.00219559 0.00220099\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220112\n",
      " 0.00219559 0.00219559 0.00220681 0.00220014 0.00219559 0.00220622\n",
      " 0.00220681 0.00219559 0.00219559 0.00219559 0.00220014 0.00220523\n",
      " 0.00219559 0.00220523 0.00219559 0.0022111  0.00220014 0.00219559\n",
      " 0.00219559 0.00219559 0.00220555 0.00220014 0.00219559 0.00220636\n",
      " 0.00219559 0.00220014 0.00220681 0.00219559 0.00220014 0.00220099\n",
      " 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220127\n",
      " 0.00220112 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220099 0.00219559 0.00219559 0.00220112 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220523 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220608\n",
      " 0.00219559 0.00219559 0.00220099 0.00219559 0.00219559]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 152, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 293 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 158  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 123  59  25 137\n",
      " 119 207 310 316 129 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True,  True, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([215, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████████████████████████████████████████████████████████████▉                                                                                   | 949/2000 [02:08<02:21,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_5__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:20:09.211511+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:20:09.213923+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:20:09.215790+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:20:09.218005+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:20:09.221838+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:20:09.223755+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:20:09.225650+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 5 accuracy:  0.9032967032967033\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220557 0.00219512 0.00219512 0.00220521 0.00219512 0.00220079\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.0022113\n",
      " 0.00220511 0.00219512 0.00221067 0.00219512 0.00219512 0.00219512\n",
      " 0.0022113  0.00220002 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00220079 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220571 0.00219512 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00220065 0.00220588 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00221081 0.00219512 0.00220511 0.00221511 0.00220051\n",
      " 0.00219512 0.00219512 0.00219512 0.00220079 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00221067 0.00219512 0.00220634 0.00219512\n",
      " 0.00219512 0.00220002 0.00221045 0.00219967 0.00219512 0.00220065\n",
      " 0.00220543 0.00219512 0.0022002  0.00219512 0.00220065 0.00219512\n",
      " 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220065 0.00219967 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220557 0.00220458 0.00219512 0.0022161  0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219967\n",
      " 0.00219967 0.00219512 0.00219512 0.00219512 0.00220002 0.00219512\n",
      " 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.0022056  0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220507 0.00219512 0.00221144 0.00220968 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.0022002  0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220511 0.00219512 0.00220079 0.00220605 0.00219512\n",
      " 0.00219512 0.00220079 0.00219512 0.00219967 0.00219512 0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00220051 0.00219512 0.00221634\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220051 0.00219512 0.00220002 0.00219512 0.00219512 0.00219512\n",
      " 0.00220065 0.00219512 0.00219512 0.0022002  0.00219512 0.00219512\n",
      " 0.00220543 0.00219512 0.00219512 0.00219512 0.00219512 0.00220051\n",
      " 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219967\n",
      " 0.00222643 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220458 0.00219967 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00221144 0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00220065 0.0022161  0.00219967\n",
      " 0.00220543 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220507 0.00219512 0.00220051 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.0022002  0.00219512 0.00220051 0.00219512\n",
      " 0.0022056  0.00220571 0.00220968 0.00219512 0.00220051 0.00219512\n",
      " 0.00220571 0.00219512 0.00219512 0.00219512 0.00219512 0.00220458\n",
      " 0.00219512 0.00219512 0.00219512 0.00221539 0.00219512 0.00220051\n",
      " 0.00220002 0.00221624 0.00220507 0.00219512 0.00219512 0.00221539\n",
      " 0.00220521 0.00219967 0.00219512 0.00219512 0.00221045 0.00220051\n",
      " 0.00219512 0.0022002  0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219967 0.00219512 0.0022002  0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00219512 0.0022056  0.00219512\n",
      " 0.00219512 0.00219512 0.00220475 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00220634 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00220571 0.00219512 0.00221081 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220051 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00220051 0.00219512\n",
      " 0.00221144 0.00219512 0.00219512 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00220065 0.00219512 0.00220475 0.00219512 0.00220051\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00220065\n",
      " 0.00219512 0.00219512 0.00221127 0.00219967 0.00219512 0.00220574\n",
      " 0.00221127 0.00219512 0.00219512 0.00219512 0.00219967 0.00220475\n",
      " 0.00219512 0.00220475 0.00219512 0.00221062 0.00219967 0.00219512\n",
      " 0.00219512 0.00219512 0.00221    0.00219967 0.00219512 0.00220588\n",
      " 0.00219512 0.00219967 0.00220634 0.00219512 0.00219967 0.00220051\n",
      " 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00220079\n",
      " 0.00220065 0.00219512 0.00220079 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220051 0.00219512 0.00219512 0.00220065 0.00220002\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220968 0.00220002 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00221053\n",
      " 0.00219512 0.00219512 0.00220051 0.00219512 0.00219512]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0022319271049430866\n",
      "Boosting iter: 7 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 7/20\n",
      "random state: 6\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220557 0.00219512 0.00219512 0.00220521 0.00219512 0.00220079\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.0022113\n",
      " 0.00220511 0.00219512 0.00221067 0.00219512 0.00219512 0.00219512\n",
      " 0.0022113  0.00220002 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00220079 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220571 0.00219512 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00220065 0.00220588 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00221081 0.00219512 0.00220511 0.00221511 0.00220051\n",
      " 0.00219512 0.00219512 0.00219512 0.00220079 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00221067 0.00219512 0.00220634 0.00219512\n",
      " 0.00219512 0.00220002 0.00221045 0.00219967 0.00219512 0.00220065\n",
      " 0.00220543 0.00219512 0.0022002  0.00219512 0.00220065 0.00219512\n",
      " 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220065 0.00219967 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220557 0.00220458 0.00219512 0.0022161  0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219967\n",
      " 0.00219967 0.00219512 0.00219512 0.00219512 0.00220002 0.00219512\n",
      " 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.0022056  0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220507 0.00219512 0.00221144 0.00220968 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.0022002  0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220511 0.00219512 0.00220079 0.00220605 0.00219512\n",
      " 0.00219512 0.00220079 0.00219512 0.00219967 0.00219512 0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00220051 0.00219512 0.00221634\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220051 0.00219512 0.00220002 0.00219512 0.00219512 0.00219512\n",
      " 0.00220065 0.00219512 0.00219512 0.0022002  0.00219512 0.00219512\n",
      " 0.00220543 0.00219512 0.00219512 0.00219512 0.00219512 0.00220051\n",
      " 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219967\n",
      " 0.00222643 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220458 0.00219967 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00221144 0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00220065 0.0022161  0.00219967\n",
      " 0.00220543 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220507 0.00219512 0.00220051 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.0022002  0.00219512 0.00220051 0.00219512\n",
      " 0.0022056  0.00220571 0.00220968 0.00219512 0.00220051 0.00219512\n",
      " 0.00220571 0.00219512 0.00219512 0.00219512 0.00219512 0.00220458\n",
      " 0.00219512 0.00219512 0.00219512 0.00221539 0.00219512 0.00220051\n",
      " 0.00220002 0.00221624 0.00220507 0.00219512 0.00219512 0.00221539\n",
      " 0.00220521 0.00219967 0.00219512 0.00219512 0.00221045 0.00220051\n",
      " 0.00219512 0.0022002  0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219967 0.00219512 0.0022002  0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00219512 0.0022056  0.00219512\n",
      " 0.00219512 0.00219512 0.00220475 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00220634 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00220571 0.00219512 0.00221081 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220051 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00220051 0.00219512\n",
      " 0.00221144 0.00219512 0.00219512 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00220065 0.00219512 0.00220475 0.00219512 0.00220051\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00220065\n",
      " 0.00219512 0.00219512 0.00221127 0.00219967 0.00219512 0.00220574\n",
      " 0.00221127 0.00219512 0.00219512 0.00219512 0.00219967 0.00220475\n",
      " 0.00219512 0.00220475 0.00219512 0.00221062 0.00219967 0.00219512\n",
      " 0.00219512 0.00219512 0.00221    0.00219967 0.00219512 0.00220588\n",
      " 0.00219512 0.00219967 0.00220634 0.00219512 0.00219967 0.00220051\n",
      " 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00220079\n",
      " 0.00220065 0.00219512 0.00220079 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220051 0.00219512 0.00219512 0.00220065 0.00220002\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220968 0.00220002 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00221053\n",
      " 0.00219512 0.00219512 0.00220051 0.00219512 0.00219512]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  67 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([214, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████████████████▍                                                                                                                      | 499/2000 [01:03<03:11,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_6__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:21:24.506726+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:21:24.508771+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:21:24.510545+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:21:24.512645+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:21:24.516374+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:21:24.518197+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:21:24.519883+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 6 accuracy:  0.8967032967032967\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220507 0.00219463 0.00219463 0.00220471 0.00219463 0.0022003\n",
      " 0.00219463 0.00219937 0.00219463 0.00219463 0.00219463 0.0022108\n",
      " 0.00220462 0.00219463 0.00221017 0.00219463 0.00219463 0.00219463\n",
      " 0.0022108  0.00219953 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.0022003  0.00219463 0.00219463 0.00219937\n",
      " 0.00219463 0.00220521 0.00219463 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00220016 0.00221015 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00221032 0.00219463 0.00220938 0.00221461 0.00220002\n",
      " 0.00219463 0.00219463 0.00219463 0.00220505 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00221495 0.00219463 0.00220584 0.00219463\n",
      " 0.00219463 0.00219953 0.00220996 0.00219917 0.00219463 0.00220016\n",
      " 0.0022097  0.00219463 0.0021997  0.00219463 0.00220016 0.00219463\n",
      " 0.00219917 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220016 0.00219917 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220507 0.00220885 0.00219463 0.0022156  0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219917\n",
      " 0.00220392 0.00219463 0.00219463 0.00219463 0.00219953 0.00219463\n",
      " 0.00219463 0.00219463 0.00220392 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219937 0.00220987 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220457 0.00219463 0.00221572 0.00221396 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.0021997  0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220462 0.00219463 0.0022003  0.00220556 0.00219463\n",
      " 0.00219463 0.0022003  0.00219463 0.00220392 0.00219463 0.00220392\n",
      " 0.00219463 0.00219463 0.00220016 0.00220002 0.00219463 0.00222063\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220477 0.00219463 0.00219953 0.00219463 0.00219463 0.00219463\n",
      " 0.00220016 0.00219463 0.00219463 0.0021997  0.00219937 0.00219463\n",
      " 0.00220493 0.00219463 0.00219463 0.00219463 0.00219463 0.00220002\n",
      " 0.00219463 0.00220392 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219917\n",
      " 0.00223074 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00220885 0.00220392 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00221094 0.00220392\n",
      " 0.00219463 0.00219463 0.00220016 0.00220016 0.0022156  0.00219917\n",
      " 0.00220493 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220934 0.00219463 0.00220002 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.0021997  0.00219463 0.00220002 0.00219463\n",
      " 0.00220511 0.00220521 0.00220919 0.00219463 0.00220002 0.00219463\n",
      " 0.00220521 0.00219463 0.00219463 0.00219463 0.00219463 0.00220885\n",
      " 0.00219463 0.00219463 0.00219463 0.00221968 0.00219463 0.00220002\n",
      " 0.00219953 0.00221574 0.00220934 0.00219463 0.00219463 0.00221489\n",
      " 0.00220471 0.00219917 0.00219463 0.00219463 0.00221473 0.00220002\n",
      " 0.00219463 0.0021997  0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00220392 0.00219463 0.00220446 0.00220392\n",
      " 0.00219463 0.00219463 0.00220491 0.00219463 0.00220511 0.00219463\n",
      " 0.00219463 0.00219463 0.00220426 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00220584 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00220521 0.00219463 0.00221032 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00220002 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00220002 0.00219463\n",
      " 0.00221572 0.00219463 0.00219463 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00220491 0.00219463 0.00220902 0.00219463 0.00220002\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00220016\n",
      " 0.00219463 0.00219463 0.00221077 0.00220392 0.00219463 0.00221001\n",
      " 0.00221077 0.00219937 0.00219463 0.00219463 0.00219917 0.00220902\n",
      " 0.00219463 0.00220902 0.00219463 0.0022149  0.00219917 0.00219463\n",
      " 0.00219463 0.00219463 0.00221427 0.00219917 0.00219463 0.00220539\n",
      " 0.00219463 0.00219917 0.00220584 0.00219463 0.00220392 0.00220477\n",
      " 0.00219463 0.00219917 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.0022003\n",
      " 0.00220016 0.00219463 0.00220505 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220002 0.00219463 0.00219463 0.00220016 0.00219953\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00221396 0.00219953 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00221003\n",
      " 0.00219463 0.00219463 0.00220002 0.00219463 0.00219463]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0021580214308772787\n",
      "Boosting iter: 8 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 8/20\n",
      "random state: 7\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220507 0.00219463 0.00219463 0.00220471 0.00219463 0.0022003\n",
      " 0.00219463 0.00219937 0.00219463 0.00219463 0.00219463 0.0022108\n",
      " 0.00220462 0.00219463 0.00221017 0.00219463 0.00219463 0.00219463\n",
      " 0.0022108  0.00219953 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.0022003  0.00219463 0.00219463 0.00219937\n",
      " 0.00219463 0.00220521 0.00219463 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00220016 0.00221015 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00221032 0.00219463 0.00220938 0.00221461 0.00220002\n",
      " 0.00219463 0.00219463 0.00219463 0.00220505 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00221495 0.00219463 0.00220584 0.00219463\n",
      " 0.00219463 0.00219953 0.00220996 0.00219917 0.00219463 0.00220016\n",
      " 0.0022097  0.00219463 0.0021997  0.00219463 0.00220016 0.00219463\n",
      " 0.00219917 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220016 0.00219917 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220507 0.00220885 0.00219463 0.0022156  0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219917\n",
      " 0.00220392 0.00219463 0.00219463 0.00219463 0.00219953 0.00219463\n",
      " 0.00219463 0.00219463 0.00220392 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219937 0.00220987 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220457 0.00219463 0.00221572 0.00221396 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.0021997  0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220462 0.00219463 0.0022003  0.00220556 0.00219463\n",
      " 0.00219463 0.0022003  0.00219463 0.00220392 0.00219463 0.00220392\n",
      " 0.00219463 0.00219463 0.00220016 0.00220002 0.00219463 0.00222063\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220477 0.00219463 0.00219953 0.00219463 0.00219463 0.00219463\n",
      " 0.00220016 0.00219463 0.00219463 0.0021997  0.00219937 0.00219463\n",
      " 0.00220493 0.00219463 0.00219463 0.00219463 0.00219463 0.00220002\n",
      " 0.00219463 0.00220392 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219917\n",
      " 0.00223074 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00220885 0.00220392 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00221094 0.00220392\n",
      " 0.00219463 0.00219463 0.00220016 0.00220016 0.0022156  0.00219917\n",
      " 0.00220493 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220934 0.00219463 0.00220002 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.0021997  0.00219463 0.00220002 0.00219463\n",
      " 0.00220511 0.00220521 0.00220919 0.00219463 0.00220002 0.00219463\n",
      " 0.00220521 0.00219463 0.00219463 0.00219463 0.00219463 0.00220885\n",
      " 0.00219463 0.00219463 0.00219463 0.00221968 0.00219463 0.00220002\n",
      " 0.00219953 0.00221574 0.00220934 0.00219463 0.00219463 0.00221489\n",
      " 0.00220471 0.00219917 0.00219463 0.00219463 0.00221473 0.00220002\n",
      " 0.00219463 0.0021997  0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00220392 0.00219463 0.00220446 0.00220392\n",
      " 0.00219463 0.00219463 0.00220491 0.00219463 0.00220511 0.00219463\n",
      " 0.00219463 0.00219463 0.00220426 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00220584 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00220521 0.00219463 0.00221032 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00220002 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00220002 0.00219463\n",
      " 0.00221572 0.00219463 0.00219463 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00220491 0.00219463 0.00220902 0.00219463 0.00220002\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00220016\n",
      " 0.00219463 0.00219463 0.00221077 0.00220392 0.00219463 0.00221001\n",
      " 0.00221077 0.00219937 0.00219463 0.00219463 0.00219917 0.00220902\n",
      " 0.00219463 0.00220902 0.00219463 0.0022149  0.00219917 0.00219463\n",
      " 0.00219463 0.00219463 0.00221427 0.00219917 0.00219463 0.00220539\n",
      " 0.00219463 0.00219917 0.00220584 0.00219463 0.00220392 0.00220477\n",
      " 0.00219463 0.00219917 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.0022003\n",
      " 0.00220016 0.00219463 0.00220505 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220002 0.00219463 0.00219463 0.00220016 0.00219953\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00221396 0.00219953 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00221003\n",
      " 0.00219463 0.00219463 0.00220002 0.00219463 0.00219463]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 158  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([214, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                               | 1399/2000 [03:06<01:20,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_7__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:24:41.848331+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:24:41.850433+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:24:41.852121+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:24:41.854170+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:24:41.857792+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:24:41.859543+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:24:41.861215+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 7 accuracy:  0.9428571428571428\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220472 0.00219427 0.00219427 0.00220436 0.00219427 0.00219994\n",
      " 0.00219427 0.00219901 0.00219427 0.00219427 0.00219427 0.00221045\n",
      " 0.00220426 0.00219427 0.00221601 0.00219427 0.00219427 0.00219427\n",
      " 0.00221045 0.00219918 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219994 0.00219427 0.00219427 0.00219901\n",
      " 0.00219427 0.00220486 0.00219427 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.0021998  0.0022098  0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00220996 0.00219427 0.00220903 0.00222046 0.00219966\n",
      " 0.00219427 0.00219427 0.00219427 0.0022047  0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.0022208  0.00219427 0.00220549 0.00219427\n",
      " 0.00219427 0.00220534 0.0022096  0.00219882 0.00219427 0.0021998\n",
      " 0.00220934 0.00219427 0.00219935 0.00219427 0.0021998  0.00219427\n",
      " 0.00219882 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.0021998  0.00219882 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220472 0.00220849 0.00219427 0.00222145 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219882\n",
      " 0.00220357 0.00219427 0.00219427 0.00219427 0.00219918 0.00219427\n",
      " 0.00219427 0.00219427 0.00220975 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219901 0.00220951 0.00219427 0.00220042 0.00219427\n",
      " 0.00219427 0.00220422 0.00219427 0.00221536 0.0022136  0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219935 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00220426 0.00219427 0.00220611 0.00220521 0.00219427\n",
      " 0.00219427 0.00219994 0.00219427 0.00220357 0.00219427 0.00220357\n",
      " 0.00219427 0.00219427 0.00220597 0.00220583 0.00219427 0.00222649\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220442 0.00219427 0.00219918 0.00219427 0.00219427 0.00219427\n",
      " 0.0021998  0.00219427 0.00219427 0.00219935 0.00219901 0.00219427\n",
      " 0.00220458 0.00219427 0.00219427 0.00219427 0.00219427 0.00220583\n",
      " 0.00219427 0.00220357 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219882\n",
      " 0.00223663 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00220849 0.00220357 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00221059 0.00220357\n",
      " 0.00219427 0.00219427 0.0021998  0.0021998  0.00222145 0.00219882\n",
      " 0.00220458 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220898 0.00219427 0.00219966 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219935 0.00219427 0.00219966 0.00219427\n",
      " 0.00220475 0.00221104 0.00220883 0.00219427 0.00219966 0.00219427\n",
      " 0.00220486 0.00219427 0.00219427 0.00219427 0.00219427 0.00220849\n",
      " 0.00219427 0.00219427 0.00220042 0.00221932 0.00219427 0.00220583\n",
      " 0.00219918 0.0022216  0.00220898 0.00219427 0.00219427 0.00221454\n",
      " 0.00220436 0.00219882 0.00219427 0.00219427 0.00221437 0.00219966\n",
      " 0.00219427 0.00219935 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00220357 0.00219427 0.0022041  0.00220357\n",
      " 0.00219427 0.00219427 0.00220455 0.00219427 0.00220475 0.00219427\n",
      " 0.00219427 0.00219427 0.00221008 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00220549 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00221104 0.00219427 0.00221615 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219966 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219966 0.00219427\n",
      " 0.00221536 0.00220042 0.00219427 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00220455 0.00219427 0.00220867 0.00219427 0.00219966\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.0021998\n",
      " 0.00219427 0.00219427 0.00221041 0.00220357 0.00219427 0.00220965\n",
      " 0.00221661 0.00219901 0.00219427 0.00219427 0.00219882 0.00220867\n",
      " 0.00220042 0.00221486 0.00219427 0.00222075 0.00219882 0.00219427\n",
      " 0.00219427 0.00219427 0.00221392 0.00219882 0.00219427 0.00220503\n",
      " 0.00219427 0.00219882 0.00220549 0.00219427 0.00220357 0.00220442\n",
      " 0.00219427 0.00219882 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219994\n",
      " 0.0021998  0.00219427 0.0022047  0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219966 0.00219427 0.00219427 0.0021998  0.00219918\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.0022136  0.00219918 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00220968\n",
      " 0.00219427 0.00219427 0.00219966 0.00219427 0.00219427]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0027989634885745187\n",
      "Boosting iter: 9 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 9/20\n",
      "random state: 8\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220472 0.00219427 0.00219427 0.00220436 0.00219427 0.00219994\n",
      " 0.00219427 0.00219901 0.00219427 0.00219427 0.00219427 0.00221045\n",
      " 0.00220426 0.00219427 0.00221601 0.00219427 0.00219427 0.00219427\n",
      " 0.00221045 0.00219918 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219994 0.00219427 0.00219427 0.00219901\n",
      " 0.00219427 0.00220486 0.00219427 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.0021998  0.0022098  0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00220996 0.00219427 0.00220903 0.00222046 0.00219966\n",
      " 0.00219427 0.00219427 0.00219427 0.0022047  0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.0022208  0.00219427 0.00220549 0.00219427\n",
      " 0.00219427 0.00220534 0.0022096  0.00219882 0.00219427 0.0021998\n",
      " 0.00220934 0.00219427 0.00219935 0.00219427 0.0021998  0.00219427\n",
      " 0.00219882 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.0021998  0.00219882 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220472 0.00220849 0.00219427 0.00222145 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219882\n",
      " 0.00220357 0.00219427 0.00219427 0.00219427 0.00219918 0.00219427\n",
      " 0.00219427 0.00219427 0.00220975 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219901 0.00220951 0.00219427 0.00220042 0.00219427\n",
      " 0.00219427 0.00220422 0.00219427 0.00221536 0.0022136  0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219935 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00220426 0.00219427 0.00220611 0.00220521 0.00219427\n",
      " 0.00219427 0.00219994 0.00219427 0.00220357 0.00219427 0.00220357\n",
      " 0.00219427 0.00219427 0.00220597 0.00220583 0.00219427 0.00222649\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220442 0.00219427 0.00219918 0.00219427 0.00219427 0.00219427\n",
      " 0.0021998  0.00219427 0.00219427 0.00219935 0.00219901 0.00219427\n",
      " 0.00220458 0.00219427 0.00219427 0.00219427 0.00219427 0.00220583\n",
      " 0.00219427 0.00220357 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219882\n",
      " 0.00223663 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00220849 0.00220357 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00221059 0.00220357\n",
      " 0.00219427 0.00219427 0.0021998  0.0021998  0.00222145 0.00219882\n",
      " 0.00220458 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220898 0.00219427 0.00219966 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219935 0.00219427 0.00219966 0.00219427\n",
      " 0.00220475 0.00221104 0.00220883 0.00219427 0.00219966 0.00219427\n",
      " 0.00220486 0.00219427 0.00219427 0.00219427 0.00219427 0.00220849\n",
      " 0.00219427 0.00219427 0.00220042 0.00221932 0.00219427 0.00220583\n",
      " 0.00219918 0.0022216  0.00220898 0.00219427 0.00219427 0.00221454\n",
      " 0.00220436 0.00219882 0.00219427 0.00219427 0.00221437 0.00219966\n",
      " 0.00219427 0.00219935 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00220357 0.00219427 0.0022041  0.00220357\n",
      " 0.00219427 0.00219427 0.00220455 0.00219427 0.00220475 0.00219427\n",
      " 0.00219427 0.00219427 0.00221008 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00220549 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00221104 0.00219427 0.00221615 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219966 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219966 0.00219427\n",
      " 0.00221536 0.00220042 0.00219427 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00220455 0.00219427 0.00220867 0.00219427 0.00219966\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.0021998\n",
      " 0.00219427 0.00219427 0.00221041 0.00220357 0.00219427 0.00220965\n",
      " 0.00221661 0.00219901 0.00219427 0.00219427 0.00219882 0.00220867\n",
      " 0.00220042 0.00221486 0.00219427 0.00222075 0.00219882 0.00219427\n",
      " 0.00219427 0.00219427 0.00221392 0.00219882 0.00219427 0.00220503\n",
      " 0.00219427 0.00219882 0.00220549 0.00219427 0.00220357 0.00220442\n",
      " 0.00219427 0.00219882 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219994\n",
      " 0.0021998  0.00219427 0.0022047  0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219966 0.00219427 0.00219427 0.0021998  0.00219918\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.0022136  0.00219918 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00220968\n",
      " 0.00219427 0.00219427 0.00219966 0.00219427 0.00219427]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 152, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 158  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 123  59  25 137\n",
      " 119 207 310 316 129 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True,  True, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([215, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████████████████████████████████████                                                                                       | 899/2000 [02:00<02:27,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_8__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:26:53.705780+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:26:53.707867+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:26:53.709545+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:26:53.711596+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:26:53.715247+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:26:53.716945+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:26:53.718639+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 8 accuracy:  0.9054945054945055\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220425 0.0021938  0.0021938  0.00220389 0.0021938  0.00219947\n",
      " 0.0021938  0.00219854 0.0021938  0.0021938  0.0021938  0.00221497\n",
      " 0.00220877 0.0021938  0.00222054 0.0021938  0.0021938  0.0021938\n",
      " 0.00221497 0.00219871 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219947 0.0021938  0.0021938  0.00219854\n",
      " 0.0021938  0.00220439 0.0021938  0.0021938  0.0021938  0.00219871\n",
      " 0.0021938  0.0021938  0.0022043  0.00220932 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219876 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00221448 0.0021938  0.00220855 0.00221999 0.00219919\n",
      " 0.0021938  0.0021938  0.0021938  0.00220422 0.0021938  0.00219871\n",
      " 0.00219876 0.0021938  0.00222534 0.0021938  0.00221    0.0021938\n",
      " 0.0021938  0.00220985 0.00220913 0.00219835 0.00219876 0.00219933\n",
      " 0.00220887 0.0021938  0.00219888 0.0021938  0.0022043  0.0021938\n",
      " 0.00219835 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219933 0.00219835 0.0021938  0.0021938  0.00220367\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00220922 0.00220802 0.0021938  0.002226   0.0021938  0.0021938\n",
      " 0.0021938  0.00219876 0.0021938  0.0021938  0.0021938  0.00219835\n",
      " 0.0022031  0.0021938  0.0021938  0.0021938  0.00219871 0.0021938\n",
      " 0.0021938  0.0021938  0.00220927 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219854 0.00220904 0.00219876 0.00219995 0.0021938\n",
      " 0.0021938  0.00220375 0.0021938  0.00221989 0.00221313 0.00219876\n",
      " 0.00219876 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00219888 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00220379 0.0021938  0.00220564 0.00220473 0.0021938\n",
      " 0.0021938  0.00219947 0.0021938  0.0022031  0.0021938  0.0022031\n",
      " 0.0021938  0.0021938  0.00221048 0.00220536 0.0021938  0.00223104\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00220394 0.0021938  0.00219871 0.0021938  0.0021938  0.0021938\n",
      " 0.00219933 0.0021938  0.0021938  0.00219888 0.00219854 0.0021938\n",
      " 0.00220908 0.0021938  0.0021938  0.0021938  0.0021938  0.00220536\n",
      " 0.0021938  0.0022031  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219835\n",
      " 0.0022412  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00220802 0.0022031  0.0021938\n",
      " 0.00219876 0.0021938  0.0021938  0.0021938  0.00221012 0.0022031\n",
      " 0.0021938  0.0021938  0.0022043  0.00219933 0.002226   0.00219835\n",
      " 0.00220411 0.0021938  0.0021938  0.0021938  0.00219876 0.0021938\n",
      " 0.00220851 0.0021938  0.00219919 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219888 0.0021938  0.00220416 0.0021938\n",
      " 0.00220428 0.00221556 0.00220836 0.0021938  0.00219919 0.0021938\n",
      " 0.00220439 0.0021938  0.0021938  0.0021938  0.0021938  0.00220802\n",
      " 0.0021938  0.0021938  0.00220492 0.00221885 0.0021938  0.00221034\n",
      " 0.00220367 0.00222112 0.00220851 0.0021938  0.0021938  0.00221406\n",
      " 0.00220389 0.00219835 0.0021938  0.0021938  0.0022139  0.00219919\n",
      " 0.0021938  0.00219888 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0022031  0.0021938  0.00220363 0.0022031\n",
      " 0.0021938  0.0021938  0.00220408 0.0021938  0.00220428 0.0021938\n",
      " 0.0021938  0.0021938  0.00220961 0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.00220501 0.0021938  0.00219835 0.0021938  0.00219876\n",
      " 0.0021938  0.0021938  0.00221556 0.0021938  0.00222068 0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00220416 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.00219919 0.0021938\n",
      " 0.00221489 0.00219995 0.0021938  0.0021938  0.0021938  0.00219871\n",
      " 0.0021938  0.00220408 0.0021938  0.00220819 0.0021938  0.00219919\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219933\n",
      " 0.0021938  0.0021938  0.00220994 0.0022031  0.0021938  0.00221417\n",
      " 0.00221614 0.00220351 0.0021938  0.0021938  0.00219835 0.00220819\n",
      " 0.00219995 0.00221438 0.0021938  0.00222028 0.00219835 0.0021938\n",
      " 0.0021938  0.0021938  0.00221344 0.00219835 0.0021938  0.00220456\n",
      " 0.0021938  0.00219835 0.00220501 0.0021938  0.0022031  0.00220394\n",
      " 0.0021938  0.00219835 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219947\n",
      " 0.00219933 0.0021938  0.00220422 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219919 0.0021938  0.0021938  0.00219933 0.00219871\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00221813 0.00220367 0.00219876\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0022092\n",
      " 0.0021938  0.0021938  0.00219919 0.0021938  0.0021938 ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002256159830820475\n",
      "Boosting iter: 10 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 10/20\n",
      "random state: 9\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220425 0.0021938  0.0021938  0.00220389 0.0021938  0.00219947\n",
      " 0.0021938  0.00219854 0.0021938  0.0021938  0.0021938  0.00221497\n",
      " 0.00220877 0.0021938  0.00222054 0.0021938  0.0021938  0.0021938\n",
      " 0.00221497 0.00219871 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219947 0.0021938  0.0021938  0.00219854\n",
      " 0.0021938  0.00220439 0.0021938  0.0021938  0.0021938  0.00219871\n",
      " 0.0021938  0.0021938  0.0022043  0.00220932 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219876 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00221448 0.0021938  0.00220855 0.00221999 0.00219919\n",
      " 0.0021938  0.0021938  0.0021938  0.00220422 0.0021938  0.00219871\n",
      " 0.00219876 0.0021938  0.00222534 0.0021938  0.00221    0.0021938\n",
      " 0.0021938  0.00220985 0.00220913 0.00219835 0.00219876 0.00219933\n",
      " 0.00220887 0.0021938  0.00219888 0.0021938  0.0022043  0.0021938\n",
      " 0.00219835 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219933 0.00219835 0.0021938  0.0021938  0.00220367\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00220922 0.00220802 0.0021938  0.002226   0.0021938  0.0021938\n",
      " 0.0021938  0.00219876 0.0021938  0.0021938  0.0021938  0.00219835\n",
      " 0.0022031  0.0021938  0.0021938  0.0021938  0.00219871 0.0021938\n",
      " 0.0021938  0.0021938  0.00220927 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219854 0.00220904 0.00219876 0.00219995 0.0021938\n",
      " 0.0021938  0.00220375 0.0021938  0.00221989 0.00221313 0.00219876\n",
      " 0.00219876 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00219888 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00220379 0.0021938  0.00220564 0.00220473 0.0021938\n",
      " 0.0021938  0.00219947 0.0021938  0.0022031  0.0021938  0.0022031\n",
      " 0.0021938  0.0021938  0.00221048 0.00220536 0.0021938  0.00223104\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00220394 0.0021938  0.00219871 0.0021938  0.0021938  0.0021938\n",
      " 0.00219933 0.0021938  0.0021938  0.00219888 0.00219854 0.0021938\n",
      " 0.00220908 0.0021938  0.0021938  0.0021938  0.0021938  0.00220536\n",
      " 0.0021938  0.0022031  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219835\n",
      " 0.0022412  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00220802 0.0022031  0.0021938\n",
      " 0.00219876 0.0021938  0.0021938  0.0021938  0.00221012 0.0022031\n",
      " 0.0021938  0.0021938  0.0022043  0.00219933 0.002226   0.00219835\n",
      " 0.00220411 0.0021938  0.0021938  0.0021938  0.00219876 0.0021938\n",
      " 0.00220851 0.0021938  0.00219919 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219888 0.0021938  0.00220416 0.0021938\n",
      " 0.00220428 0.00221556 0.00220836 0.0021938  0.00219919 0.0021938\n",
      " 0.00220439 0.0021938  0.0021938  0.0021938  0.0021938  0.00220802\n",
      " 0.0021938  0.0021938  0.00220492 0.00221885 0.0021938  0.00221034\n",
      " 0.00220367 0.00222112 0.00220851 0.0021938  0.0021938  0.00221406\n",
      " 0.00220389 0.00219835 0.0021938  0.0021938  0.0022139  0.00219919\n",
      " 0.0021938  0.00219888 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0022031  0.0021938  0.00220363 0.0022031\n",
      " 0.0021938  0.0021938  0.00220408 0.0021938  0.00220428 0.0021938\n",
      " 0.0021938  0.0021938  0.00220961 0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.00220501 0.0021938  0.00219835 0.0021938  0.00219876\n",
      " 0.0021938  0.0021938  0.00221556 0.0021938  0.00222068 0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00220416 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.00219919 0.0021938\n",
      " 0.00221489 0.00219995 0.0021938  0.0021938  0.0021938  0.00219871\n",
      " 0.0021938  0.00220408 0.0021938  0.00220819 0.0021938  0.00219919\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219933\n",
      " 0.0021938  0.0021938  0.00220994 0.0022031  0.0021938  0.00221417\n",
      " 0.00221614 0.00220351 0.0021938  0.0021938  0.00219835 0.00220819\n",
      " 0.00219995 0.00221438 0.0021938  0.00222028 0.00219835 0.0021938\n",
      " 0.0021938  0.0021938  0.00221344 0.00219835 0.0021938  0.00220456\n",
      " 0.0021938  0.00219835 0.00220501 0.0021938  0.0022031  0.00220394\n",
      " 0.0021938  0.00219835 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219947\n",
      " 0.00219933 0.0021938  0.00220422 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219919 0.0021938  0.0021938  0.00219933 0.00219871\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00221813 0.00220367 0.00219876\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0022092\n",
      " 0.0021938  0.0021938  0.00219919 0.0021938  0.0021938 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([212, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 1949/2000 [04:23<00:06,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_9__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:31:28.116173+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:31:28.118307+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:31:28.120048+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:31:28.122156+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:31:28.125918+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:31:28.127715+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:31:28.129425+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 9 accuracy:  0.9428571428571428\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220389 0.00219345 0.00219345 0.00220353 0.00219345 0.00219912\n",
      " 0.00219345 0.00219819 0.00219345 0.00219345 0.00219345 0.00221461\n",
      " 0.0022146  0.00219345 0.0022264  0.00219345 0.00219345 0.00219345\n",
      " 0.00221461 0.00219835 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219912 0.00219345 0.00219345 0.00220434\n",
      " 0.00219345 0.00220403 0.00219345 0.00219345 0.00219345 0.00219835\n",
      " 0.00219345 0.00219345 0.00221011 0.00220897 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.0021984  0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00221412 0.00219345 0.0022082  0.00221963 0.00219884\n",
      " 0.00219345 0.00219345 0.00219345 0.00220387 0.00219345 0.00219835\n",
      " 0.0021984  0.00219345 0.00223121 0.00219345 0.00220964 0.00219345\n",
      " 0.00219345 0.00220949 0.00220877 0.00219799 0.0021984  0.00219898\n",
      " 0.00220851 0.00219345 0.00219852 0.00219345 0.00220394 0.00219345\n",
      " 0.00219799 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219898 0.00219799 0.00219345 0.00219345 0.00220949\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00220887 0.00220767 0.00219345 0.00223187 0.00219345 0.00219345\n",
      " 0.00219345 0.0021984  0.00219345 0.00219345 0.00219345 0.00219799\n",
      " 0.00220274 0.00219345 0.00219345 0.00219345 0.00219835 0.00219345\n",
      " 0.00219345 0.00219345 0.0022151  0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219819 0.00221487 0.0021984  0.0021996  0.00219345\n",
      " 0.00219345 0.00220339 0.00219345 0.00221954 0.00221277 0.0021984\n",
      " 0.0021984  0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219852 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00220961 0.00219345 0.00220528 0.00220438 0.00219345\n",
      " 0.00219345 0.00219912 0.00219345 0.00220274 0.00219345 0.00220274\n",
      " 0.00219345 0.00219345 0.00221012 0.002205   0.00219345 0.00223693\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00220359 0.00219345 0.00219835 0.00219345 0.00219345 0.00219345\n",
      " 0.00219898 0.00219345 0.00219345 0.00219852 0.00219819 0.00219345\n",
      " 0.00220873 0.00219345 0.00219345 0.00219345 0.00219345 0.002205\n",
      " 0.00219345 0.00220274 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219799\n",
      " 0.00224712 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00221385 0.00220274 0.00219345\n",
      " 0.0021984  0.00219345 0.00219345 0.00219345 0.00220976 0.00220891\n",
      " 0.00219345 0.00219345 0.00220394 0.00219898 0.00222564 0.00219799\n",
      " 0.00220375 0.00219345 0.00219345 0.00219345 0.0021984  0.00219345\n",
      " 0.00220815 0.00219345 0.00219884 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219852 0.00219345 0.0022038  0.00219345\n",
      " 0.00220392 0.0022214  0.002208   0.00219345 0.00219884 0.00219345\n",
      " 0.00220403 0.00219345 0.00219345 0.00219345 0.00219345 0.00220767\n",
      " 0.00219345 0.00219345 0.00220457 0.0022247  0.00219345 0.00220998\n",
      " 0.00220332 0.00222076 0.00220815 0.00219345 0.00219345 0.00221371\n",
      " 0.00220353 0.00219799 0.00219345 0.00219345 0.00221974 0.00219884\n",
      " 0.00219345 0.00219852 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00220891 0.00219345 0.00220327 0.00220274\n",
      " 0.00219345 0.00219345 0.00220373 0.00219345 0.00220392 0.00219345\n",
      " 0.00219345 0.00219345 0.00220925 0.00219799 0.00219345 0.00219345\n",
      " 0.00219345 0.00220466 0.00219345 0.00219799 0.00219345 0.0021984\n",
      " 0.00219345 0.00219345 0.0022214  0.00219345 0.00222033 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00220415 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.0022038  0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219799 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219884 0.00219345\n",
      " 0.00221453 0.0021996  0.00219345 0.00219345 0.00219345 0.00219835\n",
      " 0.00219345 0.00220373 0.00219345 0.00220784 0.00219345 0.00219884\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219898\n",
      " 0.00219345 0.00219345 0.00220959 0.00220274 0.00219345 0.00221381\n",
      " 0.00222198 0.00220315 0.00219345 0.00219345 0.00219799 0.00220784\n",
      " 0.0021996  0.00222023 0.00219345 0.00222614 0.00219799 0.00219345\n",
      " 0.00219345 0.00219345 0.00221309 0.00219799 0.00219345 0.00220421\n",
      " 0.00219345 0.00219799 0.00220466 0.00219345 0.00220891 0.00220359\n",
      " 0.00219345 0.00219799 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219912\n",
      " 0.00219898 0.00219345 0.00220387 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219884 0.00219345 0.00219345 0.00219898 0.00219835\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00222398 0.00220332 0.0021984\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00221503\n",
      " 0.00219345 0.00219345 0.00219884 0.00219345 0.00219345]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0027960283714454385\n",
      "Boosting iter: 11 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 11/20\n",
      "random state: 10\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220389 0.00219345 0.00219345 0.00220353 0.00219345 0.00219912\n",
      " 0.00219345 0.00219819 0.00219345 0.00219345 0.00219345 0.00221461\n",
      " 0.0022146  0.00219345 0.0022264  0.00219345 0.00219345 0.00219345\n",
      " 0.00221461 0.00219835 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219912 0.00219345 0.00219345 0.00220434\n",
      " 0.00219345 0.00220403 0.00219345 0.00219345 0.00219345 0.00219835\n",
      " 0.00219345 0.00219345 0.00221011 0.00220897 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.0021984  0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00221412 0.00219345 0.0022082  0.00221963 0.00219884\n",
      " 0.00219345 0.00219345 0.00219345 0.00220387 0.00219345 0.00219835\n",
      " 0.0021984  0.00219345 0.00223121 0.00219345 0.00220964 0.00219345\n",
      " 0.00219345 0.00220949 0.00220877 0.00219799 0.0021984  0.00219898\n",
      " 0.00220851 0.00219345 0.00219852 0.00219345 0.00220394 0.00219345\n",
      " 0.00219799 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219898 0.00219799 0.00219345 0.00219345 0.00220949\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00220887 0.00220767 0.00219345 0.00223187 0.00219345 0.00219345\n",
      " 0.00219345 0.0021984  0.00219345 0.00219345 0.00219345 0.00219799\n",
      " 0.00220274 0.00219345 0.00219345 0.00219345 0.00219835 0.00219345\n",
      " 0.00219345 0.00219345 0.0022151  0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219819 0.00221487 0.0021984  0.0021996  0.00219345\n",
      " 0.00219345 0.00220339 0.00219345 0.00221954 0.00221277 0.0021984\n",
      " 0.0021984  0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219852 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00220961 0.00219345 0.00220528 0.00220438 0.00219345\n",
      " 0.00219345 0.00219912 0.00219345 0.00220274 0.00219345 0.00220274\n",
      " 0.00219345 0.00219345 0.00221012 0.002205   0.00219345 0.00223693\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00220359 0.00219345 0.00219835 0.00219345 0.00219345 0.00219345\n",
      " 0.00219898 0.00219345 0.00219345 0.00219852 0.00219819 0.00219345\n",
      " 0.00220873 0.00219345 0.00219345 0.00219345 0.00219345 0.002205\n",
      " 0.00219345 0.00220274 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219799\n",
      " 0.00224712 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00221385 0.00220274 0.00219345\n",
      " 0.0021984  0.00219345 0.00219345 0.00219345 0.00220976 0.00220891\n",
      " 0.00219345 0.00219345 0.00220394 0.00219898 0.00222564 0.00219799\n",
      " 0.00220375 0.00219345 0.00219345 0.00219345 0.0021984  0.00219345\n",
      " 0.00220815 0.00219345 0.00219884 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219852 0.00219345 0.0022038  0.00219345\n",
      " 0.00220392 0.0022214  0.002208   0.00219345 0.00219884 0.00219345\n",
      " 0.00220403 0.00219345 0.00219345 0.00219345 0.00219345 0.00220767\n",
      " 0.00219345 0.00219345 0.00220457 0.0022247  0.00219345 0.00220998\n",
      " 0.00220332 0.00222076 0.00220815 0.00219345 0.00219345 0.00221371\n",
      " 0.00220353 0.00219799 0.00219345 0.00219345 0.00221974 0.00219884\n",
      " 0.00219345 0.00219852 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00220891 0.00219345 0.00220327 0.00220274\n",
      " 0.00219345 0.00219345 0.00220373 0.00219345 0.00220392 0.00219345\n",
      " 0.00219345 0.00219345 0.00220925 0.00219799 0.00219345 0.00219345\n",
      " 0.00219345 0.00220466 0.00219345 0.00219799 0.00219345 0.0021984\n",
      " 0.00219345 0.00219345 0.0022214  0.00219345 0.00222033 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00220415 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.0022038  0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219799 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219884 0.00219345\n",
      " 0.00221453 0.0021996  0.00219345 0.00219345 0.00219345 0.00219835\n",
      " 0.00219345 0.00220373 0.00219345 0.00220784 0.00219345 0.00219884\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219898\n",
      " 0.00219345 0.00219345 0.00220959 0.00220274 0.00219345 0.00221381\n",
      " 0.00222198 0.00220315 0.00219345 0.00219345 0.00219799 0.00220784\n",
      " 0.0021996  0.00222023 0.00219345 0.00222614 0.00219799 0.00219345\n",
      " 0.00219345 0.00219345 0.00221309 0.00219799 0.00219345 0.00220421\n",
      " 0.00219345 0.00219799 0.00220466 0.00219345 0.00220891 0.00220359\n",
      " 0.00219345 0.00219799 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219912\n",
      " 0.00219898 0.00219345 0.00220387 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219884 0.00219345 0.00219345 0.00219898 0.00219835\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00222398 0.00220332 0.0021984\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00221503\n",
      " 0.00219345 0.00219345 0.00219884 0.00219345 0.00219345]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████████████████████████████████                                                                                               | 799/2000 [01:47<02:42,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_10__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:33:27.685927+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:33:27.688516+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:33:27.691665+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:33:27.693930+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:33:27.697611+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:33:27.699343+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:33:27.701031+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 10 accuracy:  0.9142857142857143\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220344 0.002193   0.00219818 0.00220829 0.002193   0.00219867\n",
      " 0.002193   0.00219774 0.002193   0.002193   0.002193   0.00221416\n",
      " 0.00221938 0.002193   0.0022312  0.002193   0.002193   0.002193\n",
      " 0.00221416 0.0021979  0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00219867 0.002193   0.002193   0.00220389\n",
      " 0.002193   0.00220879 0.002193   0.002193   0.002193   0.0021979\n",
      " 0.002193   0.002193   0.00220966 0.00220852 0.002193   0.002193\n",
      " 0.002193   0.002193   0.00219796 0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.0022189  0.002193   0.00220775 0.00221918 0.00219839\n",
      " 0.002193   0.002193   0.002193   0.00220342 0.002193   0.0022031\n",
      " 0.00219796 0.002193   0.00223602 0.002193   0.00221441 0.002193\n",
      " 0.002193   0.00220904 0.00221354 0.00219755 0.00219796 0.00219853\n",
      " 0.00220806 0.002193   0.00219808 0.002193   0.00220349 0.002193\n",
      " 0.00219755 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219853 0.00219755 0.002193   0.002193   0.00220904\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00220842 0.00221243 0.002193   0.00223668 0.002193   0.002193\n",
      " 0.002193   0.00219796 0.002193   0.002193   0.002193   0.00219755\n",
      " 0.00220229 0.002193   0.002193   0.002193   0.0021979  0.002193\n",
      " 0.002193   0.002193   0.00221465 0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219774 0.00221442 0.00219796 0.00219915 0.002193\n",
      " 0.002193   0.00220815 0.002193   0.00221908 0.00221755 0.00219796\n",
      " 0.00219796 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00219808 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.00220916 0.002193   0.00220483 0.00220393 0.002193\n",
      " 0.002193   0.00219867 0.002193   0.00220229 0.002193   0.00220229\n",
      " 0.002193   0.002193   0.00221489 0.00220455 0.002193   0.00224176\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00220314 0.002193   0.0021979  0.002193   0.002193   0.002193\n",
      " 0.00219853 0.002193   0.002193   0.00219808 0.00219774 0.002193\n",
      " 0.00220828 0.002193   0.002193   0.002193   0.002193   0.00220455\n",
      " 0.002193   0.00220229 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219755\n",
      " 0.00225197 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219818\n",
      " 0.002193   0.002193   0.002193   0.0022134  0.00220229 0.002193\n",
      " 0.00219796 0.002193   0.002193   0.002193   0.00221453 0.00220846\n",
      " 0.002193   0.002193   0.00220349 0.00219853 0.00222518 0.00219755\n",
      " 0.0022033  0.002193   0.002193   0.002193   0.00220315 0.002193\n",
      " 0.0022077  0.002193   0.00219839 0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00220327 0.002193   0.00220336 0.002193\n",
      " 0.00220348 0.0022262  0.00220755 0.002193   0.00219839 0.002193\n",
      " 0.00220879 0.002193   0.002193   0.002193   0.002193   0.00221243\n",
      " 0.002193   0.002193   0.00220412 0.0022295  0.002193   0.00220953\n",
      " 0.00220287 0.00222031 0.0022077  0.002193   0.002193   0.00221849\n",
      " 0.00220308 0.00219755 0.002193   0.002193   0.00221929 0.00219839\n",
      " 0.002193   0.00219808 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00220846 0.002193   0.00220283 0.00220229\n",
      " 0.002193   0.002193   0.00220328 0.002193   0.00220348 0.002193\n",
      " 0.002193   0.002193   0.0022088  0.00219755 0.002193   0.002193\n",
      " 0.002193   0.00220421 0.002193   0.00219755 0.002193   0.00219796\n",
      " 0.002193   0.002193   0.00222095 0.002193   0.00222512 0.002193\n",
      " 0.002193   0.002193   0.002193   0.0022037  0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00220336 0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00219755 0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.00220358 0.002193\n",
      " 0.00221931 0.00219915 0.002193   0.002193   0.002193   0.0021979\n",
      " 0.002193   0.00220328 0.002193   0.0022126  0.002193   0.00219839\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219853\n",
      " 0.002193   0.002193   0.00220914 0.0022075  0.002193   0.00221859\n",
      " 0.00222678 0.00220271 0.002193   0.002193   0.00219755 0.00220739\n",
      " 0.00219915 0.00222502 0.002193   0.00223094 0.00219755 0.002193\n",
      " 0.002193   0.002193   0.00221264 0.00219755 0.002193   0.00220896\n",
      " 0.002193   0.00219755 0.00220421 0.002193   0.00220846 0.00220314\n",
      " 0.002193   0.00219755 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219867\n",
      " 0.00219853 0.002193   0.00220342 0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219839 0.002193   0.002193   0.00219853 0.0021979\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00222878 0.00220807 0.00219796\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00221981\n",
      " 0.002193   0.002193   0.00219839 0.002193   0.002193  ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0023596904453190145\n",
      "Boosting iter: 12 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 12/20\n",
      "random state: 11\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220344 0.002193   0.00219818 0.00220829 0.002193   0.00219867\n",
      " 0.002193   0.00219774 0.002193   0.002193   0.002193   0.00221416\n",
      " 0.00221938 0.002193   0.0022312  0.002193   0.002193   0.002193\n",
      " 0.00221416 0.0021979  0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00219867 0.002193   0.002193   0.00220389\n",
      " 0.002193   0.00220879 0.002193   0.002193   0.002193   0.0021979\n",
      " 0.002193   0.002193   0.00220966 0.00220852 0.002193   0.002193\n",
      " 0.002193   0.002193   0.00219796 0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.0022189  0.002193   0.00220775 0.00221918 0.00219839\n",
      " 0.002193   0.002193   0.002193   0.00220342 0.002193   0.0022031\n",
      " 0.00219796 0.002193   0.00223602 0.002193   0.00221441 0.002193\n",
      " 0.002193   0.00220904 0.00221354 0.00219755 0.00219796 0.00219853\n",
      " 0.00220806 0.002193   0.00219808 0.002193   0.00220349 0.002193\n",
      " 0.00219755 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219853 0.00219755 0.002193   0.002193   0.00220904\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00220842 0.00221243 0.002193   0.00223668 0.002193   0.002193\n",
      " 0.002193   0.00219796 0.002193   0.002193   0.002193   0.00219755\n",
      " 0.00220229 0.002193   0.002193   0.002193   0.0021979  0.002193\n",
      " 0.002193   0.002193   0.00221465 0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219774 0.00221442 0.00219796 0.00219915 0.002193\n",
      " 0.002193   0.00220815 0.002193   0.00221908 0.00221755 0.00219796\n",
      " 0.00219796 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00219808 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.00220916 0.002193   0.00220483 0.00220393 0.002193\n",
      " 0.002193   0.00219867 0.002193   0.00220229 0.002193   0.00220229\n",
      " 0.002193   0.002193   0.00221489 0.00220455 0.002193   0.00224176\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00220314 0.002193   0.0021979  0.002193   0.002193   0.002193\n",
      " 0.00219853 0.002193   0.002193   0.00219808 0.00219774 0.002193\n",
      " 0.00220828 0.002193   0.002193   0.002193   0.002193   0.00220455\n",
      " 0.002193   0.00220229 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219755\n",
      " 0.00225197 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219818\n",
      " 0.002193   0.002193   0.002193   0.0022134  0.00220229 0.002193\n",
      " 0.00219796 0.002193   0.002193   0.002193   0.00221453 0.00220846\n",
      " 0.002193   0.002193   0.00220349 0.00219853 0.00222518 0.00219755\n",
      " 0.0022033  0.002193   0.002193   0.002193   0.00220315 0.002193\n",
      " 0.0022077  0.002193   0.00219839 0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00220327 0.002193   0.00220336 0.002193\n",
      " 0.00220348 0.0022262  0.00220755 0.002193   0.00219839 0.002193\n",
      " 0.00220879 0.002193   0.002193   0.002193   0.002193   0.00221243\n",
      " 0.002193   0.002193   0.00220412 0.0022295  0.002193   0.00220953\n",
      " 0.00220287 0.00222031 0.0022077  0.002193   0.002193   0.00221849\n",
      " 0.00220308 0.00219755 0.002193   0.002193   0.00221929 0.00219839\n",
      " 0.002193   0.00219808 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00220846 0.002193   0.00220283 0.00220229\n",
      " 0.002193   0.002193   0.00220328 0.002193   0.00220348 0.002193\n",
      " 0.002193   0.002193   0.0022088  0.00219755 0.002193   0.002193\n",
      " 0.002193   0.00220421 0.002193   0.00219755 0.002193   0.00219796\n",
      " 0.002193   0.002193   0.00222095 0.002193   0.00222512 0.002193\n",
      " 0.002193   0.002193   0.002193   0.0022037  0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00220336 0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00219755 0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.00220358 0.002193\n",
      " 0.00221931 0.00219915 0.002193   0.002193   0.002193   0.0021979\n",
      " 0.002193   0.00220328 0.002193   0.0022126  0.002193   0.00219839\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219853\n",
      " 0.002193   0.002193   0.00220914 0.0022075  0.002193   0.00221859\n",
      " 0.00222678 0.00220271 0.002193   0.002193   0.00219755 0.00220739\n",
      " 0.00219915 0.00222502 0.002193   0.00223094 0.00219755 0.002193\n",
      " 0.002193   0.002193   0.00221264 0.00219755 0.002193   0.00220896\n",
      " 0.002193   0.00219755 0.00220421 0.002193   0.00220846 0.00220314\n",
      " 0.002193   0.00219755 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219867\n",
      " 0.00219853 0.002193   0.00220342 0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219839 0.002193   0.002193   0.00219853 0.0021979\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00222878 0.00220807 0.00219796\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00221981\n",
      " 0.002193   0.002193   0.00219839 0.002193   0.002193  ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  67 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                       | 1299/2000 [02:55<01:34,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_11__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:36:34.172274+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:36:34.174350+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:36:34.176042+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:36:34.178138+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:36:34.181789+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:36:34.183542+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:36:34.185235+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 11 accuracy:  0.9340659340659341\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220305 0.00219262 0.0021978  0.0022079  0.00219262 0.00219828\n",
      " 0.00219262 0.00219736 0.00219262 0.00219262 0.00219262 0.00221963\n",
      " 0.00221899 0.00219262 0.00223081 0.00219262 0.00219842 0.00219262\n",
      " 0.00221963 0.00219752 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219828 0.00219262 0.00219262 0.00220934\n",
      " 0.00219262 0.00221425 0.00219262 0.00219262 0.00219262 0.00219752\n",
      " 0.00219262 0.00219262 0.00221512 0.00220813 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219757 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00221851 0.00219262 0.00220736 0.00222466 0.002198\n",
      " 0.00219262 0.00219262 0.00219262 0.00220303 0.00219262 0.00220271\n",
      " 0.00219757 0.00219262 0.00224155 0.00219262 0.00221988 0.00219262\n",
      " 0.00219262 0.0022145  0.00221315 0.00219716 0.00219757 0.00219814\n",
      " 0.00220767 0.00219262 0.00219769 0.00219262 0.00220311 0.00219262\n",
      " 0.00219716 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00220396 0.00219716 0.00219262 0.00219262 0.00220865\n",
      " 0.00219842 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00220803 0.00221204 0.00219262 0.00223629 0.00219262 0.00219262\n",
      " 0.00219262 0.00219757 0.00219262 0.00219262 0.00219262 0.00219716\n",
      " 0.00220191 0.00219262 0.00219262 0.00219262 0.00219752 0.00219262\n",
      " 0.00219262 0.00219262 0.00221426 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219736 0.00221403 0.00219757 0.00219876 0.00219262\n",
      " 0.00219262 0.00220776 0.00219262 0.00222457 0.00221716 0.00219757\n",
      " 0.00219757 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219769 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00220877 0.00219262 0.00220445 0.00220354 0.00219262\n",
      " 0.00219262 0.00219828 0.00219262 0.00220191 0.00219262 0.00220191\n",
      " 0.00219262 0.00219262 0.0022145  0.00220416 0.00219262 0.0022473\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00220275 0.00219262 0.00219752 0.00219262 0.00219262 0.00219262\n",
      " 0.00220396 0.00219262 0.00219262 0.00219769 0.00219736 0.00219262\n",
      " 0.00221373 0.00219262 0.00219262 0.00219262 0.00219262 0.00220416\n",
      " 0.00219262 0.00220191 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219716\n",
      " 0.00225753 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.0021978\n",
      " 0.00219262 0.00219262 0.00219262 0.00221301 0.00220191 0.00219262\n",
      " 0.00219757 0.00219262 0.00219262 0.00219262 0.00221414 0.00220807\n",
      " 0.00219262 0.00219262 0.00220311 0.00220396 0.00222479 0.00219716\n",
      " 0.00220291 0.00219842 0.00219262 0.00219262 0.00220276 0.00219262\n",
      " 0.00221316 0.00219262 0.002198   0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00220288 0.00219262 0.00220297 0.00219262\n",
      " 0.00220309 0.00222581 0.00220716 0.00219262 0.002198   0.00219262\n",
      " 0.0022084  0.00219262 0.00219262 0.00219262 0.00219262 0.00221204\n",
      " 0.00219262 0.00219262 0.00220373 0.00223501 0.00219262 0.00220914\n",
      " 0.00220248 0.0022258  0.00220732 0.00219262 0.00219262 0.0022181\n",
      " 0.0022027  0.00219716 0.00219262 0.00219262 0.00222477 0.002198\n",
      " 0.00219262 0.00220351 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00220807 0.00219262 0.00220244 0.00220191\n",
      " 0.00219262 0.00219262 0.00220289 0.00219262 0.00220309 0.00219262\n",
      " 0.00219262 0.00219262 0.00220842 0.00219716 0.00219262 0.00219262\n",
      " 0.00219262 0.00220382 0.00219262 0.00219716 0.00219262 0.00219757\n",
      " 0.00219262 0.00219262 0.00222644 0.00219262 0.00222473 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00220331 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00220297 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219716 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.0022032  0.00219262\n",
      " 0.00221892 0.00220458 0.00219262 0.00219262 0.00219262 0.00219752\n",
      " 0.00219262 0.00220289 0.00219262 0.00221221 0.00219262 0.002198\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219814\n",
      " 0.00219262 0.00219262 0.00220875 0.00220711 0.00219262 0.0022182\n",
      " 0.00223228 0.00220232 0.00219262 0.00219262 0.00219716 0.002207\n",
      " 0.00219876 0.00222463 0.00219262 0.00223055 0.00219716 0.00219262\n",
      " 0.00219262 0.00219262 0.00221225 0.00219716 0.00219262 0.00221442\n",
      " 0.00219262 0.00219716 0.00220966 0.00219262 0.00220807 0.00220275\n",
      " 0.00219262 0.00219716 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219828\n",
      " 0.00219814 0.00219262 0.00220303 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.002198   0.00219262 0.00219262 0.00219814 0.00219752\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00223429 0.00220768 0.00219757\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00221942\n",
      " 0.00219262 0.00219262 0.002198   0.00219262 0.00219262]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002643533066495037\n",
      "Boosting iter: 13 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 13/20\n",
      "random state: 12\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220305 0.00219262 0.0021978  0.0022079  0.00219262 0.00219828\n",
      " 0.00219262 0.00219736 0.00219262 0.00219262 0.00219262 0.00221963\n",
      " 0.00221899 0.00219262 0.00223081 0.00219262 0.00219842 0.00219262\n",
      " 0.00221963 0.00219752 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219828 0.00219262 0.00219262 0.00220934\n",
      " 0.00219262 0.00221425 0.00219262 0.00219262 0.00219262 0.00219752\n",
      " 0.00219262 0.00219262 0.00221512 0.00220813 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219757 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00221851 0.00219262 0.00220736 0.00222466 0.002198\n",
      " 0.00219262 0.00219262 0.00219262 0.00220303 0.00219262 0.00220271\n",
      " 0.00219757 0.00219262 0.00224155 0.00219262 0.00221988 0.00219262\n",
      " 0.00219262 0.0022145  0.00221315 0.00219716 0.00219757 0.00219814\n",
      " 0.00220767 0.00219262 0.00219769 0.00219262 0.00220311 0.00219262\n",
      " 0.00219716 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00220396 0.00219716 0.00219262 0.00219262 0.00220865\n",
      " 0.00219842 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00220803 0.00221204 0.00219262 0.00223629 0.00219262 0.00219262\n",
      " 0.00219262 0.00219757 0.00219262 0.00219262 0.00219262 0.00219716\n",
      " 0.00220191 0.00219262 0.00219262 0.00219262 0.00219752 0.00219262\n",
      " 0.00219262 0.00219262 0.00221426 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219736 0.00221403 0.00219757 0.00219876 0.00219262\n",
      " 0.00219262 0.00220776 0.00219262 0.00222457 0.00221716 0.00219757\n",
      " 0.00219757 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219769 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00220877 0.00219262 0.00220445 0.00220354 0.00219262\n",
      " 0.00219262 0.00219828 0.00219262 0.00220191 0.00219262 0.00220191\n",
      " 0.00219262 0.00219262 0.0022145  0.00220416 0.00219262 0.0022473\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00220275 0.00219262 0.00219752 0.00219262 0.00219262 0.00219262\n",
      " 0.00220396 0.00219262 0.00219262 0.00219769 0.00219736 0.00219262\n",
      " 0.00221373 0.00219262 0.00219262 0.00219262 0.00219262 0.00220416\n",
      " 0.00219262 0.00220191 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219716\n",
      " 0.00225753 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.0021978\n",
      " 0.00219262 0.00219262 0.00219262 0.00221301 0.00220191 0.00219262\n",
      " 0.00219757 0.00219262 0.00219262 0.00219262 0.00221414 0.00220807\n",
      " 0.00219262 0.00219262 0.00220311 0.00220396 0.00222479 0.00219716\n",
      " 0.00220291 0.00219842 0.00219262 0.00219262 0.00220276 0.00219262\n",
      " 0.00221316 0.00219262 0.002198   0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00220288 0.00219262 0.00220297 0.00219262\n",
      " 0.00220309 0.00222581 0.00220716 0.00219262 0.002198   0.00219262\n",
      " 0.0022084  0.00219262 0.00219262 0.00219262 0.00219262 0.00221204\n",
      " 0.00219262 0.00219262 0.00220373 0.00223501 0.00219262 0.00220914\n",
      " 0.00220248 0.0022258  0.00220732 0.00219262 0.00219262 0.0022181\n",
      " 0.0022027  0.00219716 0.00219262 0.00219262 0.00222477 0.002198\n",
      " 0.00219262 0.00220351 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00220807 0.00219262 0.00220244 0.00220191\n",
      " 0.00219262 0.00219262 0.00220289 0.00219262 0.00220309 0.00219262\n",
      " 0.00219262 0.00219262 0.00220842 0.00219716 0.00219262 0.00219262\n",
      " 0.00219262 0.00220382 0.00219262 0.00219716 0.00219262 0.00219757\n",
      " 0.00219262 0.00219262 0.00222644 0.00219262 0.00222473 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00220331 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00220297 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219716 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.0022032  0.00219262\n",
      " 0.00221892 0.00220458 0.00219262 0.00219262 0.00219262 0.00219752\n",
      " 0.00219262 0.00220289 0.00219262 0.00221221 0.00219262 0.002198\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219814\n",
      " 0.00219262 0.00219262 0.00220875 0.00220711 0.00219262 0.0022182\n",
      " 0.00223228 0.00220232 0.00219262 0.00219262 0.00219716 0.002207\n",
      " 0.00219876 0.00222463 0.00219262 0.00223055 0.00219716 0.00219262\n",
      " 0.00219262 0.00219262 0.00221225 0.00219716 0.00219262 0.00221442\n",
      " 0.00219262 0.00219716 0.00220966 0.00219262 0.00220807 0.00220275\n",
      " 0.00219262 0.00219716 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219828\n",
      " 0.00219814 0.00219262 0.00220303 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.002198   0.00219262 0.00219262 0.00219814 0.00219752\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00223429 0.00220768 0.00219757\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00221942\n",
      " 0.00219262 0.00219262 0.002198   0.00219262 0.00219262]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        184, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  67 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 309 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([212, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████████████████▌                                                                                                                                  | 349/2000 [00:46<03:37,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_12__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:37:30.916619+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:37:30.918777+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:37:30.920512+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:37:30.922639+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:37:30.926412+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:37:30.928173+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:37:30.929893+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 12 accuracy:  0.9098901098901099\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220259 0.00219216 0.00219734 0.00220744 0.00219216 0.00219782\n",
      " 0.00219216 0.00219689 0.00219216 0.00219216 0.00219216 0.00222428\n",
      " 0.00221852 0.00219216 0.00223035 0.00219216 0.00219796 0.00219216\n",
      " 0.00222428 0.00219706 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219782 0.00219216 0.00219216 0.00220888\n",
      " 0.00219216 0.00221378 0.00219216 0.00219216 0.00219216 0.00219706\n",
      " 0.00219216 0.00219216 0.00221466 0.00220767 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219711 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00221804 0.00219216 0.0022069  0.00222933 0.00219754\n",
      " 0.00219216 0.00219216 0.00219216 0.00220257 0.00219216 0.00220225\n",
      " 0.00219711 0.00219216 0.00224625 0.00219216 0.00221941 0.00219216\n",
      " 0.00219216 0.00221404 0.00221269 0.0021967  0.00219711 0.00219768\n",
      " 0.00220721 0.00219216 0.00219723 0.00219216 0.00220265 0.00219216\n",
      " 0.0021967  0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.0022035  0.0021967  0.00219216 0.00219216 0.00220819\n",
      " 0.00219796 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00221266 0.00221668 0.00219216 0.00224098 0.00219216 0.00219216\n",
      " 0.00219216 0.00219711 0.00219216 0.00219216 0.00219216 0.0021967\n",
      " 0.00220145 0.00219216 0.00219216 0.00219216 0.00219706 0.00219216\n",
      " 0.00219216 0.00219216 0.0022189  0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219689 0.00221357 0.00219711 0.00220337 0.00219216\n",
      " 0.00219216 0.00221239 0.00219216 0.00222923 0.00221669 0.00219711\n",
      " 0.00219711 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219723 0.00219722 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00220831 0.00219216 0.00220907 0.00220308 0.00219216\n",
      " 0.00219216 0.00219782 0.00219216 0.00220145 0.00219216 0.00220652\n",
      " 0.00219216 0.00219216 0.00221915 0.0022037  0.00219216 0.00225201\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00220229 0.00219216 0.00219706 0.00219216 0.00219216 0.00219216\n",
      " 0.0022035  0.00219216 0.00219216 0.00219723 0.00219689 0.00219216\n",
      " 0.00221838 0.00219216 0.00219216 0.00219216 0.00219216 0.0022037\n",
      " 0.00219216 0.00220652 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.0021967\n",
      " 0.00226226 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219734\n",
      " 0.00219216 0.00219216 0.00219216 0.00221765 0.00220145 0.00219216\n",
      " 0.00219711 0.00219216 0.00219216 0.00219216 0.00221368 0.00220761\n",
      " 0.00219216 0.00219216 0.00220773 0.0022035  0.00222433 0.0021967\n",
      " 0.00220245 0.00219796 0.00219216 0.00219216 0.00220738 0.00219216\n",
      " 0.00221269 0.00219216 0.00219754 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00220242 0.00219216 0.00220251 0.00219216\n",
      " 0.00220263 0.00223048 0.0022067  0.00219216 0.00219754 0.00219216\n",
      " 0.00220794 0.00219216 0.00219216 0.00219216 0.00219216 0.00221158\n",
      " 0.00219216 0.00219216 0.00220327 0.00223454 0.00219216 0.00220868\n",
      " 0.00220202 0.00223047 0.00220685 0.00219216 0.00219216 0.00221763\n",
      " 0.00220224 0.0021967  0.00219216 0.00219216 0.00222431 0.00219754\n",
      " 0.00219216 0.00220305 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00220761 0.00219216 0.00220198 0.00220145\n",
      " 0.00219216 0.00219216 0.00220243 0.00219216 0.00220263 0.00219216\n",
      " 0.00219216 0.00219216 0.00220795 0.0021967  0.00219216 0.00219216\n",
      " 0.00219216 0.00220844 0.00219216 0.0021967  0.00219216 0.00219711\n",
      " 0.00219216 0.00219216 0.00223111 0.00219216 0.00222939 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00220285 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00220251 0.00219722 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.0021967  0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00220782 0.00219216\n",
      " 0.00222358 0.00220412 0.00219216 0.00219216 0.00219216 0.00219706\n",
      " 0.00219216 0.00220751 0.00219216 0.00221685 0.00219216 0.00220261\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219768\n",
      " 0.00219216 0.00219216 0.00220828 0.00221174 0.00219216 0.00222285\n",
      " 0.00223181 0.00220694 0.00219216 0.00219216 0.0021967  0.00221163\n",
      " 0.0021983  0.00222416 0.00219216 0.00223523 0.0021967  0.00219216\n",
      " 0.00219216 0.00219216 0.00221689 0.0021967  0.00219216 0.00221396\n",
      " 0.00219216 0.00220177 0.00220919 0.00219216 0.00220761 0.00220229\n",
      " 0.00219216 0.0021967  0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219782\n",
      " 0.00219768 0.00219216 0.00220765 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219754 0.00219216 0.00219216 0.00219768 0.00219706\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00223382 0.00220722 0.00219711\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00221896\n",
      " 0.00219216 0.00219216 0.00219754 0.00219216 0.00219216]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002304244228185672\n",
      "Boosting iter: 14 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 14/20\n",
      "random state: 13\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220259 0.00219216 0.00219734 0.00220744 0.00219216 0.00219782\n",
      " 0.00219216 0.00219689 0.00219216 0.00219216 0.00219216 0.00222428\n",
      " 0.00221852 0.00219216 0.00223035 0.00219216 0.00219796 0.00219216\n",
      " 0.00222428 0.00219706 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219782 0.00219216 0.00219216 0.00220888\n",
      " 0.00219216 0.00221378 0.00219216 0.00219216 0.00219216 0.00219706\n",
      " 0.00219216 0.00219216 0.00221466 0.00220767 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219711 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00221804 0.00219216 0.0022069  0.00222933 0.00219754\n",
      " 0.00219216 0.00219216 0.00219216 0.00220257 0.00219216 0.00220225\n",
      " 0.00219711 0.00219216 0.00224625 0.00219216 0.00221941 0.00219216\n",
      " 0.00219216 0.00221404 0.00221269 0.0021967  0.00219711 0.00219768\n",
      " 0.00220721 0.00219216 0.00219723 0.00219216 0.00220265 0.00219216\n",
      " 0.0021967  0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.0022035  0.0021967  0.00219216 0.00219216 0.00220819\n",
      " 0.00219796 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00221266 0.00221668 0.00219216 0.00224098 0.00219216 0.00219216\n",
      " 0.00219216 0.00219711 0.00219216 0.00219216 0.00219216 0.0021967\n",
      " 0.00220145 0.00219216 0.00219216 0.00219216 0.00219706 0.00219216\n",
      " 0.00219216 0.00219216 0.0022189  0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219689 0.00221357 0.00219711 0.00220337 0.00219216\n",
      " 0.00219216 0.00221239 0.00219216 0.00222923 0.00221669 0.00219711\n",
      " 0.00219711 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219723 0.00219722 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00220831 0.00219216 0.00220907 0.00220308 0.00219216\n",
      " 0.00219216 0.00219782 0.00219216 0.00220145 0.00219216 0.00220652\n",
      " 0.00219216 0.00219216 0.00221915 0.0022037  0.00219216 0.00225201\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00220229 0.00219216 0.00219706 0.00219216 0.00219216 0.00219216\n",
      " 0.0022035  0.00219216 0.00219216 0.00219723 0.00219689 0.00219216\n",
      " 0.00221838 0.00219216 0.00219216 0.00219216 0.00219216 0.0022037\n",
      " 0.00219216 0.00220652 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.0021967\n",
      " 0.00226226 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219734\n",
      " 0.00219216 0.00219216 0.00219216 0.00221765 0.00220145 0.00219216\n",
      " 0.00219711 0.00219216 0.00219216 0.00219216 0.00221368 0.00220761\n",
      " 0.00219216 0.00219216 0.00220773 0.0022035  0.00222433 0.0021967\n",
      " 0.00220245 0.00219796 0.00219216 0.00219216 0.00220738 0.00219216\n",
      " 0.00221269 0.00219216 0.00219754 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00220242 0.00219216 0.00220251 0.00219216\n",
      " 0.00220263 0.00223048 0.0022067  0.00219216 0.00219754 0.00219216\n",
      " 0.00220794 0.00219216 0.00219216 0.00219216 0.00219216 0.00221158\n",
      " 0.00219216 0.00219216 0.00220327 0.00223454 0.00219216 0.00220868\n",
      " 0.00220202 0.00223047 0.00220685 0.00219216 0.00219216 0.00221763\n",
      " 0.00220224 0.0021967  0.00219216 0.00219216 0.00222431 0.00219754\n",
      " 0.00219216 0.00220305 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00220761 0.00219216 0.00220198 0.00220145\n",
      " 0.00219216 0.00219216 0.00220243 0.00219216 0.00220263 0.00219216\n",
      " 0.00219216 0.00219216 0.00220795 0.0021967  0.00219216 0.00219216\n",
      " 0.00219216 0.00220844 0.00219216 0.0021967  0.00219216 0.00219711\n",
      " 0.00219216 0.00219216 0.00223111 0.00219216 0.00222939 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00220285 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00220251 0.00219722 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.0021967  0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00220782 0.00219216\n",
      " 0.00222358 0.00220412 0.00219216 0.00219216 0.00219216 0.00219706\n",
      " 0.00219216 0.00220751 0.00219216 0.00221685 0.00219216 0.00220261\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219768\n",
      " 0.00219216 0.00219216 0.00220828 0.00221174 0.00219216 0.00222285\n",
      " 0.00223181 0.00220694 0.00219216 0.00219216 0.0021967  0.00221163\n",
      " 0.0021983  0.00222416 0.00219216 0.00223523 0.0021967  0.00219216\n",
      " 0.00219216 0.00219216 0.00221689 0.0021967  0.00219216 0.00221396\n",
      " 0.00219216 0.00220177 0.00220919 0.00219216 0.00220761 0.00220229\n",
      " 0.00219216 0.0021967  0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219782\n",
      " 0.00219768 0.00219216 0.00220765 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219754 0.00219216 0.00219216 0.00219768 0.00219706\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00223382 0.00220722 0.00219711\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00221896\n",
      " 0.00219216 0.00219216 0.00219754 0.00219216 0.00219216]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        184, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([212, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████████████████▌                                                                                                                                  | 349/2000 [00:46<03:41,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_13__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:38:29.532898+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:38:29.535046+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:38:29.536761+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:38:29.538819+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:38:29.542510+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:38:29.544221+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:38:29.545950+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 13 accuracy:  0.9098901098901099\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220213 0.0021917  0.00219688 0.00220698 0.0021917  0.00219736\n",
      " 0.0021917  0.00219644 0.0021917  0.0021917  0.0021917  0.00222895\n",
      " 0.00222317 0.0021917  0.00223502 0.0021917  0.0021975  0.0021917\n",
      " 0.00222382 0.0021966  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219736 0.0021917  0.0021917  0.00220842\n",
      " 0.0021917  0.00221843 0.0021917  0.0021917  0.0021917  0.0021966\n",
      " 0.0021917  0.0021917  0.0022142  0.0022123  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219665 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0022227  0.0021917  0.00221153 0.002234   0.00219708\n",
      " 0.0021917  0.0021917  0.0021917  0.00220211 0.0021917  0.00220179\n",
      " 0.00219665 0.0021917  0.00225096 0.0021917  0.00221895 0.0021917\n",
      " 0.0021917  0.00221357 0.00221733 0.00219624 0.00219665 0.00219722\n",
      " 0.00220675 0.0021917  0.00219677 0.0021917  0.00220218 0.0021917\n",
      " 0.00219624 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00220304 0.00219624 0.0021917  0.0021917  0.00220772\n",
      " 0.0021975  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0022122  0.00221622 0.0021917  0.00224568 0.0021917  0.0021917\n",
      " 0.0021917  0.00219665 0.0021917  0.0021917  0.0021917  0.00219624\n",
      " 0.00220099 0.0021917  0.0021917  0.0021917  0.0021966  0.0021917\n",
      " 0.0021917  0.0021917  0.00222356 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00219644 0.0022131  0.00219665 0.00220291 0.0021917\n",
      " 0.0021917  0.00221703 0.0021917  0.00222876 0.00221623 0.00219665\n",
      " 0.00219665 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.00220184 0.00219676 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00220784 0.0021917  0.0022137  0.00220262 0.0021917\n",
      " 0.0021917  0.00219736 0.0021917  0.00220099 0.0021917  0.00220606\n",
      " 0.0021917  0.0021917  0.00221868 0.00220324 0.0021917  0.00225673\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.00220183 0.0021917  0.0021966  0.0021917  0.0021917  0.0021917\n",
      " 0.00220304 0.0021917  0.0021917  0.00219677 0.00219644 0.0021917\n",
      " 0.00222303 0.0021917  0.0021917  0.0021917  0.0021917  0.00220832\n",
      " 0.0021917  0.00220606 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00219676 0.0021917  0.00219624\n",
      " 0.00226179 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219688\n",
      " 0.0021917  0.0021917  0.0021917  0.0022223  0.00220099 0.0021917\n",
      " 0.00219665 0.0021917  0.0021917  0.0021917  0.00221321 0.00220715\n",
      " 0.0021917  0.0021917  0.00220727 0.00220304 0.00222386 0.00219624\n",
      " 0.00220199 0.0021975  0.0021917  0.0021917  0.00220692 0.0021917\n",
      " 0.00221223 0.0021917  0.00219708 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00220196 0.0021917  0.00220205 0.0021917\n",
      " 0.00220217 0.00223001 0.00220624 0.0021917  0.00219708 0.0021917\n",
      " 0.00220748 0.0021917  0.0021917  0.0021917  0.0021917  0.00221111\n",
      " 0.0021917  0.0021917  0.00220789 0.00223408 0.0021917  0.00220822\n",
      " 0.00220156 0.00223    0.00221148 0.0021917  0.0021917  0.00221717\n",
      " 0.00220177 0.00219624 0.0021917  0.0021917  0.00222897 0.00219708\n",
      " 0.0021917  0.00220259 0.0021917  0.0021917  0.0021917  0.00219676\n",
      " 0.0021917  0.0021917  0.00221224 0.0021917  0.00220152 0.00220099\n",
      " 0.0021917  0.0021917  0.00220197 0.0021917  0.00220217 0.0021917\n",
      " 0.0021917  0.0021917  0.00221258 0.00219624 0.0021917  0.0021917\n",
      " 0.0021917  0.00220798 0.0021917  0.00219624 0.0021917  0.00219665\n",
      " 0.0021917  0.0021917  0.00223579 0.0021917  0.00223407 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00220239 0.00219676 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00220205 0.00220182 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00219624 0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219676 0.0021917  0.00221245 0.0021917\n",
      " 0.00222311 0.00220366 0.0021917  0.0021917  0.0021917  0.0021966\n",
      " 0.0021917  0.00221214 0.0021917  0.0022215  0.0021917  0.00220215\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219722\n",
      " 0.0021917  0.0021917  0.00220782 0.00221638 0.0021917  0.00222239\n",
      " 0.00223135 0.00220647 0.0021917  0.0021917  0.00219624 0.00221117\n",
      " 0.00219784 0.00222883 0.0021917  0.00223476 0.00219624 0.0021917\n",
      " 0.0021917  0.0021917  0.00222154 0.00219624 0.0021917  0.00221349\n",
      " 0.0021917  0.00220131 0.00220873 0.0021917  0.00220715 0.00220691\n",
      " 0.0021917  0.00219624 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219736\n",
      " 0.00219722 0.0021917  0.00221228 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00219708 0.0021917  0.0021917  0.00219722 0.0021966\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0022385  0.00220676 0.00219665\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00221849\n",
      " 0.0021917  0.0021917  0.00219708 0.0021917  0.00219676]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002304204351201144\n",
      "Boosting iter: 15 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 15/20\n",
      "random state: 14\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220213 0.0021917  0.00219688 0.00220698 0.0021917  0.00219736\n",
      " 0.0021917  0.00219644 0.0021917  0.0021917  0.0021917  0.00222895\n",
      " 0.00222317 0.0021917  0.00223502 0.0021917  0.0021975  0.0021917\n",
      " 0.00222382 0.0021966  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219736 0.0021917  0.0021917  0.00220842\n",
      " 0.0021917  0.00221843 0.0021917  0.0021917  0.0021917  0.0021966\n",
      " 0.0021917  0.0021917  0.0022142  0.0022123  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219665 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0022227  0.0021917  0.00221153 0.002234   0.00219708\n",
      " 0.0021917  0.0021917  0.0021917  0.00220211 0.0021917  0.00220179\n",
      " 0.00219665 0.0021917  0.00225096 0.0021917  0.00221895 0.0021917\n",
      " 0.0021917  0.00221357 0.00221733 0.00219624 0.00219665 0.00219722\n",
      " 0.00220675 0.0021917  0.00219677 0.0021917  0.00220218 0.0021917\n",
      " 0.00219624 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00220304 0.00219624 0.0021917  0.0021917  0.00220772\n",
      " 0.0021975  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0022122  0.00221622 0.0021917  0.00224568 0.0021917  0.0021917\n",
      " 0.0021917  0.00219665 0.0021917  0.0021917  0.0021917  0.00219624\n",
      " 0.00220099 0.0021917  0.0021917  0.0021917  0.0021966  0.0021917\n",
      " 0.0021917  0.0021917  0.00222356 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00219644 0.0022131  0.00219665 0.00220291 0.0021917\n",
      " 0.0021917  0.00221703 0.0021917  0.00222876 0.00221623 0.00219665\n",
      " 0.00219665 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.00220184 0.00219676 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00220784 0.0021917  0.0022137  0.00220262 0.0021917\n",
      " 0.0021917  0.00219736 0.0021917  0.00220099 0.0021917  0.00220606\n",
      " 0.0021917  0.0021917  0.00221868 0.00220324 0.0021917  0.00225673\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.00220183 0.0021917  0.0021966  0.0021917  0.0021917  0.0021917\n",
      " 0.00220304 0.0021917  0.0021917  0.00219677 0.00219644 0.0021917\n",
      " 0.00222303 0.0021917  0.0021917  0.0021917  0.0021917  0.00220832\n",
      " 0.0021917  0.00220606 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00219676 0.0021917  0.00219624\n",
      " 0.00226179 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219688\n",
      " 0.0021917  0.0021917  0.0021917  0.0022223  0.00220099 0.0021917\n",
      " 0.00219665 0.0021917  0.0021917  0.0021917  0.00221321 0.00220715\n",
      " 0.0021917  0.0021917  0.00220727 0.00220304 0.00222386 0.00219624\n",
      " 0.00220199 0.0021975  0.0021917  0.0021917  0.00220692 0.0021917\n",
      " 0.00221223 0.0021917  0.00219708 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00220196 0.0021917  0.00220205 0.0021917\n",
      " 0.00220217 0.00223001 0.00220624 0.0021917  0.00219708 0.0021917\n",
      " 0.00220748 0.0021917  0.0021917  0.0021917  0.0021917  0.00221111\n",
      " 0.0021917  0.0021917  0.00220789 0.00223408 0.0021917  0.00220822\n",
      " 0.00220156 0.00223    0.00221148 0.0021917  0.0021917  0.00221717\n",
      " 0.00220177 0.00219624 0.0021917  0.0021917  0.00222897 0.00219708\n",
      " 0.0021917  0.00220259 0.0021917  0.0021917  0.0021917  0.00219676\n",
      " 0.0021917  0.0021917  0.00221224 0.0021917  0.00220152 0.00220099\n",
      " 0.0021917  0.0021917  0.00220197 0.0021917  0.00220217 0.0021917\n",
      " 0.0021917  0.0021917  0.00221258 0.00219624 0.0021917  0.0021917\n",
      " 0.0021917  0.00220798 0.0021917  0.00219624 0.0021917  0.00219665\n",
      " 0.0021917  0.0021917  0.00223579 0.0021917  0.00223407 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00220239 0.00219676 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00220205 0.00220182 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00219624 0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219676 0.0021917  0.00221245 0.0021917\n",
      " 0.00222311 0.00220366 0.0021917  0.0021917  0.0021917  0.0021966\n",
      " 0.0021917  0.00221214 0.0021917  0.0022215  0.0021917  0.00220215\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219722\n",
      " 0.0021917  0.0021917  0.00220782 0.00221638 0.0021917  0.00222239\n",
      " 0.00223135 0.00220647 0.0021917  0.0021917  0.00219624 0.00221117\n",
      " 0.00219784 0.00222883 0.0021917  0.00223476 0.00219624 0.0021917\n",
      " 0.0021917  0.0021917  0.00222154 0.00219624 0.0021917  0.00221349\n",
      " 0.0021917  0.00220131 0.00220873 0.0021917  0.00220715 0.00220691\n",
      " 0.0021917  0.00219624 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219736\n",
      " 0.00219722 0.0021917  0.00221228 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00219708 0.0021917  0.0021917  0.00219722 0.0021966\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0022385  0.00220676 0.00219665\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00221849\n",
      " 0.0021917  0.0021917  0.00219708 0.0021917  0.00219676]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  67 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([212, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                   | 1349/2000 [03:02<01:28,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_14__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:41:43.714593+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:41:43.716687+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:41:43.718432+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:41:43.720457+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:41:43.724137+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:41:43.725905+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:41:43.727610+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 14 accuracy:  0.9230769230769231\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220171 0.00219128 0.00219646 0.00220655 0.00219128 0.00219694\n",
      " 0.00219128 0.00219601 0.00219128 0.00219128 0.00219128 0.00222852\n",
      " 0.00222825 0.00219128 0.00224013 0.00219128 0.00219708 0.00219128\n",
      " 0.00222339 0.00219617 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219694 0.00219128 0.00219128 0.00220799\n",
      " 0.00219128 0.002218   0.00219128 0.00219128 0.00219128 0.00219617\n",
      " 0.00219128 0.00219128 0.00221377 0.00221187 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219623 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00222227 0.00219128 0.0022111  0.00223357 0.00219666\n",
      " 0.00219128 0.00219128 0.00219128 0.00220169 0.00219128 0.00220136\n",
      " 0.00219623 0.00219128 0.0022561  0.00219128 0.00222402 0.00219128\n",
      " 0.00219128 0.00221315 0.00222239 0.00219582 0.00219623 0.0021968\n",
      " 0.00220632 0.00219128 0.00219635 0.00219128 0.00220722 0.00219128\n",
      " 0.00219582 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00220261 0.00219582 0.00219128 0.00219128 0.0022073\n",
      " 0.00219708 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00221725 0.00221579 0.00219128 0.00225081 0.00219128 0.00219128\n",
      " 0.00219128 0.00219623 0.00219128 0.00219128 0.00219128 0.00219582\n",
      " 0.00220056 0.00219128 0.00219128 0.00219128 0.00219617 0.00219128\n",
      " 0.00219128 0.00219128 0.00222864 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219601 0.00221268 0.00219623 0.00220249 0.00219128\n",
      " 0.00219128 0.0022166  0.00219128 0.00222834 0.00222129 0.00219623\n",
      " 0.00219623 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00220141 0.00219633 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00220742 0.00219128 0.00221328 0.00220765 0.00219128\n",
      " 0.00219128 0.00219694 0.00219128 0.00220056 0.00219128 0.00220564\n",
      " 0.00219128 0.00219128 0.00221825 0.00220282 0.00219128 0.00226189\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00220141 0.00219128 0.00219617 0.00219128 0.00219128 0.00219128\n",
      " 0.00220261 0.00219128 0.00219128 0.00219635 0.00219601 0.00219128\n",
      " 0.0022226  0.00219128 0.00219128 0.00219128 0.00219128 0.0022079\n",
      " 0.00219128 0.00220564 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219633 0.00219128 0.00219582\n",
      " 0.00226696 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219646\n",
      " 0.00219128 0.00219128 0.00219128 0.00222737 0.00220056 0.00219128\n",
      " 0.00220167 0.00219128 0.00219128 0.00219128 0.00221827 0.00220672\n",
      " 0.00219128 0.00219128 0.00221231 0.00220261 0.00222343 0.00219582\n",
      " 0.00220157 0.00220252 0.00219128 0.00219128 0.00220649 0.00219128\n",
      " 0.00221181 0.00219128 0.00219666 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00220154 0.00219128 0.00220708 0.00219128\n",
      " 0.00220174 0.00222958 0.00221128 0.00219128 0.00219666 0.00219128\n",
      " 0.00220705 0.00219128 0.00219128 0.00219128 0.00219128 0.00221069\n",
      " 0.00219128 0.00219128 0.00221293 0.00223918 0.00219128 0.00220779\n",
      " 0.00220114 0.00222957 0.00221106 0.00219128 0.00219128 0.00222223\n",
      " 0.00220135 0.00219582 0.00219128 0.00219128 0.00223406 0.00219666\n",
      " 0.00219128 0.00220216 0.00219128 0.00219128 0.00219128 0.00219633\n",
      " 0.00219128 0.00219128 0.00221181 0.00219128 0.00220109 0.00220056\n",
      " 0.00219128 0.00219128 0.00220155 0.00219128 0.00220174 0.00219128\n",
      " 0.00219128 0.00219128 0.00221216 0.00219582 0.00219128 0.00219128\n",
      " 0.00219128 0.00220756 0.00219128 0.00219582 0.00219128 0.00219623\n",
      " 0.00219128 0.00219128 0.00223536 0.00219128 0.00223917 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00220197 0.00219633 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00220708 0.0022014  0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219582 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219633 0.00219128 0.00221202 0.00219128\n",
      " 0.00222268 0.00220324 0.00219128 0.00219128 0.00219128 0.00219617\n",
      " 0.00219128 0.00221171 0.00219128 0.00222658 0.00219671 0.00220173\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.0021968\n",
      " 0.00219128 0.00219128 0.0022074  0.00222144 0.00219128 0.00222196\n",
      " 0.00223644 0.00220605 0.00219128 0.00219128 0.00219582 0.00221074\n",
      " 0.00220286 0.00223392 0.00219128 0.00223986 0.00219582 0.00219128\n",
      " 0.00219128 0.00219128 0.00222111 0.00219582 0.00219128 0.00221307\n",
      " 0.00219128 0.00220088 0.00220831 0.00219128 0.00221219 0.00220648\n",
      " 0.00219128 0.00219582 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219694\n",
      " 0.0021968  0.00219128 0.00221186 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219666 0.00219128 0.00219128 0.0021968  0.00219617\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00223807 0.00220634 0.00219623\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00222356\n",
      " 0.00219128 0.00219128 0.00219666 0.00219128 0.00219633]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002474240651679884\n",
      "Boosting iter: 16 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 16/20\n",
      "random state: 15\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220171 0.00219128 0.00219646 0.00220655 0.00219128 0.00219694\n",
      " 0.00219128 0.00219601 0.00219128 0.00219128 0.00219128 0.00222852\n",
      " 0.00222825 0.00219128 0.00224013 0.00219128 0.00219708 0.00219128\n",
      " 0.00222339 0.00219617 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219694 0.00219128 0.00219128 0.00220799\n",
      " 0.00219128 0.002218   0.00219128 0.00219128 0.00219128 0.00219617\n",
      " 0.00219128 0.00219128 0.00221377 0.00221187 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219623 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00222227 0.00219128 0.0022111  0.00223357 0.00219666\n",
      " 0.00219128 0.00219128 0.00219128 0.00220169 0.00219128 0.00220136\n",
      " 0.00219623 0.00219128 0.0022561  0.00219128 0.00222402 0.00219128\n",
      " 0.00219128 0.00221315 0.00222239 0.00219582 0.00219623 0.0021968\n",
      " 0.00220632 0.00219128 0.00219635 0.00219128 0.00220722 0.00219128\n",
      " 0.00219582 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00220261 0.00219582 0.00219128 0.00219128 0.0022073\n",
      " 0.00219708 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00221725 0.00221579 0.00219128 0.00225081 0.00219128 0.00219128\n",
      " 0.00219128 0.00219623 0.00219128 0.00219128 0.00219128 0.00219582\n",
      " 0.00220056 0.00219128 0.00219128 0.00219128 0.00219617 0.00219128\n",
      " 0.00219128 0.00219128 0.00222864 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219601 0.00221268 0.00219623 0.00220249 0.00219128\n",
      " 0.00219128 0.0022166  0.00219128 0.00222834 0.00222129 0.00219623\n",
      " 0.00219623 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00220141 0.00219633 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00220742 0.00219128 0.00221328 0.00220765 0.00219128\n",
      " 0.00219128 0.00219694 0.00219128 0.00220056 0.00219128 0.00220564\n",
      " 0.00219128 0.00219128 0.00221825 0.00220282 0.00219128 0.00226189\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00220141 0.00219128 0.00219617 0.00219128 0.00219128 0.00219128\n",
      " 0.00220261 0.00219128 0.00219128 0.00219635 0.00219601 0.00219128\n",
      " 0.0022226  0.00219128 0.00219128 0.00219128 0.00219128 0.0022079\n",
      " 0.00219128 0.00220564 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219633 0.00219128 0.00219582\n",
      " 0.00226696 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219646\n",
      " 0.00219128 0.00219128 0.00219128 0.00222737 0.00220056 0.00219128\n",
      " 0.00220167 0.00219128 0.00219128 0.00219128 0.00221827 0.00220672\n",
      " 0.00219128 0.00219128 0.00221231 0.00220261 0.00222343 0.00219582\n",
      " 0.00220157 0.00220252 0.00219128 0.00219128 0.00220649 0.00219128\n",
      " 0.00221181 0.00219128 0.00219666 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00220154 0.00219128 0.00220708 0.00219128\n",
      " 0.00220174 0.00222958 0.00221128 0.00219128 0.00219666 0.00219128\n",
      " 0.00220705 0.00219128 0.00219128 0.00219128 0.00219128 0.00221069\n",
      " 0.00219128 0.00219128 0.00221293 0.00223918 0.00219128 0.00220779\n",
      " 0.00220114 0.00222957 0.00221106 0.00219128 0.00219128 0.00222223\n",
      " 0.00220135 0.00219582 0.00219128 0.00219128 0.00223406 0.00219666\n",
      " 0.00219128 0.00220216 0.00219128 0.00219128 0.00219128 0.00219633\n",
      " 0.00219128 0.00219128 0.00221181 0.00219128 0.00220109 0.00220056\n",
      " 0.00219128 0.00219128 0.00220155 0.00219128 0.00220174 0.00219128\n",
      " 0.00219128 0.00219128 0.00221216 0.00219582 0.00219128 0.00219128\n",
      " 0.00219128 0.00220756 0.00219128 0.00219582 0.00219128 0.00219623\n",
      " 0.00219128 0.00219128 0.00223536 0.00219128 0.00223917 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00220197 0.00219633 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00220708 0.0022014  0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219582 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219633 0.00219128 0.00221202 0.00219128\n",
      " 0.00222268 0.00220324 0.00219128 0.00219128 0.00219128 0.00219617\n",
      " 0.00219128 0.00221171 0.00219128 0.00222658 0.00219671 0.00220173\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.0021968\n",
      " 0.00219128 0.00219128 0.0022074  0.00222144 0.00219128 0.00222196\n",
      " 0.00223644 0.00220605 0.00219128 0.00219128 0.00219582 0.00221074\n",
      " 0.00220286 0.00223392 0.00219128 0.00223986 0.00219582 0.00219128\n",
      " 0.00219128 0.00219128 0.00222111 0.00219582 0.00219128 0.00221307\n",
      " 0.00219128 0.00220088 0.00220831 0.00219128 0.00221219 0.00220648\n",
      " 0.00219128 0.00219582 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219694\n",
      " 0.0021968  0.00219128 0.00221186 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219666 0.00219128 0.00219128 0.0021968  0.00219617\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00223807 0.00220634 0.00219623\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00222356\n",
      " 0.00219128 0.00219128 0.00219666 0.00219128 0.00219633]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 210 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                      | 1099/2000 [02:24<01:58,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_15__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:44:19.919800+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:44:19.921846+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:44:19.923562+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:44:19.925599+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:44:19.929298+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:44:19.931065+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:44:19.932743+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 15 accuracy:  0.9318681318681319\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220705 0.00219089 0.00219606 0.00220615 0.00219089 0.00219655\n",
      " 0.00219089 0.00219562 0.00219089 0.00219089 0.00219089 0.00223393\n",
      " 0.00222785 0.00219089 0.00224557 0.00219089 0.00219668 0.00219089\n",
      " 0.00222299 0.00219578 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219655 0.00219089 0.00219089 0.00220759\n",
      " 0.00219089 0.0022176  0.00219089 0.00219089 0.00219089 0.00219578\n",
      " 0.00219089 0.00219089 0.00221915 0.00221147 0.0021966  0.00219089\n",
      " 0.00219089 0.00219089 0.00219583 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00222187 0.00219089 0.00221647 0.00223317 0.00219627\n",
      " 0.00219089 0.00219089 0.00219089 0.00220129 0.00219089 0.00220097\n",
      " 0.00219583 0.00219089 0.00226158 0.00219089 0.00222362 0.00219089\n",
      " 0.00219089 0.00221852 0.00222199 0.00219542 0.00219583 0.0021964\n",
      " 0.00220593 0.00219089 0.00219595 0.00219089 0.00220682 0.00219089\n",
      " 0.00219542 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00220222 0.00219542 0.00219089 0.00219089 0.0022069\n",
      " 0.00219668 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00221685 0.00221539 0.00219089 0.00225628 0.00219089 0.00219089\n",
      " 0.00219089 0.00219583 0.00219089 0.00219089 0.00219089 0.00219542\n",
      " 0.00220017 0.00219089 0.00219089 0.00219089 0.00219578 0.00219089\n",
      " 0.00219089 0.00219089 0.00223405 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219562 0.00221228 0.00219583 0.00220784 0.00219089\n",
      " 0.00219089 0.00221621 0.00219089 0.00222794 0.00222089 0.00219583\n",
      " 0.00219583 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00220102 0.00219594 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00220702 0.00219089 0.00221288 0.00221301 0.00219089\n",
      " 0.00219089 0.00219655 0.00219089 0.00220017 0.00219089 0.00220524\n",
      " 0.00219089 0.00219089 0.00221786 0.00220242 0.00219089 0.00226738\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00220101 0.00219089 0.00219578 0.00219089 0.00219089 0.00219089\n",
      " 0.00220796 0.00219089 0.00219089 0.00219595 0.00219562 0.00219089\n",
      " 0.0022222  0.00219089 0.00219089 0.00219089 0.00219089 0.0022075\n",
      " 0.00219089 0.00220524 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219594 0.00219089 0.00219542\n",
      " 0.00227246 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219606\n",
      " 0.00219089 0.00219089 0.00219089 0.00222697 0.00220017 0.00219089\n",
      " 0.00220127 0.00219089 0.00219089 0.00219089 0.00222365 0.00220633\n",
      " 0.00219089 0.00219089 0.00221768 0.00220222 0.00222303 0.00219542\n",
      " 0.00220117 0.00220213 0.00219089 0.00219089 0.0022061  0.0021966\n",
      " 0.00221141 0.00219089 0.00219627 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00220688 0.00219089 0.00220668 0.00219089\n",
      " 0.00220135 0.00222918 0.00221088 0.00219089 0.00219627 0.00219089\n",
      " 0.00220666 0.00219089 0.00219089 0.00219089 0.00219089 0.00221029\n",
      " 0.00219089 0.00219089 0.00221254 0.00224462 0.00219089 0.0022074\n",
      " 0.00220074 0.00222917 0.00221066 0.00219089 0.00219089 0.00222183\n",
      " 0.00220096 0.00219542 0.00219089 0.00219089 0.00223949 0.00219627\n",
      " 0.00219089 0.00220177 0.00219089 0.00219089 0.00219089 0.00219594\n",
      " 0.00219089 0.00219089 0.00221142 0.00219089 0.0022007  0.00220017\n",
      " 0.00219089 0.00219089 0.00220115 0.00219089 0.00220135 0.00219089\n",
      " 0.00219089 0.0021966  0.00221176 0.00219542 0.00219089 0.00219089\n",
      " 0.00219089 0.00220716 0.00219089 0.00219542 0.00219089 0.00219583\n",
      " 0.00219089 0.00219089 0.00224079 0.00219089 0.00224461 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00220157 0.00219594 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00221244 0.00220101 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219542 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219594 0.00219089 0.00221162 0.00219089\n",
      " 0.00222228 0.00220859 0.00219089 0.00219089 0.00219089 0.00219578\n",
      " 0.00219089 0.00221132 0.00219089 0.00222618 0.00219631 0.00220133\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.0021964\n",
      " 0.00219089 0.00219089 0.002207   0.00222104 0.00219089 0.00222156\n",
      " 0.00223604 0.00220565 0.00219089 0.00219089 0.00219542 0.00221034\n",
      " 0.00220247 0.00223352 0.00219089 0.0022453  0.00219542 0.00219089\n",
      " 0.00219089 0.00219089 0.00222071 0.00219542 0.00219089 0.00221267\n",
      " 0.00219089 0.00220049 0.00221367 0.00219089 0.00221756 0.00220609\n",
      " 0.00219089 0.00219542 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219655\n",
      " 0.0021964  0.00219089 0.00221146 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219627 0.00219089 0.00219089 0.0021964  0.00219578\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.0021966  0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00223767 0.00220594 0.00219583\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00222896\n",
      " 0.00219089 0.00219089 0.00219627 0.00219089 0.00219594]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0026048839357009812\n",
      "Boosting iter: 17 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 17/20\n",
      "random state: 16\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220705 0.00219089 0.00219606 0.00220615 0.00219089 0.00219655\n",
      " 0.00219089 0.00219562 0.00219089 0.00219089 0.00219089 0.00223393\n",
      " 0.00222785 0.00219089 0.00224557 0.00219089 0.00219668 0.00219089\n",
      " 0.00222299 0.00219578 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219655 0.00219089 0.00219089 0.00220759\n",
      " 0.00219089 0.0022176  0.00219089 0.00219089 0.00219089 0.00219578\n",
      " 0.00219089 0.00219089 0.00221915 0.00221147 0.0021966  0.00219089\n",
      " 0.00219089 0.00219089 0.00219583 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00222187 0.00219089 0.00221647 0.00223317 0.00219627\n",
      " 0.00219089 0.00219089 0.00219089 0.00220129 0.00219089 0.00220097\n",
      " 0.00219583 0.00219089 0.00226158 0.00219089 0.00222362 0.00219089\n",
      " 0.00219089 0.00221852 0.00222199 0.00219542 0.00219583 0.0021964\n",
      " 0.00220593 0.00219089 0.00219595 0.00219089 0.00220682 0.00219089\n",
      " 0.00219542 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00220222 0.00219542 0.00219089 0.00219089 0.0022069\n",
      " 0.00219668 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00221685 0.00221539 0.00219089 0.00225628 0.00219089 0.00219089\n",
      " 0.00219089 0.00219583 0.00219089 0.00219089 0.00219089 0.00219542\n",
      " 0.00220017 0.00219089 0.00219089 0.00219089 0.00219578 0.00219089\n",
      " 0.00219089 0.00219089 0.00223405 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219562 0.00221228 0.00219583 0.00220784 0.00219089\n",
      " 0.00219089 0.00221621 0.00219089 0.00222794 0.00222089 0.00219583\n",
      " 0.00219583 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00220102 0.00219594 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00220702 0.00219089 0.00221288 0.00221301 0.00219089\n",
      " 0.00219089 0.00219655 0.00219089 0.00220017 0.00219089 0.00220524\n",
      " 0.00219089 0.00219089 0.00221786 0.00220242 0.00219089 0.00226738\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00220101 0.00219089 0.00219578 0.00219089 0.00219089 0.00219089\n",
      " 0.00220796 0.00219089 0.00219089 0.00219595 0.00219562 0.00219089\n",
      " 0.0022222  0.00219089 0.00219089 0.00219089 0.00219089 0.0022075\n",
      " 0.00219089 0.00220524 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219594 0.00219089 0.00219542\n",
      " 0.00227246 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219606\n",
      " 0.00219089 0.00219089 0.00219089 0.00222697 0.00220017 0.00219089\n",
      " 0.00220127 0.00219089 0.00219089 0.00219089 0.00222365 0.00220633\n",
      " 0.00219089 0.00219089 0.00221768 0.00220222 0.00222303 0.00219542\n",
      " 0.00220117 0.00220213 0.00219089 0.00219089 0.0022061  0.0021966\n",
      " 0.00221141 0.00219089 0.00219627 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00220688 0.00219089 0.00220668 0.00219089\n",
      " 0.00220135 0.00222918 0.00221088 0.00219089 0.00219627 0.00219089\n",
      " 0.00220666 0.00219089 0.00219089 0.00219089 0.00219089 0.00221029\n",
      " 0.00219089 0.00219089 0.00221254 0.00224462 0.00219089 0.0022074\n",
      " 0.00220074 0.00222917 0.00221066 0.00219089 0.00219089 0.00222183\n",
      " 0.00220096 0.00219542 0.00219089 0.00219089 0.00223949 0.00219627\n",
      " 0.00219089 0.00220177 0.00219089 0.00219089 0.00219089 0.00219594\n",
      " 0.00219089 0.00219089 0.00221142 0.00219089 0.0022007  0.00220017\n",
      " 0.00219089 0.00219089 0.00220115 0.00219089 0.00220135 0.00219089\n",
      " 0.00219089 0.0021966  0.00221176 0.00219542 0.00219089 0.00219089\n",
      " 0.00219089 0.00220716 0.00219089 0.00219542 0.00219089 0.00219583\n",
      " 0.00219089 0.00219089 0.00224079 0.00219089 0.00224461 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00220157 0.00219594 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00221244 0.00220101 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219542 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219594 0.00219089 0.00221162 0.00219089\n",
      " 0.00222228 0.00220859 0.00219089 0.00219089 0.00219089 0.00219578\n",
      " 0.00219089 0.00221132 0.00219089 0.00222618 0.00219631 0.00220133\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.0021964\n",
      " 0.00219089 0.00219089 0.002207   0.00222104 0.00219089 0.00222156\n",
      " 0.00223604 0.00220565 0.00219089 0.00219089 0.00219542 0.00221034\n",
      " 0.00220247 0.00223352 0.00219089 0.0022453  0.00219542 0.00219089\n",
      " 0.00219089 0.00219089 0.00222071 0.00219542 0.00219089 0.00221267\n",
      " 0.00219089 0.00220049 0.00221367 0.00219089 0.00221756 0.00220609\n",
      " 0.00219089 0.00219542 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219655\n",
      " 0.0021964  0.00219089 0.00221146 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219627 0.00219089 0.00219089 0.0021964  0.00219578\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.0021966  0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00223767 0.00220594 0.00219583\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00222896\n",
      " 0.00219089 0.00219089 0.00219627 0.00219089 0.00219594]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 210 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████████████████▉                                                                               | 999/2000 [02:09<02:10,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_16__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:46:40.810204+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:46:40.812263+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:46:40.813943+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:46:40.815949+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:46:40.819635+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:46:40.821356+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:46:40.823048+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 16 accuracy:  0.9296703296703297\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00221233 0.00219048 0.00219566 0.00220575 0.00219048 0.00219614\n",
      " 0.00219048 0.00219522 0.00219048 0.00219048 0.00219048 0.00223927\n",
      " 0.00222745 0.00219048 0.00224516 0.00219048 0.00219628 0.00219048\n",
      " 0.0022283  0.00219538 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219614 0.00219048 0.00219048 0.00221287\n",
      " 0.00219048 0.00221719 0.00219048 0.00219048 0.00219048 0.00219538\n",
      " 0.00219048 0.00219048 0.00222445 0.00221107 0.0021962  0.00219048\n",
      " 0.00219048 0.00219048 0.00219543 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00222146 0.00219048 0.00221606 0.00223276 0.00219586\n",
      " 0.00219048 0.00219048 0.00219048 0.00220089 0.00219048 0.00220057\n",
      " 0.00219543 0.00219048 0.00226117 0.00219048 0.00222321 0.00219048\n",
      " 0.00219048 0.00222382 0.00222159 0.00219502 0.00219543 0.002196\n",
      " 0.0022112  0.00219048 0.00219555 0.00219048 0.00220642 0.00219048\n",
      " 0.00219502 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00220182 0.00219502 0.00219048 0.00219048 0.0022065\n",
      " 0.00220193 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00221645 0.00221499 0.00219048 0.00226167 0.00219048 0.00219048\n",
      " 0.00219048 0.00219543 0.00219048 0.00219048 0.00219048 0.00219502\n",
      " 0.00219976 0.00219048 0.00219048 0.00219048 0.00219538 0.00219048\n",
      " 0.00219048 0.00219048 0.00223939 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219522 0.00221187 0.00219543 0.00220743 0.00219048\n",
      " 0.00219048 0.0022158  0.00219048 0.00223326 0.00222049 0.00219543\n",
      " 0.00219543 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00220062 0.00219554 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00220662 0.00219048 0.00221247 0.0022183  0.00219048\n",
      " 0.00219048 0.00219614 0.00219048 0.00219976 0.00219048 0.00220484\n",
      " 0.00219048 0.00219048 0.00221745 0.00220202 0.00219048 0.0022728\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00220061 0.00219048 0.00219538 0.00219048 0.00219048 0.00219048\n",
      " 0.00220756 0.00219048 0.00219048 0.00219555 0.00219522 0.00219048\n",
      " 0.0022218  0.00219048 0.00219048 0.00219048 0.00219048 0.0022071\n",
      " 0.00219048 0.00220484 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219554 0.00219048 0.00219502\n",
      " 0.00227789 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219566\n",
      " 0.00219048 0.00219048 0.00219048 0.00222657 0.00219976 0.00219048\n",
      " 0.00220087 0.00219048 0.00219048 0.00219048 0.00222897 0.0022116\n",
      " 0.00219048 0.00219048 0.00222298 0.00220182 0.00222834 0.00219502\n",
      " 0.00220077 0.00220172 0.00219048 0.00219048 0.0022057  0.0021962\n",
      " 0.002211   0.00219048 0.00219586 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00220648 0.00219048 0.00220628 0.00219048\n",
      " 0.00220094 0.00222877 0.00221048 0.00219048 0.00219586 0.00219048\n",
      " 0.00220625 0.00219048 0.00219048 0.00219048 0.00219048 0.00220989\n",
      " 0.00219048 0.00219048 0.00221213 0.00224998 0.00219048 0.00220699\n",
      " 0.00220034 0.00222876 0.00221025 0.00219048 0.00219048 0.00222143\n",
      " 0.00220055 0.00219502 0.00219048 0.00219048 0.00224484 0.00219586\n",
      " 0.00219048 0.00220136 0.00219048 0.00219048 0.00219048 0.00219554\n",
      " 0.00219048 0.00219048 0.0022167  0.00219048 0.00220029 0.00219976\n",
      " 0.00219048 0.00219048 0.00220075 0.00219048 0.00220094 0.00219048\n",
      " 0.00219048 0.0021962  0.00221136 0.00219502 0.00219048 0.00219048\n",
      " 0.00219048 0.00220676 0.00219048 0.00219502 0.00219048 0.00219543\n",
      " 0.00219048 0.00219048 0.00224038 0.00219048 0.0022442  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00220683 0.00219554 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00221203 0.0022006  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219502 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219554 0.00219048 0.00221122 0.00219048\n",
      " 0.00222188 0.00220818 0.00219048 0.00219048 0.00219048 0.00219538\n",
      " 0.00219048 0.0022166  0.00219048 0.00222577 0.00219591 0.00220093\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00220165\n",
      " 0.00219048 0.00219048 0.0022066  0.00222063 0.00219048 0.00222687\n",
      " 0.00224138 0.00220525 0.00219048 0.00219048 0.00219502 0.00220994\n",
      " 0.00220207 0.00223885 0.00219048 0.00225067 0.00219502 0.00219048\n",
      " 0.00219048 0.00219048 0.0022203  0.00219502 0.00219048 0.00221227\n",
      " 0.00219048 0.00220009 0.00221326 0.00219048 0.00222286 0.00220568\n",
      " 0.00219048 0.00219502 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219614\n",
      " 0.00220165 0.00219048 0.00221106 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219586 0.00219048 0.00219048 0.002196   0.00219538\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.0021962  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00224302 0.00220554 0.00219543\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00223429\n",
      " 0.00219048 0.00219048 0.00219586 0.00219048 0.00219554]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0025687711105727555\n",
      "Boosting iter: 18 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 18/20\n",
      "random state: 17\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00221233 0.00219048 0.00219566 0.00220575 0.00219048 0.00219614\n",
      " 0.00219048 0.00219522 0.00219048 0.00219048 0.00219048 0.00223927\n",
      " 0.00222745 0.00219048 0.00224516 0.00219048 0.00219628 0.00219048\n",
      " 0.0022283  0.00219538 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219614 0.00219048 0.00219048 0.00221287\n",
      " 0.00219048 0.00221719 0.00219048 0.00219048 0.00219048 0.00219538\n",
      " 0.00219048 0.00219048 0.00222445 0.00221107 0.0021962  0.00219048\n",
      " 0.00219048 0.00219048 0.00219543 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00222146 0.00219048 0.00221606 0.00223276 0.00219586\n",
      " 0.00219048 0.00219048 0.00219048 0.00220089 0.00219048 0.00220057\n",
      " 0.00219543 0.00219048 0.00226117 0.00219048 0.00222321 0.00219048\n",
      " 0.00219048 0.00222382 0.00222159 0.00219502 0.00219543 0.002196\n",
      " 0.0022112  0.00219048 0.00219555 0.00219048 0.00220642 0.00219048\n",
      " 0.00219502 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00220182 0.00219502 0.00219048 0.00219048 0.0022065\n",
      " 0.00220193 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00221645 0.00221499 0.00219048 0.00226167 0.00219048 0.00219048\n",
      " 0.00219048 0.00219543 0.00219048 0.00219048 0.00219048 0.00219502\n",
      " 0.00219976 0.00219048 0.00219048 0.00219048 0.00219538 0.00219048\n",
      " 0.00219048 0.00219048 0.00223939 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219522 0.00221187 0.00219543 0.00220743 0.00219048\n",
      " 0.00219048 0.0022158  0.00219048 0.00223326 0.00222049 0.00219543\n",
      " 0.00219543 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00220062 0.00219554 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00220662 0.00219048 0.00221247 0.0022183  0.00219048\n",
      " 0.00219048 0.00219614 0.00219048 0.00219976 0.00219048 0.00220484\n",
      " 0.00219048 0.00219048 0.00221745 0.00220202 0.00219048 0.0022728\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00220061 0.00219048 0.00219538 0.00219048 0.00219048 0.00219048\n",
      " 0.00220756 0.00219048 0.00219048 0.00219555 0.00219522 0.00219048\n",
      " 0.0022218  0.00219048 0.00219048 0.00219048 0.00219048 0.0022071\n",
      " 0.00219048 0.00220484 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219554 0.00219048 0.00219502\n",
      " 0.00227789 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219566\n",
      " 0.00219048 0.00219048 0.00219048 0.00222657 0.00219976 0.00219048\n",
      " 0.00220087 0.00219048 0.00219048 0.00219048 0.00222897 0.0022116\n",
      " 0.00219048 0.00219048 0.00222298 0.00220182 0.00222834 0.00219502\n",
      " 0.00220077 0.00220172 0.00219048 0.00219048 0.0022057  0.0021962\n",
      " 0.002211   0.00219048 0.00219586 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00220648 0.00219048 0.00220628 0.00219048\n",
      " 0.00220094 0.00222877 0.00221048 0.00219048 0.00219586 0.00219048\n",
      " 0.00220625 0.00219048 0.00219048 0.00219048 0.00219048 0.00220989\n",
      " 0.00219048 0.00219048 0.00221213 0.00224998 0.00219048 0.00220699\n",
      " 0.00220034 0.00222876 0.00221025 0.00219048 0.00219048 0.00222143\n",
      " 0.00220055 0.00219502 0.00219048 0.00219048 0.00224484 0.00219586\n",
      " 0.00219048 0.00220136 0.00219048 0.00219048 0.00219048 0.00219554\n",
      " 0.00219048 0.00219048 0.0022167  0.00219048 0.00220029 0.00219976\n",
      " 0.00219048 0.00219048 0.00220075 0.00219048 0.00220094 0.00219048\n",
      " 0.00219048 0.0021962  0.00221136 0.00219502 0.00219048 0.00219048\n",
      " 0.00219048 0.00220676 0.00219048 0.00219502 0.00219048 0.00219543\n",
      " 0.00219048 0.00219048 0.00224038 0.00219048 0.0022442  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00220683 0.00219554 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00221203 0.0022006  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219502 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219554 0.00219048 0.00221122 0.00219048\n",
      " 0.00222188 0.00220818 0.00219048 0.00219048 0.00219048 0.00219538\n",
      " 0.00219048 0.0022166  0.00219048 0.00222577 0.00219591 0.00220093\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00220165\n",
      " 0.00219048 0.00219048 0.0022066  0.00222063 0.00219048 0.00222687\n",
      " 0.00224138 0.00220525 0.00219048 0.00219048 0.00219502 0.00220994\n",
      " 0.00220207 0.00223885 0.00219048 0.00225067 0.00219502 0.00219048\n",
      " 0.00219048 0.00219048 0.0022203  0.00219502 0.00219048 0.00221227\n",
      " 0.00219048 0.00220009 0.00221326 0.00219048 0.00222286 0.00220568\n",
      " 0.00219048 0.00219502 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219614\n",
      " 0.00220165 0.00219048 0.00221106 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219586 0.00219048 0.00219048 0.002196   0.00219538\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.0021962  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00224302 0.00220554 0.00219543\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00223429\n",
      " 0.00219048 0.00219048 0.00219586 0.00219048 0.00219554]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 360,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 210 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  67 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  34 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████▌                                                                                                                              | 399/2000 [00:48<03:12,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_17__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:47:40.152689+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:47:40.154766+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:47:40.156444+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:47:40.158497+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:47:40.162207+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:47:40.163931+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:47:40.165627+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 17 accuracy:  0.9362637362637363\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00221194 0.00219011 0.00219528 0.00220537 0.00219011 0.00219576\n",
      " 0.00219011 0.00219484 0.00219011 0.00219011 0.00219011 0.00224487\n",
      " 0.00222706 0.00219011 0.00225077 0.00219011 0.0021959  0.00219011\n",
      " 0.00222792 0.002195   0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219576 0.00219011 0.00219011 0.00221248\n",
      " 0.00219011 0.00221681 0.00219011 0.00219011 0.00219011 0.002195\n",
      " 0.00219011 0.00219011 0.00223001 0.00221069 0.00219582 0.00219011\n",
      " 0.00219011 0.00219011 0.00219505 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00222108 0.00219011 0.00221568 0.00223237 0.00219548\n",
      " 0.00219011 0.00219011 0.00219011 0.00220051 0.00219011 0.00220018\n",
      " 0.00219505 0.00219011 0.00226682 0.00219011 0.00222283 0.00219011\n",
      " 0.00219011 0.00222344 0.0022212  0.00219464 0.00219505 0.00219562\n",
      " 0.00221673 0.00219011 0.00219517 0.00219011 0.00220603 0.00219011\n",
      " 0.00219464 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00220143 0.00219464 0.00219011 0.00219011 0.00220612\n",
      " 0.00220155 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00222199 0.0022146  0.00219011 0.00226732 0.00219011 0.00219011\n",
      " 0.00219011 0.00219505 0.00219011 0.00219011 0.00219011 0.00219464\n",
      " 0.00219938 0.00219011 0.00219011 0.00219011 0.002195   0.00219011\n",
      " 0.00219011 0.00219011 0.002239   0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219484 0.00221149 0.00219505 0.00220705 0.00219011\n",
      " 0.00219011 0.00221542 0.00219011 0.00223884 0.0022201  0.00219505\n",
      " 0.00219505 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00220024 0.00219516 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00220624 0.00219011 0.00221209 0.00222385 0.00219011\n",
      " 0.00219011 0.00219576 0.00219011 0.00219938 0.00219011 0.00220446\n",
      " 0.00219011 0.00219011 0.00221707 0.00220164 0.00219011 0.00227848\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00220023 0.00219011 0.002195   0.00219011 0.00219011 0.00219011\n",
      " 0.00220718 0.00219011 0.00219011 0.00219517 0.00219484 0.00219011\n",
      " 0.00222141 0.00219011 0.00219011 0.00219011 0.00219011 0.00220672\n",
      " 0.00219011 0.00220446 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219516 0.00219011 0.00219464\n",
      " 0.00228359 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219528\n",
      " 0.00219011 0.00219011 0.00219596 0.00223214 0.00219938 0.00219011\n",
      " 0.00220049 0.00219011 0.00219011 0.00219011 0.00222858 0.00221713\n",
      " 0.00219011 0.00219011 0.00222854 0.00220143 0.00222796 0.00219464\n",
      " 0.00220039 0.00220134 0.00219011 0.00219011 0.00220531 0.00219582\n",
      " 0.00221062 0.00219011 0.00219548 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.0022061  0.00219011 0.00220589 0.00219011\n",
      " 0.00220056 0.00223435 0.0022101  0.00219011 0.00219548 0.00219011\n",
      " 0.00220587 0.00219011 0.00219011 0.00219011 0.00219011 0.00220951\n",
      " 0.00219011 0.00219011 0.00221175 0.00225561 0.00219011 0.00220661\n",
      " 0.00219996 0.00223433 0.00220987 0.00219011 0.00219011 0.00222104\n",
      " 0.00220017 0.00219464 0.00219011 0.00219011 0.00225045 0.00219548\n",
      " 0.00219011 0.00220098 0.00219011 0.00219011 0.00219011 0.00219516\n",
      " 0.00219011 0.00219011 0.00221632 0.00219011 0.00219991 0.00219938\n",
      " 0.00219011 0.00219011 0.00220037 0.00219011 0.00220056 0.00219011\n",
      " 0.00219011 0.00219582 0.00221689 0.00219464 0.00219011 0.00219011\n",
      " 0.00219011 0.00221228 0.00219011 0.00219464 0.00219011 0.00219505\n",
      " 0.00219011 0.00219011 0.00224598 0.00219011 0.00224981 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00220645 0.00219516 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00221165 0.00220022 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219464 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00220103 0.00219011 0.00221084 0.00219011\n",
      " 0.00222149 0.0022078  0.00219011 0.00219011 0.00219011 0.002195\n",
      " 0.00219011 0.00221622 0.00219011 0.00222539 0.00219553 0.00220055\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00220127\n",
      " 0.00219011 0.00219011 0.00220622 0.00222025 0.00219011 0.00223244\n",
      " 0.00224699 0.00220487 0.00219011 0.00219011 0.00219464 0.00220956\n",
      " 0.00220168 0.00224445 0.00219011 0.00225028 0.00219464 0.00219011\n",
      " 0.00219011 0.00219011 0.00221992 0.00219464 0.00219011 0.00221188\n",
      " 0.00219011 0.00219971 0.00221288 0.00219011 0.00222247 0.0022053\n",
      " 0.00219011 0.00219464 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219576\n",
      " 0.00220716 0.00219011 0.00221067 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219548 0.00219011 0.00219011 0.00219562 0.002195\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219582 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00224862 0.00220515 0.00219505\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.0022339\n",
      " 0.00219011 0.00219011 0.00219548 0.00219011 0.00219516]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002670849097163872\n",
      "Boosting iter: 19 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 19/20\n",
      "random state: 18\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00221194 0.00219011 0.00219528 0.00220537 0.00219011 0.00219576\n",
      " 0.00219011 0.00219484 0.00219011 0.00219011 0.00219011 0.00224487\n",
      " 0.00222706 0.00219011 0.00225077 0.00219011 0.0021959  0.00219011\n",
      " 0.00222792 0.002195   0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219576 0.00219011 0.00219011 0.00221248\n",
      " 0.00219011 0.00221681 0.00219011 0.00219011 0.00219011 0.002195\n",
      " 0.00219011 0.00219011 0.00223001 0.00221069 0.00219582 0.00219011\n",
      " 0.00219011 0.00219011 0.00219505 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00222108 0.00219011 0.00221568 0.00223237 0.00219548\n",
      " 0.00219011 0.00219011 0.00219011 0.00220051 0.00219011 0.00220018\n",
      " 0.00219505 0.00219011 0.00226682 0.00219011 0.00222283 0.00219011\n",
      " 0.00219011 0.00222344 0.0022212  0.00219464 0.00219505 0.00219562\n",
      " 0.00221673 0.00219011 0.00219517 0.00219011 0.00220603 0.00219011\n",
      " 0.00219464 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00220143 0.00219464 0.00219011 0.00219011 0.00220612\n",
      " 0.00220155 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00222199 0.0022146  0.00219011 0.00226732 0.00219011 0.00219011\n",
      " 0.00219011 0.00219505 0.00219011 0.00219011 0.00219011 0.00219464\n",
      " 0.00219938 0.00219011 0.00219011 0.00219011 0.002195   0.00219011\n",
      " 0.00219011 0.00219011 0.002239   0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219484 0.00221149 0.00219505 0.00220705 0.00219011\n",
      " 0.00219011 0.00221542 0.00219011 0.00223884 0.0022201  0.00219505\n",
      " 0.00219505 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00220024 0.00219516 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00220624 0.00219011 0.00221209 0.00222385 0.00219011\n",
      " 0.00219011 0.00219576 0.00219011 0.00219938 0.00219011 0.00220446\n",
      " 0.00219011 0.00219011 0.00221707 0.00220164 0.00219011 0.00227848\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00220023 0.00219011 0.002195   0.00219011 0.00219011 0.00219011\n",
      " 0.00220718 0.00219011 0.00219011 0.00219517 0.00219484 0.00219011\n",
      " 0.00222141 0.00219011 0.00219011 0.00219011 0.00219011 0.00220672\n",
      " 0.00219011 0.00220446 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219516 0.00219011 0.00219464\n",
      " 0.00228359 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219528\n",
      " 0.00219011 0.00219011 0.00219596 0.00223214 0.00219938 0.00219011\n",
      " 0.00220049 0.00219011 0.00219011 0.00219011 0.00222858 0.00221713\n",
      " 0.00219011 0.00219011 0.00222854 0.00220143 0.00222796 0.00219464\n",
      " 0.00220039 0.00220134 0.00219011 0.00219011 0.00220531 0.00219582\n",
      " 0.00221062 0.00219011 0.00219548 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.0022061  0.00219011 0.00220589 0.00219011\n",
      " 0.00220056 0.00223435 0.0022101  0.00219011 0.00219548 0.00219011\n",
      " 0.00220587 0.00219011 0.00219011 0.00219011 0.00219011 0.00220951\n",
      " 0.00219011 0.00219011 0.00221175 0.00225561 0.00219011 0.00220661\n",
      " 0.00219996 0.00223433 0.00220987 0.00219011 0.00219011 0.00222104\n",
      " 0.00220017 0.00219464 0.00219011 0.00219011 0.00225045 0.00219548\n",
      " 0.00219011 0.00220098 0.00219011 0.00219011 0.00219011 0.00219516\n",
      " 0.00219011 0.00219011 0.00221632 0.00219011 0.00219991 0.00219938\n",
      " 0.00219011 0.00219011 0.00220037 0.00219011 0.00220056 0.00219011\n",
      " 0.00219011 0.00219582 0.00221689 0.00219464 0.00219011 0.00219011\n",
      " 0.00219011 0.00221228 0.00219011 0.00219464 0.00219011 0.00219505\n",
      " 0.00219011 0.00219011 0.00224598 0.00219011 0.00224981 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00220645 0.00219516 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00221165 0.00220022 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219464 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00220103 0.00219011 0.00221084 0.00219011\n",
      " 0.00222149 0.0022078  0.00219011 0.00219011 0.00219011 0.002195\n",
      " 0.00219011 0.00221622 0.00219011 0.00222539 0.00219553 0.00220055\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00220127\n",
      " 0.00219011 0.00219011 0.00220622 0.00222025 0.00219011 0.00223244\n",
      " 0.00224699 0.00220487 0.00219011 0.00219011 0.00219464 0.00220956\n",
      " 0.00220168 0.00224445 0.00219011 0.00225028 0.00219464 0.00219011\n",
      " 0.00219011 0.00219011 0.00221992 0.00219464 0.00219011 0.00221188\n",
      " 0.00219011 0.00219971 0.00221288 0.00219011 0.00222247 0.0022053\n",
      " 0.00219011 0.00219464 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219576\n",
      " 0.00220716 0.00219011 0.00221067 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219548 0.00219011 0.00219011 0.00219562 0.002195\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219582 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00224862 0.00220515 0.00219505\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.0022339\n",
      " 0.00219011 0.00219011 0.00219548 0.00219011 0.00219516]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 360,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 210 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  34 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                       | 1299/2000 [02:48<01:31,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_18__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:50:40.068158+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:50:40.070262+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:50:40.071940+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:50:40.073992+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:50:40.077671+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:50:40.079390+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:50:40.081060+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 18 accuracy:  0.9252747252747253\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00221706 0.00218969 0.00219486 0.00220495 0.00218969 0.00219535\n",
      " 0.00218969 0.00219442 0.00218969 0.00218969 0.00218969 0.00225007\n",
      " 0.00223222 0.00218969 0.00225598 0.00218969 0.00219549 0.00218969\n",
      " 0.00223307 0.00219458 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00219535 0.00218969 0.00218969 0.00221206\n",
      " 0.00218969 0.00221639 0.00218969 0.00218969 0.00218969 0.00219458\n",
      " 0.00218969 0.00218969 0.00222959 0.00221027 0.0021954  0.00218969\n",
      " 0.00218969 0.00218969 0.00219464 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00222066 0.00218969 0.00221526 0.00223195 0.00219507\n",
      " 0.00218969 0.00218969 0.00218969 0.00220009 0.00218969 0.00219977\n",
      " 0.00219464 0.00218969 0.00227207 0.00218969 0.00222797 0.00218969\n",
      " 0.00218969 0.00222858 0.00222078 0.00219423 0.00219464 0.00219521\n",
      " 0.00221631 0.00218969 0.00219476 0.00218969 0.00221114 0.00218969\n",
      " 0.00219423 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00220102 0.00219423 0.00218969 0.00218969 0.00221122\n",
      " 0.00220113 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00222157 0.00221973 0.00218969 0.00227257 0.00218969 0.00218969\n",
      " 0.00218969 0.00219464 0.00218969 0.00218969 0.00218969 0.00219423\n",
      " 0.00219897 0.00218969 0.00218969 0.00218969 0.00219458 0.00218969\n",
      " 0.00218969 0.00218969 0.00223857 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00219442 0.00221107 0.00219464 0.00220663 0.00218969\n",
      " 0.00218969 0.002215   0.00218969 0.00224403 0.00221968 0.00219464\n",
      " 0.00219464 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00219982 0.00219474 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00220582 0.00218969 0.00221167 0.00222342 0.00218969\n",
      " 0.00218969 0.00219535 0.00218969 0.00219897 0.00218969 0.00220404\n",
      " 0.00218969 0.00218969 0.0022222  0.00220122 0.00218969 0.00228376\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00220532 0.00218969 0.00219458 0.00218969 0.00218969 0.00218969\n",
      " 0.00220676 0.00218969 0.00218969 0.00219476 0.00219442 0.00218969\n",
      " 0.00222099 0.00218969 0.00218969 0.00218969 0.00218969 0.0022063\n",
      " 0.00218969 0.00220404 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00219474 0.00218969 0.00219423\n",
      " 0.00228887 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00219486\n",
      " 0.00218969 0.00218969 0.00219555 0.00223171 0.00219897 0.00218969\n",
      " 0.00220007 0.00218969 0.00218969 0.00218969 0.00223374 0.00221671\n",
      " 0.00218969 0.00218969 0.0022337  0.00220102 0.00222754 0.00219423\n",
      " 0.00219997 0.00220092 0.00218969 0.00218969 0.0022049  0.0021954\n",
      " 0.0022102  0.00218969 0.00219507 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00220568 0.00218969 0.00220548 0.00218969\n",
      " 0.00220015 0.00223952 0.00220968 0.00218969 0.00219507 0.00218969\n",
      " 0.00220545 0.00218969 0.00218969 0.00218969 0.00218969 0.00220909\n",
      " 0.00218969 0.00218969 0.00221687 0.00225518 0.00218969 0.00220619\n",
      " 0.00219954 0.00223391 0.00220945 0.00218969 0.00218969 0.00222618\n",
      " 0.00219975 0.00219423 0.00218969 0.00218969 0.00225003 0.00219507\n",
      " 0.00218969 0.00220056 0.00218969 0.00218969 0.00218969 0.00219474\n",
      " 0.00219518 0.00218969 0.0022159  0.00218969 0.0021995  0.00219897\n",
      " 0.00218969 0.00218969 0.00219995 0.00218969 0.00220566 0.00218969\n",
      " 0.00218969 0.0021954  0.00222202 0.00219423 0.00218969 0.00218969\n",
      " 0.00218969 0.00221186 0.00218969 0.00219423 0.00218969 0.00219464\n",
      " 0.00218969 0.00218969 0.00225118 0.00218969 0.00225502 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00220603 0.00219474 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00221677 0.0021998  0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00219423 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00220061 0.00218969 0.00221042 0.00218969\n",
      " 0.00222107 0.00220738 0.00218969 0.00218969 0.00218969 0.00219458\n",
      " 0.00218969 0.0022158  0.00218969 0.00223054 0.00219511 0.00220013\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00220085\n",
      " 0.00218969 0.00219518 0.0022058  0.00221983 0.00218969 0.00223761\n",
      " 0.00224656 0.00220445 0.00218969 0.00218969 0.00219423 0.00220914\n",
      " 0.00220678 0.00224402 0.00218969 0.00224985 0.00219423 0.00218969\n",
      " 0.00218969 0.00218969 0.0022195  0.00219423 0.00218969 0.00221146\n",
      " 0.00218969 0.00219929 0.00221246 0.00219518 0.00222205 0.00220488\n",
      " 0.00218969 0.00219423 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00219535\n",
      " 0.00220674 0.00218969 0.00221025 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00219507 0.00218969 0.00218969 0.00219521 0.00219458\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.0021954  0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.0022482  0.00220474 0.00219464\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00223907\n",
      " 0.00218969 0.00218969 0.00219507 0.00218969 0.00219474]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0025022473149690356\n",
      "Boosting iter: 20 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 20/20\n",
      "random state: 19\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00221706 0.00218969 0.00219486 0.00220495 0.00218969 0.00219535\n",
      " 0.00218969 0.00219442 0.00218969 0.00218969 0.00218969 0.00225007\n",
      " 0.00223222 0.00218969 0.00225598 0.00218969 0.00219549 0.00218969\n",
      " 0.00223307 0.00219458 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00219535 0.00218969 0.00218969 0.00221206\n",
      " 0.00218969 0.00221639 0.00218969 0.00218969 0.00218969 0.00219458\n",
      " 0.00218969 0.00218969 0.00222959 0.00221027 0.0021954  0.00218969\n",
      " 0.00218969 0.00218969 0.00219464 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00222066 0.00218969 0.00221526 0.00223195 0.00219507\n",
      " 0.00218969 0.00218969 0.00218969 0.00220009 0.00218969 0.00219977\n",
      " 0.00219464 0.00218969 0.00227207 0.00218969 0.00222797 0.00218969\n",
      " 0.00218969 0.00222858 0.00222078 0.00219423 0.00219464 0.00219521\n",
      " 0.00221631 0.00218969 0.00219476 0.00218969 0.00221114 0.00218969\n",
      " 0.00219423 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00220102 0.00219423 0.00218969 0.00218969 0.00221122\n",
      " 0.00220113 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00222157 0.00221973 0.00218969 0.00227257 0.00218969 0.00218969\n",
      " 0.00218969 0.00219464 0.00218969 0.00218969 0.00218969 0.00219423\n",
      " 0.00219897 0.00218969 0.00218969 0.00218969 0.00219458 0.00218969\n",
      " 0.00218969 0.00218969 0.00223857 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00219442 0.00221107 0.00219464 0.00220663 0.00218969\n",
      " 0.00218969 0.002215   0.00218969 0.00224403 0.00221968 0.00219464\n",
      " 0.00219464 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00219982 0.00219474 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00220582 0.00218969 0.00221167 0.00222342 0.00218969\n",
      " 0.00218969 0.00219535 0.00218969 0.00219897 0.00218969 0.00220404\n",
      " 0.00218969 0.00218969 0.0022222  0.00220122 0.00218969 0.00228376\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00220532 0.00218969 0.00219458 0.00218969 0.00218969 0.00218969\n",
      " 0.00220676 0.00218969 0.00218969 0.00219476 0.00219442 0.00218969\n",
      " 0.00222099 0.00218969 0.00218969 0.00218969 0.00218969 0.0022063\n",
      " 0.00218969 0.00220404 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00219474 0.00218969 0.00219423\n",
      " 0.00228887 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00219486\n",
      " 0.00218969 0.00218969 0.00219555 0.00223171 0.00219897 0.00218969\n",
      " 0.00220007 0.00218969 0.00218969 0.00218969 0.00223374 0.00221671\n",
      " 0.00218969 0.00218969 0.0022337  0.00220102 0.00222754 0.00219423\n",
      " 0.00219997 0.00220092 0.00218969 0.00218969 0.0022049  0.0021954\n",
      " 0.0022102  0.00218969 0.00219507 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00220568 0.00218969 0.00220548 0.00218969\n",
      " 0.00220015 0.00223952 0.00220968 0.00218969 0.00219507 0.00218969\n",
      " 0.00220545 0.00218969 0.00218969 0.00218969 0.00218969 0.00220909\n",
      " 0.00218969 0.00218969 0.00221687 0.00225518 0.00218969 0.00220619\n",
      " 0.00219954 0.00223391 0.00220945 0.00218969 0.00218969 0.00222618\n",
      " 0.00219975 0.00219423 0.00218969 0.00218969 0.00225003 0.00219507\n",
      " 0.00218969 0.00220056 0.00218969 0.00218969 0.00218969 0.00219474\n",
      " 0.00219518 0.00218969 0.0022159  0.00218969 0.0021995  0.00219897\n",
      " 0.00218969 0.00218969 0.00219995 0.00218969 0.00220566 0.00218969\n",
      " 0.00218969 0.0021954  0.00222202 0.00219423 0.00218969 0.00218969\n",
      " 0.00218969 0.00221186 0.00218969 0.00219423 0.00218969 0.00219464\n",
      " 0.00218969 0.00218969 0.00225118 0.00218969 0.00225502 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00220603 0.00219474 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00221677 0.0021998  0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00219423 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00220061 0.00218969 0.00221042 0.00218969\n",
      " 0.00222107 0.00220738 0.00218969 0.00218969 0.00218969 0.00219458\n",
      " 0.00218969 0.0022158  0.00218969 0.00223054 0.00219511 0.00220013\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00220085\n",
      " 0.00218969 0.00219518 0.0022058  0.00221983 0.00218969 0.00223761\n",
      " 0.00224656 0.00220445 0.00218969 0.00218969 0.00219423 0.00220914\n",
      " 0.00220678 0.00224402 0.00218969 0.00224985 0.00219423 0.00218969\n",
      " 0.00218969 0.00218969 0.0022195  0.00219423 0.00218969 0.00221146\n",
      " 0.00218969 0.00219929 0.00221246 0.00219518 0.00222205 0.00220488\n",
      " 0.00218969 0.00219423 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00219535\n",
      " 0.00220674 0.00218969 0.00221025 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00219507 0.00218969 0.00218969 0.00219521 0.00219458\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.0021954  0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.0022482  0.00220474 0.00219464\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00223907\n",
      " 0.00218969 0.00218969 0.00219507 0.00218969 0.00219474]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 272, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 210 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  34 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True,  True, False, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                               | 1399/2000 [03:08<01:20,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_19__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-17T21:53:59.583944+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:53:59.586194+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:53:59.587983+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:53:59.590131+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:53:59.593971+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:53:59.595764+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:53:59.597501+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 19 accuracy:  0.9340659340659341\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00222252 0.0021893  0.00219448 0.00220456 0.0021893  0.00219496\n",
      " 0.0021893  0.00219403 0.0021893  0.0021893  0.0021893  0.0022556\n",
      " 0.00223182 0.0021893  0.00226153 0.0021893  0.0021951  0.0021893\n",
      " 0.00223268 0.00219419 0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.00220075 0.0021893  0.0021893  0.00221167\n",
      " 0.0021893  0.002216   0.0021893  0.0021893  0.0021893  0.00219419\n",
      " 0.0021893  0.0021893  0.00223507 0.00220988 0.00219501 0.0021893\n",
      " 0.0021893  0.0021893  0.00219425 0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.00222027 0.0021893  0.00221487 0.00223156 0.00219468\n",
      " 0.0021893  0.0021893  0.0021893  0.0021997  0.0021893  0.00219938\n",
      " 0.00219425 0.0021893  0.00227766 0.0021893  0.00222758 0.0021893\n",
      " 0.0021893  0.00222819 0.00222039 0.00219384 0.00219425 0.00219482\n",
      " 0.00222176 0.0021893  0.00219437 0.0021893  0.00221658 0.0021893\n",
      " 0.00219384 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.00220063 0.00219384 0.0021893  0.0021893  0.00221083\n",
      " 0.00220074 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.00222118 0.00221934 0.0021893  0.00227816 0.0021893  0.0021893\n",
      " 0.0021893  0.00219425 0.0021893  0.0021893  0.0021893  0.00219962\n",
      " 0.00219858 0.0021893  0.0021893  0.0021893  0.00219419 0.0021893\n",
      " 0.0021893  0.0021893  0.00223818 0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.00219403 0.00221068 0.00219425 0.00220624 0.0021893\n",
      " 0.0021893  0.0022146  0.0021893  0.00224955 0.00221929 0.00219425\n",
      " 0.00219425 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.00219943 0.00220014 0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.00220543 0.0021893  0.00221128 0.00222889 0.0021893\n",
      " 0.0021893  0.00219496 0.0021893  0.00219858 0.0021893  0.00220365\n",
      " 0.0021893  0.0021893  0.00222181 0.00220083 0.0021893  0.00228937\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.00220493 0.0021893  0.00219419 0.0021893  0.0021893  0.0021893\n",
      " 0.00220637 0.0021893  0.0021893  0.00219437 0.00219403 0.0021893\n",
      " 0.0022206  0.0021893  0.0021893  0.0021893  0.0021893  0.00220591\n",
      " 0.0021893  0.00220946 0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.00219435 0.0021893  0.00219384\n",
      " 0.0022945  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.00219448\n",
      " 0.0021893  0.0021893  0.00219516 0.00223132 0.00219858 0.0021893\n",
      " 0.00219968 0.0021893  0.0021893  0.0021893  0.00223923 0.00221632\n",
      " 0.0021893  0.0021893  0.0022333  0.00220063 0.00222714 0.00219384\n",
      " 0.00219958 0.00220054 0.0021893  0.0021893  0.00220451 0.00219501\n",
      " 0.00220981 0.0021893  0.00219468 0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0022111  0.0021893  0.00220509 0.0021893\n",
      " 0.00219976 0.00224503 0.00220929 0.0021893  0.00219468 0.0021893\n",
      " 0.00221088 0.0021893  0.0021893  0.0021893  0.0021893  0.0022087\n",
      " 0.0021893  0.0021893  0.00221648 0.00226072 0.0021893  0.0022058\n",
      " 0.00219915 0.00223352 0.00220906 0.0021893  0.0021893  0.00222579\n",
      " 0.00219937 0.00219384 0.0021893  0.0021893  0.00225556 0.00219468\n",
      " 0.0021893  0.00220018 0.0021893  0.0021893  0.0021893  0.00219435\n",
      " 0.00219479 0.0021893  0.0022155  0.0021893  0.00219911 0.00219858\n",
      " 0.0021893  0.0021893  0.00219956 0.0021893  0.00220527 0.0021893\n",
      " 0.0021893  0.00219501 0.00222163 0.00219384 0.0021893  0.0021893\n",
      " 0.0021893  0.00221147 0.0021893  0.00219384 0.0021893  0.00219425\n",
      " 0.0021893  0.0021893  0.00225672 0.0021893  0.00226057 0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.00220564 0.00219435 0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.00222222 0.00219942 0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.00219384 0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.00220022 0.0021893  0.00221003 0.0021893\n",
      " 0.00222068 0.00220699 0.0021893  0.0021893  0.0021893  0.00219419\n",
      " 0.0021893  0.0022154  0.0021893  0.00223602 0.00219473 0.00219974\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.00220046\n",
      " 0.0021893  0.00219479 0.00220541 0.00221944 0.0021893  0.00224311\n",
      " 0.00224616 0.00220987 0.0021893  0.0021893  0.00219384 0.00220875\n",
      " 0.00220639 0.00224954 0.0021893  0.00224945 0.00219384 0.0021893\n",
      " 0.0021893  0.0021893  0.00221911 0.00219384 0.0021893  0.00221107\n",
      " 0.0021893  0.0021989  0.00221207 0.00219479 0.00222166 0.0022045\n",
      " 0.0021893  0.00219384 0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.00219496\n",
      " 0.00220635 0.0021893  0.00220986 0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.00219468 0.0021893  0.0021893  0.00219482 0.00219419\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.00219501 0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0022478  0.00220435 0.00219425\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.00224458\n",
      " 0.0021893  0.0021893  0.00219468 0.0021893  0.00219435]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002633369102196049\n",
      "Finished run 0 / 3\n",
      "Run 2 / 3\n",
      "Boosting iter: 1 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 21/20\n",
      "random state: 20\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  None\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████        | 1899/2000 [03:02<00:09, 10.43it/s]\n",
      "[2023-12-17T21:57:07.770992+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:57:07.773078+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T21:57:07.774338+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T21:57:07.775844+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T21:57:07.778488+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:57:07.780006+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T21:57:07.781252+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_0__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 0 accuracy:  0.9252747252747253\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220292 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00220292 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00220292\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.00251627230906622\n",
      "Boosting iter: 2 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 22/20\n",
      "random state: 21\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220292 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00220292 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00220292\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 253, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 232, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 293 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True, False,  True, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False,  True, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([215, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 1599/2000 [03:28<00:52,  7.66it/s]\n",
      "[2023-12-17T22:00:42.435553+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:00:42.437631+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:00:42.439365+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:00:42.441411+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:00:42.445153+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:00:42.446940+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:00:42.448629+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_1__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 1 accuracy:  0.8879120879120879\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220241 0.00219688 0.00219688 0.00220698 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00220241\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00220143 0.00219688 0.00220241 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00220241 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00220698\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00220698 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00220241 0.00220241 0.00220143\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00220143\n",
      " 0.00220698 0.00220143 0.00219688 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241\n",
      " 0.00219688 0.00219688 0.00220241 0.00220143 0.00219688 0.00220241\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00220143 0.00220143\n",
      " 0.00219688 0.00220143 0.00219688 0.00220698 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00220241 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002069523106334788\n",
      "Boosting iter: 3 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 23/20\n",
      "random state: 22\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220241 0.00219688 0.00219688 0.00220698 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00220241\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00220143 0.00219688 0.00220241 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00220241 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00220698\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00220698 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00220241 0.00220241 0.00220143\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00220143\n",
      " 0.00220698 0.00220143 0.00219688 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241\n",
      " 0.00219688 0.00219688 0.00220241 0.00220143 0.00219688 0.00220241\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00220143 0.00220143\n",
      " 0.00219688 0.00220143 0.00219688 0.00220698 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00220241 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 152, 397, 449,  70,  85,  97, 181,\n",
      "         83, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 232, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 293 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  91   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 158  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 123  59  25 137\n",
      " 119 207 310 316 129 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True,  True, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True, False,  True, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([215, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████████████████▌                                                                                                                                  | 349/2000 [00:44<03:29,  7.90it/s]\n",
      "[2023-12-17T22:01:32.673317+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:01:32.675479+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:01:32.677235+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:01:32.679312+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:01:32.683030+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:01:32.684789+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:01:32.686508+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_2__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 2 accuracy:  0.9296703296703297\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220201 0.00219648 0.00219648 0.00220657 0.00219648 0.00220215\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220215\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00219648\n",
      " 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220201 0.00220215 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00219648 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220215 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.0022077  0.00219648\n",
      " 0.00219648 0.00219648 0.00220672 0.00220103 0.00219648 0.00220201\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201 0.00219648\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220201 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220201 0.00220103 0.00219648 0.00220201 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.0022077  0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220215 0.00220201 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00220103 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00221228\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220201 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00221228 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.0022077  0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00220201 0.00220201 0.00220103\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00219648 0.00220672 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00220103 0.00219648 0.00219648 0.00220672\n",
      " 0.00220657 0.00220103 0.00219648 0.00219648 0.00220672 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.0022077  0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220215 0.00219648 0.00220215 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.0022077  0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220201 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201\n",
      " 0.00219648 0.00219648 0.0022077  0.00220103 0.00219648 0.00220201\n",
      " 0.0022077  0.00219648 0.00219648 0.00219648 0.00220103 0.00220103\n",
      " 0.00219648 0.00220103 0.00219648 0.00220657 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648 0.00220215\n",
      " 0.00219648 0.00220103 0.0022077  0.00219648 0.00220103 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220215\n",
      " 0.00220201 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002580824186467436\n",
      "Boosting iter: 4 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 24/20\n",
      "random state: 23\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220201 0.00219648 0.00219648 0.00220657 0.00219648 0.00220215\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220215\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00219648\n",
      " 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220201 0.00220215 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00219648 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220215 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.0022077  0.00219648\n",
      " 0.00219648 0.00219648 0.00220672 0.00220103 0.00219648 0.00220201\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201 0.00219648\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220201 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220201 0.00220103 0.00219648 0.00220201 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.0022077  0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220215 0.00220201 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00220103 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00221228\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220201 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00221228 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.0022077  0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00220201 0.00220201 0.00220103\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00219648 0.00220672 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00220103 0.00219648 0.00219648 0.00220672\n",
      " 0.00220657 0.00220103 0.00219648 0.00219648 0.00220672 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.0022077  0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220215 0.00219648 0.00220215 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.0022077  0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220201 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201\n",
      " 0.00219648 0.00219648 0.0022077  0.00220103 0.00219648 0.00220201\n",
      " 0.0022077  0.00219648 0.00219648 0.00219648 0.00220103 0.00220103\n",
      " 0.00219648 0.00220103 0.00219648 0.00220657 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648 0.00220215\n",
      " 0.00219648 0.00220103 0.0022077  0.00219648 0.00220103 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220215\n",
      " 0.00220201 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 152, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 293 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 158  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 129 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True,  True, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([215, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                   | 1349/2000 [02:59<01:26,  7.51it/s]\n",
      "[2023-12-17T22:04:38.386754+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:04:38.388854+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:04:38.390570+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:04:38.392612+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:04:38.396220+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:04:38.397960+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:04:38.399606+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_3__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 3 accuracy:  0.9098901098901099\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220155 0.00219602 0.00219602 0.00220611 0.00219602 0.0022017\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220679\n",
      " 0.0022011  0.00219602 0.00220665 0.00219602 0.00219602 0.00219602\n",
      " 0.00220679 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220155 0.00220679 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220679 0.00219602 0.0022011  0.00220566 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.0022017  0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220665 0.00219602 0.00220724 0.00219602\n",
      " 0.00219602 0.00219602 0.00221136 0.00220057 0.00219602 0.00220155\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00220155 0.00219602\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220155 0.00220057 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220155 0.00220057 0.00219602 0.00220665 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00221235 0.00220566 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.0022011  0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.0022011  0.00219602 0.0022017  0.00220155 0.00219602\n",
      " 0.00219602 0.0022017  0.00219602 0.00220057 0.00219602 0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00219602 0.00219602 0.00221181\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220155 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00221693 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00220057 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00221235 0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00220155 0.00220665 0.00220057\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602\n",
      " 0.0022011  0.0022017  0.00220566 0.00219602 0.00219602 0.00219602\n",
      " 0.0022017  0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00219602 0.00219602 0.00219602 0.00221136 0.00219602 0.00219602\n",
      " 0.00219602 0.00220679 0.00220057 0.00219602 0.00219602 0.00221136\n",
      " 0.00220611 0.00220057 0.00219602 0.00219602 0.00221136 0.00219602\n",
      " 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00219602 0.0022011  0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00219602 0.0022011  0.00219602\n",
      " 0.00219602 0.00219602 0.00220566 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00220724 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022017  0.00219602 0.00220679 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00221235 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220155 0.00219602 0.00220566 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220155\n",
      " 0.00219602 0.00219602 0.00220724 0.00220057 0.00219602 0.00220665\n",
      " 0.00220724 0.00219602 0.00219602 0.00219602 0.00220057 0.00220566\n",
      " 0.00219602 0.00220566 0.00219602 0.00220611 0.00220057 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00220057 0.00219602 0.00220679\n",
      " 0.00219602 0.00220057 0.00220724 0.00219602 0.00220057 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.0022017\n",
      " 0.00220155 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00220155 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220566 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.0022011\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0023105879357532355\n",
      "Boosting iter: 5 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 25/20\n",
      "random state: 24\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220155 0.00219602 0.00219602 0.00220611 0.00219602 0.0022017\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220679\n",
      " 0.0022011  0.00219602 0.00220665 0.00219602 0.00219602 0.00219602\n",
      " 0.00220679 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220155 0.00220679 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220679 0.00219602 0.0022011  0.00220566 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.0022017  0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220665 0.00219602 0.00220724 0.00219602\n",
      " 0.00219602 0.00219602 0.00221136 0.00220057 0.00219602 0.00220155\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00220155 0.00219602\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220155 0.00220057 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220155 0.00220057 0.00219602 0.00220665 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00221235 0.00220566 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.0022011  0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.0022011  0.00219602 0.0022017  0.00220155 0.00219602\n",
      " 0.00219602 0.0022017  0.00219602 0.00220057 0.00219602 0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00219602 0.00219602 0.00221181\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220155 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00221693 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00220057 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00221235 0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00220155 0.00220665 0.00220057\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602\n",
      " 0.0022011  0.0022017  0.00220566 0.00219602 0.00219602 0.00219602\n",
      " 0.0022017  0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00219602 0.00219602 0.00219602 0.00221136 0.00219602 0.00219602\n",
      " 0.00219602 0.00220679 0.00220057 0.00219602 0.00219602 0.00221136\n",
      " 0.00220611 0.00220057 0.00219602 0.00219602 0.00221136 0.00219602\n",
      " 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00219602 0.0022011  0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00219602 0.0022011  0.00219602\n",
      " 0.00219602 0.00219602 0.00220566 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00220724 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022017  0.00219602 0.00220679 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00221235 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220155 0.00219602 0.00220566 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220155\n",
      " 0.00219602 0.00219602 0.00220724 0.00220057 0.00219602 0.00220665\n",
      " 0.00220724 0.00219602 0.00219602 0.00219602 0.00220057 0.00220566\n",
      " 0.00219602 0.00220566 0.00219602 0.00220611 0.00220057 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00220057 0.00219602 0.00220679\n",
      " 0.00219602 0.00220057 0.00220724 0.00219602 0.00220057 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.0022017\n",
      " 0.00220155 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00220155 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220566 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.0022011\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 293 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 129 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([214, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                       | 1299/2000 [02:50<01:32,  7.62it/s]\n",
      "[2023-12-17T22:07:34.979356+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:07:34.981436+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:07:34.983194+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:07:34.985268+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:07:34.989191+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:07:34.991032+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:07:34.992727+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_4__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 4 accuracy:  0.9208791208791208\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220112 0.00219559 0.00219559 0.00220568 0.00219559 0.00220127\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00221178\n",
      " 0.00220067 0.00219559 0.00220622 0.00219559 0.00219559 0.00219559\n",
      " 0.00221178 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220112 0.00220636 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220636 0.00219559 0.00220067 0.00221065 0.00220099\n",
      " 0.00219559 0.00219559 0.00219559 0.00220127 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220622 0.00219559 0.00220681 0.00219559\n",
      " 0.00219559 0.00219559 0.00221093 0.00220014 0.00219559 0.00220112\n",
      " 0.00220099 0.00219559 0.00220067 0.00219559 0.00220112 0.00219559\n",
      " 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220112 0.00220014 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220112 0.00220014 0.00219559 0.00221164 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220608 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220555 0.00219559 0.00221192 0.00220523 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220067 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220067 0.00219559 0.00220127 0.00220653 0.00219559\n",
      " 0.00219559 0.00220127 0.00219559 0.00220014 0.00219559 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00220099 0.00219559 0.00221682\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220112 0.00219559 0.00219559 0.00220067 0.00219559 0.00219559\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00220099\n",
      " 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00222194 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00220014 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00221192 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00220112 0.00221164 0.00220014\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220555 0.00219559 0.00220099 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220067 0.00219559 0.00220099 0.00219559\n",
      " 0.00220608 0.00220127 0.00220523 0.00219559 0.00220099 0.00219559\n",
      " 0.00220127 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00219559 0.00219559 0.00219559 0.00221093 0.00219559 0.00220099\n",
      " 0.00219559 0.00221178 0.00220555 0.00219559 0.00219559 0.00221093\n",
      " 0.00220568 0.00220014 0.00219559 0.00219559 0.00221093 0.00220099\n",
      " 0.00219559 0.00220067 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220014 0.00219559 0.00220067 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00219559 0.00220608 0.00219559\n",
      " 0.00219559 0.00219559 0.00220523 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00220681 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220127 0.00219559 0.00220636 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220099 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00220099 0.00219559\n",
      " 0.00221192 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220112 0.00219559 0.00220523 0.00219559 0.00220099\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220112\n",
      " 0.00219559 0.00219559 0.00220681 0.00220014 0.00219559 0.00220622\n",
      " 0.00220681 0.00219559 0.00219559 0.00219559 0.00220014 0.00220523\n",
      " 0.00219559 0.00220523 0.00219559 0.0022111  0.00220014 0.00219559\n",
      " 0.00219559 0.00219559 0.00220555 0.00220014 0.00219559 0.00220636\n",
      " 0.00219559 0.00220014 0.00220681 0.00219559 0.00220014 0.00220099\n",
      " 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220127\n",
      " 0.00220112 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220099 0.00219559 0.00219559 0.00220112 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220523 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220608\n",
      " 0.00219559 0.00219559 0.00220099 0.00219559 0.00219559]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024531187774958023\n",
      "Boosting iter: 6 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 26/20\n",
      "random state: 25\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220112 0.00219559 0.00219559 0.00220568 0.00219559 0.00220127\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00221178\n",
      " 0.00220067 0.00219559 0.00220622 0.00219559 0.00219559 0.00219559\n",
      " 0.00221178 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220112 0.00220636 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220636 0.00219559 0.00220067 0.00221065 0.00220099\n",
      " 0.00219559 0.00219559 0.00219559 0.00220127 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220622 0.00219559 0.00220681 0.00219559\n",
      " 0.00219559 0.00219559 0.00221093 0.00220014 0.00219559 0.00220112\n",
      " 0.00220099 0.00219559 0.00220067 0.00219559 0.00220112 0.00219559\n",
      " 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220112 0.00220014 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220112 0.00220014 0.00219559 0.00221164 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220608 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220555 0.00219559 0.00221192 0.00220523 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220067 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220067 0.00219559 0.00220127 0.00220653 0.00219559\n",
      " 0.00219559 0.00220127 0.00219559 0.00220014 0.00219559 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00220099 0.00219559 0.00221682\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220112 0.00219559 0.00219559 0.00220067 0.00219559 0.00219559\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00220099\n",
      " 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00222194 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00220014 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00221192 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00220112 0.00221164 0.00220014\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220555 0.00219559 0.00220099 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220067 0.00219559 0.00220099 0.00219559\n",
      " 0.00220608 0.00220127 0.00220523 0.00219559 0.00220099 0.00219559\n",
      " 0.00220127 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00219559 0.00219559 0.00219559 0.00221093 0.00219559 0.00220099\n",
      " 0.00219559 0.00221178 0.00220555 0.00219559 0.00219559 0.00221093\n",
      " 0.00220568 0.00220014 0.00219559 0.00219559 0.00221093 0.00220099\n",
      " 0.00219559 0.00220067 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220014 0.00219559 0.00220067 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00219559 0.00220608 0.00219559\n",
      " 0.00219559 0.00219559 0.00220523 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00220681 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220127 0.00219559 0.00220636 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220099 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00220099 0.00219559\n",
      " 0.00221192 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220112 0.00219559 0.00220523 0.00219559 0.00220099\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220112\n",
      " 0.00219559 0.00219559 0.00220681 0.00220014 0.00219559 0.00220622\n",
      " 0.00220681 0.00219559 0.00219559 0.00219559 0.00220014 0.00220523\n",
      " 0.00219559 0.00220523 0.00219559 0.0022111  0.00220014 0.00219559\n",
      " 0.00219559 0.00219559 0.00220555 0.00220014 0.00219559 0.00220636\n",
      " 0.00219559 0.00220014 0.00220681 0.00219559 0.00220014 0.00220099\n",
      " 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220127\n",
      " 0.00220112 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220099 0.00219559 0.00219559 0.00220112 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220523 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220608\n",
      " 0.00219559 0.00219559 0.00220099 0.00219559 0.00219559]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 152, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 293 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 158  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 123  59  25 137\n",
      " 119 207 310 316 129 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True,  True, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([215, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████████████████████████████████████                                                                                       | 899/2000 [01:58<02:25,  7.58it/s]\n",
      "[2023-12-17T22:09:39.607548+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:09:39.609643+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:09:39.611374+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:09:39.613428+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:09:39.617152+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:09:39.618878+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:09:39.620544+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_5__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 5 accuracy:  0.9032967032967033\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220557 0.00219512 0.00219512 0.00220521 0.00219512 0.00220079\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.0022113\n",
      " 0.00220511 0.00219512 0.00221067 0.00219512 0.00219512 0.00219512\n",
      " 0.0022113  0.00220002 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00220079 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220571 0.00219512 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00220065 0.00220588 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00221081 0.00219512 0.00220511 0.00221511 0.00220051\n",
      " 0.00219512 0.00219512 0.00219512 0.00220079 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00221067 0.00219512 0.00220634 0.00219512\n",
      " 0.00219512 0.00220002 0.00221045 0.00219967 0.00219512 0.00220065\n",
      " 0.00220543 0.00219512 0.0022002  0.00219512 0.00220065 0.00219512\n",
      " 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220065 0.00219967 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220557 0.00220458 0.00219512 0.0022161  0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219967\n",
      " 0.00219967 0.00219512 0.00219512 0.00219512 0.00220002 0.00219512\n",
      " 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.0022056  0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220507 0.00219512 0.00221144 0.00220968 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.0022002  0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220511 0.00219512 0.00220079 0.00220605 0.00219512\n",
      " 0.00219512 0.00220079 0.00219512 0.00219967 0.00219512 0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00220051 0.00219512 0.00221634\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220051 0.00219512 0.00220002 0.00219512 0.00219512 0.00219512\n",
      " 0.00220065 0.00219512 0.00219512 0.0022002  0.00219512 0.00219512\n",
      " 0.00220543 0.00219512 0.00219512 0.00219512 0.00219512 0.00220051\n",
      " 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219967\n",
      " 0.00222643 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220458 0.00219967 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00221144 0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00220065 0.0022161  0.00219967\n",
      " 0.00220543 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220507 0.00219512 0.00220051 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.0022002  0.00219512 0.00220051 0.00219512\n",
      " 0.0022056  0.00220571 0.00220968 0.00219512 0.00220051 0.00219512\n",
      " 0.00220571 0.00219512 0.00219512 0.00219512 0.00219512 0.00220458\n",
      " 0.00219512 0.00219512 0.00219512 0.00221539 0.00219512 0.00220051\n",
      " 0.00220002 0.00221624 0.00220507 0.00219512 0.00219512 0.00221539\n",
      " 0.00220521 0.00219967 0.00219512 0.00219512 0.00221045 0.00220051\n",
      " 0.00219512 0.0022002  0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219967 0.00219512 0.0022002  0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00219512 0.0022056  0.00219512\n",
      " 0.00219512 0.00219512 0.00220475 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00220634 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00220571 0.00219512 0.00221081 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220051 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00220051 0.00219512\n",
      " 0.00221144 0.00219512 0.00219512 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00220065 0.00219512 0.00220475 0.00219512 0.00220051\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00220065\n",
      " 0.00219512 0.00219512 0.00221127 0.00219967 0.00219512 0.00220574\n",
      " 0.00221127 0.00219512 0.00219512 0.00219512 0.00219967 0.00220475\n",
      " 0.00219512 0.00220475 0.00219512 0.00221062 0.00219967 0.00219512\n",
      " 0.00219512 0.00219512 0.00221    0.00219967 0.00219512 0.00220588\n",
      " 0.00219512 0.00219967 0.00220634 0.00219512 0.00219967 0.00220051\n",
      " 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00220079\n",
      " 0.00220065 0.00219512 0.00220079 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220051 0.00219512 0.00219512 0.00220065 0.00220002\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220968 0.00220002 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00221053\n",
      " 0.00219512 0.00219512 0.00220051 0.00219512 0.00219512]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0022319271049430866\n",
      "Boosting iter: 7 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 27/20\n",
      "random state: 26\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220557 0.00219512 0.00219512 0.00220521 0.00219512 0.00220079\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.0022113\n",
      " 0.00220511 0.00219512 0.00221067 0.00219512 0.00219512 0.00219512\n",
      " 0.0022113  0.00220002 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00220079 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220571 0.00219512 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00220065 0.00220588 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00221081 0.00219512 0.00220511 0.00221511 0.00220051\n",
      " 0.00219512 0.00219512 0.00219512 0.00220079 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00221067 0.00219512 0.00220634 0.00219512\n",
      " 0.00219512 0.00220002 0.00221045 0.00219967 0.00219512 0.00220065\n",
      " 0.00220543 0.00219512 0.0022002  0.00219512 0.00220065 0.00219512\n",
      " 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220065 0.00219967 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220557 0.00220458 0.00219512 0.0022161  0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219967\n",
      " 0.00219967 0.00219512 0.00219512 0.00219512 0.00220002 0.00219512\n",
      " 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.0022056  0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220507 0.00219512 0.00221144 0.00220968 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.0022002  0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220511 0.00219512 0.00220079 0.00220605 0.00219512\n",
      " 0.00219512 0.00220079 0.00219512 0.00219967 0.00219512 0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00220051 0.00219512 0.00221634\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220051 0.00219512 0.00220002 0.00219512 0.00219512 0.00219512\n",
      " 0.00220065 0.00219512 0.00219512 0.0022002  0.00219512 0.00219512\n",
      " 0.00220543 0.00219512 0.00219512 0.00219512 0.00219512 0.00220051\n",
      " 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219967\n",
      " 0.00222643 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220458 0.00219967 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00221144 0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00220065 0.0022161  0.00219967\n",
      " 0.00220543 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220507 0.00219512 0.00220051 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.0022002  0.00219512 0.00220051 0.00219512\n",
      " 0.0022056  0.00220571 0.00220968 0.00219512 0.00220051 0.00219512\n",
      " 0.00220571 0.00219512 0.00219512 0.00219512 0.00219512 0.00220458\n",
      " 0.00219512 0.00219512 0.00219512 0.00221539 0.00219512 0.00220051\n",
      " 0.00220002 0.00221624 0.00220507 0.00219512 0.00219512 0.00221539\n",
      " 0.00220521 0.00219967 0.00219512 0.00219512 0.00221045 0.00220051\n",
      " 0.00219512 0.0022002  0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219967 0.00219512 0.0022002  0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00219512 0.0022056  0.00219512\n",
      " 0.00219512 0.00219512 0.00220475 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00220634 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00220571 0.00219512 0.00221081 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220051 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00220051 0.00219512\n",
      " 0.00221144 0.00219512 0.00219512 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00220065 0.00219512 0.00220475 0.00219512 0.00220051\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00220065\n",
      " 0.00219512 0.00219512 0.00221127 0.00219967 0.00219512 0.00220574\n",
      " 0.00221127 0.00219512 0.00219512 0.00219512 0.00219967 0.00220475\n",
      " 0.00219512 0.00220475 0.00219512 0.00221062 0.00219967 0.00219512\n",
      " 0.00219512 0.00219512 0.00221    0.00219967 0.00219512 0.00220588\n",
      " 0.00219512 0.00219967 0.00220634 0.00219512 0.00219967 0.00220051\n",
      " 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00220079\n",
      " 0.00220065 0.00219512 0.00220079 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220051 0.00219512 0.00219512 0.00220065 0.00220002\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220968 0.00220002 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00221053\n",
      " 0.00219512 0.00219512 0.00220051 0.00219512 0.00219512]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  67 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([214, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 1749/2000 [03:52<00:33,  7.52it/s]\n",
      "[2023-12-17T22:13:38.323738+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:13:38.325901+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:13:38.327656+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:13:38.329739+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:13:38.333503+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:13:38.335285+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:13:38.336985+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_6__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 6 accuracy:  0.8967032967032967\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220507 0.00219463 0.00219463 0.00220471 0.00219463 0.0022003\n",
      " 0.00219463 0.00219937 0.00219463 0.00219463 0.00219463 0.0022108\n",
      " 0.00220462 0.00219463 0.00221017 0.00219463 0.00219463 0.00219463\n",
      " 0.0022108  0.00219953 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.0022003  0.00219463 0.00219463 0.00219937\n",
      " 0.00219463 0.00220521 0.00219463 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00220016 0.00221015 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00221032 0.00219463 0.00220938 0.00221461 0.00220002\n",
      " 0.00219463 0.00219463 0.00219463 0.00220505 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00221495 0.00219463 0.00220584 0.00219463\n",
      " 0.00219463 0.00219953 0.00220996 0.00219917 0.00219463 0.00220016\n",
      " 0.0022097  0.00219463 0.0021997  0.00219463 0.00220016 0.00219463\n",
      " 0.00219917 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220016 0.00219917 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220507 0.00220885 0.00219463 0.0022156  0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219917\n",
      " 0.00220392 0.00219463 0.00219463 0.00219463 0.00219953 0.00219463\n",
      " 0.00219463 0.00219463 0.00220392 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219937 0.00220987 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220457 0.00219463 0.00221572 0.00221396 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.0021997  0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220462 0.00219463 0.0022003  0.00220556 0.00219463\n",
      " 0.00219463 0.0022003  0.00219463 0.00220392 0.00219463 0.00220392\n",
      " 0.00219463 0.00219463 0.00220016 0.00220002 0.00219463 0.00222063\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220477 0.00219463 0.00219953 0.00219463 0.00219463 0.00219463\n",
      " 0.00220016 0.00219463 0.00219463 0.0021997  0.00219937 0.00219463\n",
      " 0.00220493 0.00219463 0.00219463 0.00219463 0.00219463 0.00220002\n",
      " 0.00219463 0.00220392 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219917\n",
      " 0.00223074 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00220885 0.00220392 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00221094 0.00220392\n",
      " 0.00219463 0.00219463 0.00220016 0.00220016 0.0022156  0.00219917\n",
      " 0.00220493 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220934 0.00219463 0.00220002 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.0021997  0.00219463 0.00220002 0.00219463\n",
      " 0.00220511 0.00220521 0.00220919 0.00219463 0.00220002 0.00219463\n",
      " 0.00220521 0.00219463 0.00219463 0.00219463 0.00219463 0.00220885\n",
      " 0.00219463 0.00219463 0.00219463 0.00221968 0.00219463 0.00220002\n",
      " 0.00219953 0.00221574 0.00220934 0.00219463 0.00219463 0.00221489\n",
      " 0.00220471 0.00219917 0.00219463 0.00219463 0.00221473 0.00220002\n",
      " 0.00219463 0.0021997  0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00220392 0.00219463 0.00220446 0.00220392\n",
      " 0.00219463 0.00219463 0.00220491 0.00219463 0.00220511 0.00219463\n",
      " 0.00219463 0.00219463 0.00220426 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00220584 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00220521 0.00219463 0.00221032 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00220002 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00220002 0.00219463\n",
      " 0.00221572 0.00219463 0.00219463 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00220491 0.00219463 0.00220902 0.00219463 0.00220002\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00220016\n",
      " 0.00219463 0.00219463 0.00221077 0.00220392 0.00219463 0.00221001\n",
      " 0.00221077 0.00219937 0.00219463 0.00219463 0.00219917 0.00220902\n",
      " 0.00219463 0.00220902 0.00219463 0.0022149  0.00219917 0.00219463\n",
      " 0.00219463 0.00219463 0.00221427 0.00219917 0.00219463 0.00220539\n",
      " 0.00219463 0.00219917 0.00220584 0.00219463 0.00220392 0.00220477\n",
      " 0.00219463 0.00219917 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.0022003\n",
      " 0.00220016 0.00219463 0.00220505 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220002 0.00219463 0.00219463 0.00220016 0.00219953\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00221396 0.00219953 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00221003\n",
      " 0.00219463 0.00219463 0.00220002 0.00219463 0.00219463]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0021580214308772787\n",
      "Boosting iter: 8 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 28/20\n",
      "random state: 27\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220507 0.00219463 0.00219463 0.00220471 0.00219463 0.0022003\n",
      " 0.00219463 0.00219937 0.00219463 0.00219463 0.00219463 0.0022108\n",
      " 0.00220462 0.00219463 0.00221017 0.00219463 0.00219463 0.00219463\n",
      " 0.0022108  0.00219953 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.0022003  0.00219463 0.00219463 0.00219937\n",
      " 0.00219463 0.00220521 0.00219463 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00220016 0.00221015 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00221032 0.00219463 0.00220938 0.00221461 0.00220002\n",
      " 0.00219463 0.00219463 0.00219463 0.00220505 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00221495 0.00219463 0.00220584 0.00219463\n",
      " 0.00219463 0.00219953 0.00220996 0.00219917 0.00219463 0.00220016\n",
      " 0.0022097  0.00219463 0.0021997  0.00219463 0.00220016 0.00219463\n",
      " 0.00219917 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220016 0.00219917 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220507 0.00220885 0.00219463 0.0022156  0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219917\n",
      " 0.00220392 0.00219463 0.00219463 0.00219463 0.00219953 0.00219463\n",
      " 0.00219463 0.00219463 0.00220392 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219937 0.00220987 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220457 0.00219463 0.00221572 0.00221396 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.0021997  0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220462 0.00219463 0.0022003  0.00220556 0.00219463\n",
      " 0.00219463 0.0022003  0.00219463 0.00220392 0.00219463 0.00220392\n",
      " 0.00219463 0.00219463 0.00220016 0.00220002 0.00219463 0.00222063\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220477 0.00219463 0.00219953 0.00219463 0.00219463 0.00219463\n",
      " 0.00220016 0.00219463 0.00219463 0.0021997  0.00219937 0.00219463\n",
      " 0.00220493 0.00219463 0.00219463 0.00219463 0.00219463 0.00220002\n",
      " 0.00219463 0.00220392 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219917\n",
      " 0.00223074 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00220885 0.00220392 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00221094 0.00220392\n",
      " 0.00219463 0.00219463 0.00220016 0.00220016 0.0022156  0.00219917\n",
      " 0.00220493 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220934 0.00219463 0.00220002 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.0021997  0.00219463 0.00220002 0.00219463\n",
      " 0.00220511 0.00220521 0.00220919 0.00219463 0.00220002 0.00219463\n",
      " 0.00220521 0.00219463 0.00219463 0.00219463 0.00219463 0.00220885\n",
      " 0.00219463 0.00219463 0.00219463 0.00221968 0.00219463 0.00220002\n",
      " 0.00219953 0.00221574 0.00220934 0.00219463 0.00219463 0.00221489\n",
      " 0.00220471 0.00219917 0.00219463 0.00219463 0.00221473 0.00220002\n",
      " 0.00219463 0.0021997  0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00220392 0.00219463 0.00220446 0.00220392\n",
      " 0.00219463 0.00219463 0.00220491 0.00219463 0.00220511 0.00219463\n",
      " 0.00219463 0.00219463 0.00220426 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00220584 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00220521 0.00219463 0.00221032 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00220002 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00220002 0.00219463\n",
      " 0.00221572 0.00219463 0.00219463 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00220491 0.00219463 0.00220902 0.00219463 0.00220002\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00220016\n",
      " 0.00219463 0.00219463 0.00221077 0.00220392 0.00219463 0.00221001\n",
      " 0.00221077 0.00219937 0.00219463 0.00219463 0.00219917 0.00220902\n",
      " 0.00219463 0.00220902 0.00219463 0.0022149  0.00219917 0.00219463\n",
      " 0.00219463 0.00219463 0.00221427 0.00219917 0.00219463 0.00220539\n",
      " 0.00219463 0.00219917 0.00220584 0.00219463 0.00220392 0.00220477\n",
      " 0.00219463 0.00219917 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.0022003\n",
      " 0.00220016 0.00219463 0.00220505 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220002 0.00219463 0.00219463 0.00220016 0.00219953\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00221396 0.00219953 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00221003\n",
      " 0.00219463 0.00219463 0.00220002 0.00219463 0.00219463]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 158  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([214, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 1499/2000 [03:20<01:07,  7.46it/s]\n",
      "[2023-12-17T22:17:05.350885+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:17:05.352967+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:17:05.354699+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:17:05.356737+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:17:05.360421+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:17:05.362159+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:17:05.363818+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_7__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 7 accuracy:  0.9428571428571428\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220472 0.00219427 0.00219427 0.00220436 0.00219427 0.00219994\n",
      " 0.00219427 0.00219901 0.00219427 0.00219427 0.00219427 0.00221045\n",
      " 0.00220426 0.00219427 0.00221601 0.00219427 0.00219427 0.00219427\n",
      " 0.00221045 0.00219918 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219994 0.00219427 0.00219427 0.00219901\n",
      " 0.00219427 0.00220486 0.00219427 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.0021998  0.0022098  0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00220996 0.00219427 0.00220903 0.00222046 0.00219966\n",
      " 0.00219427 0.00219427 0.00219427 0.0022047  0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.0022208  0.00219427 0.00220549 0.00219427\n",
      " 0.00219427 0.00220534 0.0022096  0.00219882 0.00219427 0.0021998\n",
      " 0.00220934 0.00219427 0.00219935 0.00219427 0.0021998  0.00219427\n",
      " 0.00219882 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.0021998  0.00219882 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220472 0.00220849 0.00219427 0.00222145 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219882\n",
      " 0.00220357 0.00219427 0.00219427 0.00219427 0.00219918 0.00219427\n",
      " 0.00219427 0.00219427 0.00220975 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219901 0.00220951 0.00219427 0.00220042 0.00219427\n",
      " 0.00219427 0.00220422 0.00219427 0.00221536 0.0022136  0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219935 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00220426 0.00219427 0.00220611 0.00220521 0.00219427\n",
      " 0.00219427 0.00219994 0.00219427 0.00220357 0.00219427 0.00220357\n",
      " 0.00219427 0.00219427 0.00220597 0.00220583 0.00219427 0.00222649\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220442 0.00219427 0.00219918 0.00219427 0.00219427 0.00219427\n",
      " 0.0021998  0.00219427 0.00219427 0.00219935 0.00219901 0.00219427\n",
      " 0.00220458 0.00219427 0.00219427 0.00219427 0.00219427 0.00220583\n",
      " 0.00219427 0.00220357 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219882\n",
      " 0.00223663 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00220849 0.00220357 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00221059 0.00220357\n",
      " 0.00219427 0.00219427 0.0021998  0.0021998  0.00222145 0.00219882\n",
      " 0.00220458 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220898 0.00219427 0.00219966 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219935 0.00219427 0.00219966 0.00219427\n",
      " 0.00220475 0.00221104 0.00220883 0.00219427 0.00219966 0.00219427\n",
      " 0.00220486 0.00219427 0.00219427 0.00219427 0.00219427 0.00220849\n",
      " 0.00219427 0.00219427 0.00220042 0.00221932 0.00219427 0.00220583\n",
      " 0.00219918 0.0022216  0.00220898 0.00219427 0.00219427 0.00221454\n",
      " 0.00220436 0.00219882 0.00219427 0.00219427 0.00221437 0.00219966\n",
      " 0.00219427 0.00219935 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00220357 0.00219427 0.0022041  0.00220357\n",
      " 0.00219427 0.00219427 0.00220455 0.00219427 0.00220475 0.00219427\n",
      " 0.00219427 0.00219427 0.00221008 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00220549 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00221104 0.00219427 0.00221615 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219966 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219966 0.00219427\n",
      " 0.00221536 0.00220042 0.00219427 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00220455 0.00219427 0.00220867 0.00219427 0.00219966\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.0021998\n",
      " 0.00219427 0.00219427 0.00221041 0.00220357 0.00219427 0.00220965\n",
      " 0.00221661 0.00219901 0.00219427 0.00219427 0.00219882 0.00220867\n",
      " 0.00220042 0.00221486 0.00219427 0.00222075 0.00219882 0.00219427\n",
      " 0.00219427 0.00219427 0.00221392 0.00219882 0.00219427 0.00220503\n",
      " 0.00219427 0.00219882 0.00220549 0.00219427 0.00220357 0.00220442\n",
      " 0.00219427 0.00219882 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219994\n",
      " 0.0021998  0.00219427 0.0022047  0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219966 0.00219427 0.00219427 0.0021998  0.00219918\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.0022136  0.00219918 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00220968\n",
      " 0.00219427 0.00219427 0.00219966 0.00219427 0.00219427]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0027989634885745187\n",
      "Boosting iter: 9 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 29/20\n",
      "random state: 28\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220472 0.00219427 0.00219427 0.00220436 0.00219427 0.00219994\n",
      " 0.00219427 0.00219901 0.00219427 0.00219427 0.00219427 0.00221045\n",
      " 0.00220426 0.00219427 0.00221601 0.00219427 0.00219427 0.00219427\n",
      " 0.00221045 0.00219918 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219994 0.00219427 0.00219427 0.00219901\n",
      " 0.00219427 0.00220486 0.00219427 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.0021998  0.0022098  0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00220996 0.00219427 0.00220903 0.00222046 0.00219966\n",
      " 0.00219427 0.00219427 0.00219427 0.0022047  0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.0022208  0.00219427 0.00220549 0.00219427\n",
      " 0.00219427 0.00220534 0.0022096  0.00219882 0.00219427 0.0021998\n",
      " 0.00220934 0.00219427 0.00219935 0.00219427 0.0021998  0.00219427\n",
      " 0.00219882 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.0021998  0.00219882 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220472 0.00220849 0.00219427 0.00222145 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219882\n",
      " 0.00220357 0.00219427 0.00219427 0.00219427 0.00219918 0.00219427\n",
      " 0.00219427 0.00219427 0.00220975 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219901 0.00220951 0.00219427 0.00220042 0.00219427\n",
      " 0.00219427 0.00220422 0.00219427 0.00221536 0.0022136  0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219935 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00220426 0.00219427 0.00220611 0.00220521 0.00219427\n",
      " 0.00219427 0.00219994 0.00219427 0.00220357 0.00219427 0.00220357\n",
      " 0.00219427 0.00219427 0.00220597 0.00220583 0.00219427 0.00222649\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220442 0.00219427 0.00219918 0.00219427 0.00219427 0.00219427\n",
      " 0.0021998  0.00219427 0.00219427 0.00219935 0.00219901 0.00219427\n",
      " 0.00220458 0.00219427 0.00219427 0.00219427 0.00219427 0.00220583\n",
      " 0.00219427 0.00220357 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219882\n",
      " 0.00223663 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00220849 0.00220357 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00221059 0.00220357\n",
      " 0.00219427 0.00219427 0.0021998  0.0021998  0.00222145 0.00219882\n",
      " 0.00220458 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220898 0.00219427 0.00219966 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219935 0.00219427 0.00219966 0.00219427\n",
      " 0.00220475 0.00221104 0.00220883 0.00219427 0.00219966 0.00219427\n",
      " 0.00220486 0.00219427 0.00219427 0.00219427 0.00219427 0.00220849\n",
      " 0.00219427 0.00219427 0.00220042 0.00221932 0.00219427 0.00220583\n",
      " 0.00219918 0.0022216  0.00220898 0.00219427 0.00219427 0.00221454\n",
      " 0.00220436 0.00219882 0.00219427 0.00219427 0.00221437 0.00219966\n",
      " 0.00219427 0.00219935 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00220357 0.00219427 0.0022041  0.00220357\n",
      " 0.00219427 0.00219427 0.00220455 0.00219427 0.00220475 0.00219427\n",
      " 0.00219427 0.00219427 0.00221008 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00220549 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00221104 0.00219427 0.00221615 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219966 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219966 0.00219427\n",
      " 0.00221536 0.00220042 0.00219427 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00220455 0.00219427 0.00220867 0.00219427 0.00219966\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.0021998\n",
      " 0.00219427 0.00219427 0.00221041 0.00220357 0.00219427 0.00220965\n",
      " 0.00221661 0.00219901 0.00219427 0.00219427 0.00219882 0.00220867\n",
      " 0.00220042 0.00221486 0.00219427 0.00222075 0.00219882 0.00219427\n",
      " 0.00219427 0.00219427 0.00221392 0.00219882 0.00219427 0.00220503\n",
      " 0.00219427 0.00219882 0.00220549 0.00219427 0.00220357 0.00220442\n",
      " 0.00219427 0.00219882 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219994\n",
      " 0.0021998  0.00219427 0.0022047  0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219966 0.00219427 0.00219427 0.0021998  0.00219918\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.0022136  0.00219918 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00220968\n",
      " 0.00219427 0.00219427 0.00219966 0.00219427 0.00219427]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 152, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 158  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 123  59  25 137\n",
      " 119 207 310 316 129 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True,  True, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([215, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████████████████▉                                                                               | 999/2000 [02:09<02:09,  7.72it/s]\n",
      "[2023-12-17T22:19:20.767905+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:19:20.770051+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:19:20.771787+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:19:20.773841+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:19:20.777518+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:19:20.779271+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:19:20.780973+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_8__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 8 accuracy:  0.9054945054945055\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220425 0.0021938  0.0021938  0.00220389 0.0021938  0.00219947\n",
      " 0.0021938  0.00219854 0.0021938  0.0021938  0.0021938  0.00221497\n",
      " 0.00220877 0.0021938  0.00222054 0.0021938  0.0021938  0.0021938\n",
      " 0.00221497 0.00219871 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219947 0.0021938  0.0021938  0.00219854\n",
      " 0.0021938  0.00220439 0.0021938  0.0021938  0.0021938  0.00219871\n",
      " 0.0021938  0.0021938  0.0022043  0.00220932 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219876 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00221448 0.0021938  0.00220855 0.00221999 0.00219919\n",
      " 0.0021938  0.0021938  0.0021938  0.00220422 0.0021938  0.00219871\n",
      " 0.00219876 0.0021938  0.00222534 0.0021938  0.00221    0.0021938\n",
      " 0.0021938  0.00220985 0.00220913 0.00219835 0.00219876 0.00219933\n",
      " 0.00220887 0.0021938  0.00219888 0.0021938  0.0022043  0.0021938\n",
      " 0.00219835 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219933 0.00219835 0.0021938  0.0021938  0.00220367\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00220922 0.00220802 0.0021938  0.002226   0.0021938  0.0021938\n",
      " 0.0021938  0.00219876 0.0021938  0.0021938  0.0021938  0.00219835\n",
      " 0.0022031  0.0021938  0.0021938  0.0021938  0.00219871 0.0021938\n",
      " 0.0021938  0.0021938  0.00220927 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219854 0.00220904 0.00219876 0.00219995 0.0021938\n",
      " 0.0021938  0.00220375 0.0021938  0.00221989 0.00221313 0.00219876\n",
      " 0.00219876 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00219888 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00220379 0.0021938  0.00220564 0.00220473 0.0021938\n",
      " 0.0021938  0.00219947 0.0021938  0.0022031  0.0021938  0.0022031\n",
      " 0.0021938  0.0021938  0.00221048 0.00220536 0.0021938  0.00223104\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00220394 0.0021938  0.00219871 0.0021938  0.0021938  0.0021938\n",
      " 0.00219933 0.0021938  0.0021938  0.00219888 0.00219854 0.0021938\n",
      " 0.00220908 0.0021938  0.0021938  0.0021938  0.0021938  0.00220536\n",
      " 0.0021938  0.0022031  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219835\n",
      " 0.0022412  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00220802 0.0022031  0.0021938\n",
      " 0.00219876 0.0021938  0.0021938  0.0021938  0.00221012 0.0022031\n",
      " 0.0021938  0.0021938  0.0022043  0.00219933 0.002226   0.00219835\n",
      " 0.00220411 0.0021938  0.0021938  0.0021938  0.00219876 0.0021938\n",
      " 0.00220851 0.0021938  0.00219919 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219888 0.0021938  0.00220416 0.0021938\n",
      " 0.00220428 0.00221556 0.00220836 0.0021938  0.00219919 0.0021938\n",
      " 0.00220439 0.0021938  0.0021938  0.0021938  0.0021938  0.00220802\n",
      " 0.0021938  0.0021938  0.00220492 0.00221885 0.0021938  0.00221034\n",
      " 0.00220367 0.00222112 0.00220851 0.0021938  0.0021938  0.00221406\n",
      " 0.00220389 0.00219835 0.0021938  0.0021938  0.0022139  0.00219919\n",
      " 0.0021938  0.00219888 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0022031  0.0021938  0.00220363 0.0022031\n",
      " 0.0021938  0.0021938  0.00220408 0.0021938  0.00220428 0.0021938\n",
      " 0.0021938  0.0021938  0.00220961 0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.00220501 0.0021938  0.00219835 0.0021938  0.00219876\n",
      " 0.0021938  0.0021938  0.00221556 0.0021938  0.00222068 0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00220416 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.00219919 0.0021938\n",
      " 0.00221489 0.00219995 0.0021938  0.0021938  0.0021938  0.00219871\n",
      " 0.0021938  0.00220408 0.0021938  0.00220819 0.0021938  0.00219919\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219933\n",
      " 0.0021938  0.0021938  0.00220994 0.0022031  0.0021938  0.00221417\n",
      " 0.00221614 0.00220351 0.0021938  0.0021938  0.00219835 0.00220819\n",
      " 0.00219995 0.00221438 0.0021938  0.00222028 0.00219835 0.0021938\n",
      " 0.0021938  0.0021938  0.00221344 0.00219835 0.0021938  0.00220456\n",
      " 0.0021938  0.00219835 0.00220501 0.0021938  0.0022031  0.00220394\n",
      " 0.0021938  0.00219835 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219947\n",
      " 0.00219933 0.0021938  0.00220422 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219919 0.0021938  0.0021938  0.00219933 0.00219871\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00221813 0.00220367 0.00219876\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0022092\n",
      " 0.0021938  0.0021938  0.00219919 0.0021938  0.0021938 ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002256159830820475\n",
      "Boosting iter: 10 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 30/20\n",
      "random state: 29\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220425 0.0021938  0.0021938  0.00220389 0.0021938  0.00219947\n",
      " 0.0021938  0.00219854 0.0021938  0.0021938  0.0021938  0.00221497\n",
      " 0.00220877 0.0021938  0.00222054 0.0021938  0.0021938  0.0021938\n",
      " 0.00221497 0.00219871 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219947 0.0021938  0.0021938  0.00219854\n",
      " 0.0021938  0.00220439 0.0021938  0.0021938  0.0021938  0.00219871\n",
      " 0.0021938  0.0021938  0.0022043  0.00220932 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219876 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00221448 0.0021938  0.00220855 0.00221999 0.00219919\n",
      " 0.0021938  0.0021938  0.0021938  0.00220422 0.0021938  0.00219871\n",
      " 0.00219876 0.0021938  0.00222534 0.0021938  0.00221    0.0021938\n",
      " 0.0021938  0.00220985 0.00220913 0.00219835 0.00219876 0.00219933\n",
      " 0.00220887 0.0021938  0.00219888 0.0021938  0.0022043  0.0021938\n",
      " 0.00219835 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219933 0.00219835 0.0021938  0.0021938  0.00220367\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00220922 0.00220802 0.0021938  0.002226   0.0021938  0.0021938\n",
      " 0.0021938  0.00219876 0.0021938  0.0021938  0.0021938  0.00219835\n",
      " 0.0022031  0.0021938  0.0021938  0.0021938  0.00219871 0.0021938\n",
      " 0.0021938  0.0021938  0.00220927 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219854 0.00220904 0.00219876 0.00219995 0.0021938\n",
      " 0.0021938  0.00220375 0.0021938  0.00221989 0.00221313 0.00219876\n",
      " 0.00219876 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00219888 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00220379 0.0021938  0.00220564 0.00220473 0.0021938\n",
      " 0.0021938  0.00219947 0.0021938  0.0022031  0.0021938  0.0022031\n",
      " 0.0021938  0.0021938  0.00221048 0.00220536 0.0021938  0.00223104\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00220394 0.0021938  0.00219871 0.0021938  0.0021938  0.0021938\n",
      " 0.00219933 0.0021938  0.0021938  0.00219888 0.00219854 0.0021938\n",
      " 0.00220908 0.0021938  0.0021938  0.0021938  0.0021938  0.00220536\n",
      " 0.0021938  0.0022031  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219835\n",
      " 0.0022412  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00220802 0.0022031  0.0021938\n",
      " 0.00219876 0.0021938  0.0021938  0.0021938  0.00221012 0.0022031\n",
      " 0.0021938  0.0021938  0.0022043  0.00219933 0.002226   0.00219835\n",
      " 0.00220411 0.0021938  0.0021938  0.0021938  0.00219876 0.0021938\n",
      " 0.00220851 0.0021938  0.00219919 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219888 0.0021938  0.00220416 0.0021938\n",
      " 0.00220428 0.00221556 0.00220836 0.0021938  0.00219919 0.0021938\n",
      " 0.00220439 0.0021938  0.0021938  0.0021938  0.0021938  0.00220802\n",
      " 0.0021938  0.0021938  0.00220492 0.00221885 0.0021938  0.00221034\n",
      " 0.00220367 0.00222112 0.00220851 0.0021938  0.0021938  0.00221406\n",
      " 0.00220389 0.00219835 0.0021938  0.0021938  0.0022139  0.00219919\n",
      " 0.0021938  0.00219888 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0022031  0.0021938  0.00220363 0.0022031\n",
      " 0.0021938  0.0021938  0.00220408 0.0021938  0.00220428 0.0021938\n",
      " 0.0021938  0.0021938  0.00220961 0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.00220501 0.0021938  0.00219835 0.0021938  0.00219876\n",
      " 0.0021938  0.0021938  0.00221556 0.0021938  0.00222068 0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00220416 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.00219919 0.0021938\n",
      " 0.00221489 0.00219995 0.0021938  0.0021938  0.0021938  0.00219871\n",
      " 0.0021938  0.00220408 0.0021938  0.00220819 0.0021938  0.00219919\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219933\n",
      " 0.0021938  0.0021938  0.00220994 0.0022031  0.0021938  0.00221417\n",
      " 0.00221614 0.00220351 0.0021938  0.0021938  0.00219835 0.00220819\n",
      " 0.00219995 0.00221438 0.0021938  0.00222028 0.00219835 0.0021938\n",
      " 0.0021938  0.0021938  0.00221344 0.00219835 0.0021938  0.00220456\n",
      " 0.0021938  0.00219835 0.00220501 0.0021938  0.0022031  0.00220394\n",
      " 0.0021938  0.00219835 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219947\n",
      " 0.00219933 0.0021938  0.00220422 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219919 0.0021938  0.0021938  0.00219933 0.00219871\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00221813 0.00220367 0.00219876\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0022092\n",
      " 0.0021938  0.0021938  0.00219919 0.0021938  0.0021938 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([212, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████████████████████████████████████                                                                                       | 899/2000 [01:59<02:25,  7.55it/s]\n",
      "[2023-12-17T22:21:25.860887+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:21:25.862424+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:21:25.867103+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:21:25.870970+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:21:25.874707+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:21:25.876475+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:21:25.877958+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_9__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 9 accuracy:  0.9428571428571428\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220389 0.00219345 0.00219345 0.00220353 0.00219345 0.00219912\n",
      " 0.00219345 0.00219819 0.00219345 0.00219345 0.00219345 0.00221461\n",
      " 0.0022146  0.00219345 0.0022264  0.00219345 0.00219345 0.00219345\n",
      " 0.00221461 0.00219835 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219912 0.00219345 0.00219345 0.00220434\n",
      " 0.00219345 0.00220403 0.00219345 0.00219345 0.00219345 0.00219835\n",
      " 0.00219345 0.00219345 0.00221011 0.00220897 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.0021984  0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00221412 0.00219345 0.0022082  0.00221963 0.00219884\n",
      " 0.00219345 0.00219345 0.00219345 0.00220387 0.00219345 0.00219835\n",
      " 0.0021984  0.00219345 0.00223121 0.00219345 0.00220964 0.00219345\n",
      " 0.00219345 0.00220949 0.00220877 0.00219799 0.0021984  0.00219898\n",
      " 0.00220851 0.00219345 0.00219852 0.00219345 0.00220394 0.00219345\n",
      " 0.00219799 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219898 0.00219799 0.00219345 0.00219345 0.00220949\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00220887 0.00220767 0.00219345 0.00223187 0.00219345 0.00219345\n",
      " 0.00219345 0.0021984  0.00219345 0.00219345 0.00219345 0.00219799\n",
      " 0.00220274 0.00219345 0.00219345 0.00219345 0.00219835 0.00219345\n",
      " 0.00219345 0.00219345 0.0022151  0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219819 0.00221487 0.0021984  0.0021996  0.00219345\n",
      " 0.00219345 0.00220339 0.00219345 0.00221954 0.00221277 0.0021984\n",
      " 0.0021984  0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219852 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00220961 0.00219345 0.00220528 0.00220438 0.00219345\n",
      " 0.00219345 0.00219912 0.00219345 0.00220274 0.00219345 0.00220274\n",
      " 0.00219345 0.00219345 0.00221012 0.002205   0.00219345 0.00223693\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00220359 0.00219345 0.00219835 0.00219345 0.00219345 0.00219345\n",
      " 0.00219898 0.00219345 0.00219345 0.00219852 0.00219819 0.00219345\n",
      " 0.00220873 0.00219345 0.00219345 0.00219345 0.00219345 0.002205\n",
      " 0.00219345 0.00220274 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219799\n",
      " 0.00224712 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00221385 0.00220274 0.00219345\n",
      " 0.0021984  0.00219345 0.00219345 0.00219345 0.00220976 0.00220891\n",
      " 0.00219345 0.00219345 0.00220394 0.00219898 0.00222564 0.00219799\n",
      " 0.00220375 0.00219345 0.00219345 0.00219345 0.0021984  0.00219345\n",
      " 0.00220815 0.00219345 0.00219884 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219852 0.00219345 0.0022038  0.00219345\n",
      " 0.00220392 0.0022214  0.002208   0.00219345 0.00219884 0.00219345\n",
      " 0.00220403 0.00219345 0.00219345 0.00219345 0.00219345 0.00220767\n",
      " 0.00219345 0.00219345 0.00220457 0.0022247  0.00219345 0.00220998\n",
      " 0.00220332 0.00222076 0.00220815 0.00219345 0.00219345 0.00221371\n",
      " 0.00220353 0.00219799 0.00219345 0.00219345 0.00221974 0.00219884\n",
      " 0.00219345 0.00219852 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00220891 0.00219345 0.00220327 0.00220274\n",
      " 0.00219345 0.00219345 0.00220373 0.00219345 0.00220392 0.00219345\n",
      " 0.00219345 0.00219345 0.00220925 0.00219799 0.00219345 0.00219345\n",
      " 0.00219345 0.00220466 0.00219345 0.00219799 0.00219345 0.0021984\n",
      " 0.00219345 0.00219345 0.0022214  0.00219345 0.00222033 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00220415 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.0022038  0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219799 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219884 0.00219345\n",
      " 0.00221453 0.0021996  0.00219345 0.00219345 0.00219345 0.00219835\n",
      " 0.00219345 0.00220373 0.00219345 0.00220784 0.00219345 0.00219884\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219898\n",
      " 0.00219345 0.00219345 0.00220959 0.00220274 0.00219345 0.00221381\n",
      " 0.00222198 0.00220315 0.00219345 0.00219345 0.00219799 0.00220784\n",
      " 0.0021996  0.00222023 0.00219345 0.00222614 0.00219799 0.00219345\n",
      " 0.00219345 0.00219345 0.00221309 0.00219799 0.00219345 0.00220421\n",
      " 0.00219345 0.00219799 0.00220466 0.00219345 0.00220891 0.00220359\n",
      " 0.00219345 0.00219799 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219912\n",
      " 0.00219898 0.00219345 0.00220387 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219884 0.00219345 0.00219345 0.00219898 0.00219835\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00222398 0.00220332 0.0021984\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00221503\n",
      " 0.00219345 0.00219345 0.00219884 0.00219345 0.00219345]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0027960283714454385\n",
      "Boosting iter: 11 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 31/20\n",
      "random state: 30\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220389 0.00219345 0.00219345 0.00220353 0.00219345 0.00219912\n",
      " 0.00219345 0.00219819 0.00219345 0.00219345 0.00219345 0.00221461\n",
      " 0.0022146  0.00219345 0.0022264  0.00219345 0.00219345 0.00219345\n",
      " 0.00221461 0.00219835 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219912 0.00219345 0.00219345 0.00220434\n",
      " 0.00219345 0.00220403 0.00219345 0.00219345 0.00219345 0.00219835\n",
      " 0.00219345 0.00219345 0.00221011 0.00220897 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.0021984  0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00221412 0.00219345 0.0022082  0.00221963 0.00219884\n",
      " 0.00219345 0.00219345 0.00219345 0.00220387 0.00219345 0.00219835\n",
      " 0.0021984  0.00219345 0.00223121 0.00219345 0.00220964 0.00219345\n",
      " 0.00219345 0.00220949 0.00220877 0.00219799 0.0021984  0.00219898\n",
      " 0.00220851 0.00219345 0.00219852 0.00219345 0.00220394 0.00219345\n",
      " 0.00219799 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219898 0.00219799 0.00219345 0.00219345 0.00220949\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00220887 0.00220767 0.00219345 0.00223187 0.00219345 0.00219345\n",
      " 0.00219345 0.0021984  0.00219345 0.00219345 0.00219345 0.00219799\n",
      " 0.00220274 0.00219345 0.00219345 0.00219345 0.00219835 0.00219345\n",
      " 0.00219345 0.00219345 0.0022151  0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219819 0.00221487 0.0021984  0.0021996  0.00219345\n",
      " 0.00219345 0.00220339 0.00219345 0.00221954 0.00221277 0.0021984\n",
      " 0.0021984  0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219852 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00220961 0.00219345 0.00220528 0.00220438 0.00219345\n",
      " 0.00219345 0.00219912 0.00219345 0.00220274 0.00219345 0.00220274\n",
      " 0.00219345 0.00219345 0.00221012 0.002205   0.00219345 0.00223693\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00220359 0.00219345 0.00219835 0.00219345 0.00219345 0.00219345\n",
      " 0.00219898 0.00219345 0.00219345 0.00219852 0.00219819 0.00219345\n",
      " 0.00220873 0.00219345 0.00219345 0.00219345 0.00219345 0.002205\n",
      " 0.00219345 0.00220274 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219799\n",
      " 0.00224712 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00221385 0.00220274 0.00219345\n",
      " 0.0021984  0.00219345 0.00219345 0.00219345 0.00220976 0.00220891\n",
      " 0.00219345 0.00219345 0.00220394 0.00219898 0.00222564 0.00219799\n",
      " 0.00220375 0.00219345 0.00219345 0.00219345 0.0021984  0.00219345\n",
      " 0.00220815 0.00219345 0.00219884 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219852 0.00219345 0.0022038  0.00219345\n",
      " 0.00220392 0.0022214  0.002208   0.00219345 0.00219884 0.00219345\n",
      " 0.00220403 0.00219345 0.00219345 0.00219345 0.00219345 0.00220767\n",
      " 0.00219345 0.00219345 0.00220457 0.0022247  0.00219345 0.00220998\n",
      " 0.00220332 0.00222076 0.00220815 0.00219345 0.00219345 0.00221371\n",
      " 0.00220353 0.00219799 0.00219345 0.00219345 0.00221974 0.00219884\n",
      " 0.00219345 0.00219852 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00220891 0.00219345 0.00220327 0.00220274\n",
      " 0.00219345 0.00219345 0.00220373 0.00219345 0.00220392 0.00219345\n",
      " 0.00219345 0.00219345 0.00220925 0.00219799 0.00219345 0.00219345\n",
      " 0.00219345 0.00220466 0.00219345 0.00219799 0.00219345 0.0021984\n",
      " 0.00219345 0.00219345 0.0022214  0.00219345 0.00222033 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00220415 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.0022038  0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219799 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219884 0.00219345\n",
      " 0.00221453 0.0021996  0.00219345 0.00219345 0.00219345 0.00219835\n",
      " 0.00219345 0.00220373 0.00219345 0.00220784 0.00219345 0.00219884\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219898\n",
      " 0.00219345 0.00219345 0.00220959 0.00220274 0.00219345 0.00221381\n",
      " 0.00222198 0.00220315 0.00219345 0.00219345 0.00219799 0.00220784\n",
      " 0.0021996  0.00222023 0.00219345 0.00222614 0.00219799 0.00219345\n",
      " 0.00219345 0.00219345 0.00221309 0.00219799 0.00219345 0.00220421\n",
      " 0.00219345 0.00219799 0.00220466 0.00219345 0.00220891 0.00220359\n",
      " 0.00219345 0.00219799 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219912\n",
      " 0.00219898 0.00219345 0.00220387 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219884 0.00219345 0.00219345 0.00219898 0.00219835\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00222398 0.00220332 0.0021984\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00221503\n",
      " 0.00219345 0.00219345 0.00219884 0.00219345 0.00219345]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████▌                                                                                                                              | 399/2000 [00:51<03:27,  7.72it/s]\n",
      "[2023-12-17T22:22:23.621012+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:22:23.623209+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:22:23.624983+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:22:23.627082+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:22:23.630821+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:22:23.632574+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:22:23.634322+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_10__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 10 accuracy:  0.9142857142857143\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220344 0.002193   0.00219818 0.00220829 0.002193   0.00219867\n",
      " 0.002193   0.00219774 0.002193   0.002193   0.002193   0.00221416\n",
      " 0.00221938 0.002193   0.0022312  0.002193   0.002193   0.002193\n",
      " 0.00221416 0.0021979  0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00219867 0.002193   0.002193   0.00220389\n",
      " 0.002193   0.00220879 0.002193   0.002193   0.002193   0.0021979\n",
      " 0.002193   0.002193   0.00220966 0.00220852 0.002193   0.002193\n",
      " 0.002193   0.002193   0.00219796 0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.0022189  0.002193   0.00220775 0.00221918 0.00219839\n",
      " 0.002193   0.002193   0.002193   0.00220342 0.002193   0.0022031\n",
      " 0.00219796 0.002193   0.00223602 0.002193   0.00221441 0.002193\n",
      " 0.002193   0.00220904 0.00221354 0.00219755 0.00219796 0.00219853\n",
      " 0.00220806 0.002193   0.00219808 0.002193   0.00220349 0.002193\n",
      " 0.00219755 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219853 0.00219755 0.002193   0.002193   0.00220904\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00220842 0.00221243 0.002193   0.00223668 0.002193   0.002193\n",
      " 0.002193   0.00219796 0.002193   0.002193   0.002193   0.00219755\n",
      " 0.00220229 0.002193   0.002193   0.002193   0.0021979  0.002193\n",
      " 0.002193   0.002193   0.00221465 0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219774 0.00221442 0.00219796 0.00219915 0.002193\n",
      " 0.002193   0.00220815 0.002193   0.00221908 0.00221755 0.00219796\n",
      " 0.00219796 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00219808 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.00220916 0.002193   0.00220483 0.00220393 0.002193\n",
      " 0.002193   0.00219867 0.002193   0.00220229 0.002193   0.00220229\n",
      " 0.002193   0.002193   0.00221489 0.00220455 0.002193   0.00224176\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00220314 0.002193   0.0021979  0.002193   0.002193   0.002193\n",
      " 0.00219853 0.002193   0.002193   0.00219808 0.00219774 0.002193\n",
      " 0.00220828 0.002193   0.002193   0.002193   0.002193   0.00220455\n",
      " 0.002193   0.00220229 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219755\n",
      " 0.00225197 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219818\n",
      " 0.002193   0.002193   0.002193   0.0022134  0.00220229 0.002193\n",
      " 0.00219796 0.002193   0.002193   0.002193   0.00221453 0.00220846\n",
      " 0.002193   0.002193   0.00220349 0.00219853 0.00222518 0.00219755\n",
      " 0.0022033  0.002193   0.002193   0.002193   0.00220315 0.002193\n",
      " 0.0022077  0.002193   0.00219839 0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00220327 0.002193   0.00220336 0.002193\n",
      " 0.00220348 0.0022262  0.00220755 0.002193   0.00219839 0.002193\n",
      " 0.00220879 0.002193   0.002193   0.002193   0.002193   0.00221243\n",
      " 0.002193   0.002193   0.00220412 0.0022295  0.002193   0.00220953\n",
      " 0.00220287 0.00222031 0.0022077  0.002193   0.002193   0.00221849\n",
      " 0.00220308 0.00219755 0.002193   0.002193   0.00221929 0.00219839\n",
      " 0.002193   0.00219808 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00220846 0.002193   0.00220283 0.00220229\n",
      " 0.002193   0.002193   0.00220328 0.002193   0.00220348 0.002193\n",
      " 0.002193   0.002193   0.0022088  0.00219755 0.002193   0.002193\n",
      " 0.002193   0.00220421 0.002193   0.00219755 0.002193   0.00219796\n",
      " 0.002193   0.002193   0.00222095 0.002193   0.00222512 0.002193\n",
      " 0.002193   0.002193   0.002193   0.0022037  0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00220336 0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00219755 0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.00220358 0.002193\n",
      " 0.00221931 0.00219915 0.002193   0.002193   0.002193   0.0021979\n",
      " 0.002193   0.00220328 0.002193   0.0022126  0.002193   0.00219839\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219853\n",
      " 0.002193   0.002193   0.00220914 0.0022075  0.002193   0.00221859\n",
      " 0.00222678 0.00220271 0.002193   0.002193   0.00219755 0.00220739\n",
      " 0.00219915 0.00222502 0.002193   0.00223094 0.00219755 0.002193\n",
      " 0.002193   0.002193   0.00221264 0.00219755 0.002193   0.00220896\n",
      " 0.002193   0.00219755 0.00220421 0.002193   0.00220846 0.00220314\n",
      " 0.002193   0.00219755 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219867\n",
      " 0.00219853 0.002193   0.00220342 0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219839 0.002193   0.002193   0.00219853 0.0021979\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00222878 0.00220807 0.00219796\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00221981\n",
      " 0.002193   0.002193   0.00219839 0.002193   0.002193  ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0023596904453190145\n",
      "Boosting iter: 12 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 32/20\n",
      "random state: 31\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220344 0.002193   0.00219818 0.00220829 0.002193   0.00219867\n",
      " 0.002193   0.00219774 0.002193   0.002193   0.002193   0.00221416\n",
      " 0.00221938 0.002193   0.0022312  0.002193   0.002193   0.002193\n",
      " 0.00221416 0.0021979  0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00219867 0.002193   0.002193   0.00220389\n",
      " 0.002193   0.00220879 0.002193   0.002193   0.002193   0.0021979\n",
      " 0.002193   0.002193   0.00220966 0.00220852 0.002193   0.002193\n",
      " 0.002193   0.002193   0.00219796 0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.0022189  0.002193   0.00220775 0.00221918 0.00219839\n",
      " 0.002193   0.002193   0.002193   0.00220342 0.002193   0.0022031\n",
      " 0.00219796 0.002193   0.00223602 0.002193   0.00221441 0.002193\n",
      " 0.002193   0.00220904 0.00221354 0.00219755 0.00219796 0.00219853\n",
      " 0.00220806 0.002193   0.00219808 0.002193   0.00220349 0.002193\n",
      " 0.00219755 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219853 0.00219755 0.002193   0.002193   0.00220904\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00220842 0.00221243 0.002193   0.00223668 0.002193   0.002193\n",
      " 0.002193   0.00219796 0.002193   0.002193   0.002193   0.00219755\n",
      " 0.00220229 0.002193   0.002193   0.002193   0.0021979  0.002193\n",
      " 0.002193   0.002193   0.00221465 0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219774 0.00221442 0.00219796 0.00219915 0.002193\n",
      " 0.002193   0.00220815 0.002193   0.00221908 0.00221755 0.00219796\n",
      " 0.00219796 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00219808 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.00220916 0.002193   0.00220483 0.00220393 0.002193\n",
      " 0.002193   0.00219867 0.002193   0.00220229 0.002193   0.00220229\n",
      " 0.002193   0.002193   0.00221489 0.00220455 0.002193   0.00224176\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00220314 0.002193   0.0021979  0.002193   0.002193   0.002193\n",
      " 0.00219853 0.002193   0.002193   0.00219808 0.00219774 0.002193\n",
      " 0.00220828 0.002193   0.002193   0.002193   0.002193   0.00220455\n",
      " 0.002193   0.00220229 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219755\n",
      " 0.00225197 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219818\n",
      " 0.002193   0.002193   0.002193   0.0022134  0.00220229 0.002193\n",
      " 0.00219796 0.002193   0.002193   0.002193   0.00221453 0.00220846\n",
      " 0.002193   0.002193   0.00220349 0.00219853 0.00222518 0.00219755\n",
      " 0.0022033  0.002193   0.002193   0.002193   0.00220315 0.002193\n",
      " 0.0022077  0.002193   0.00219839 0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00220327 0.002193   0.00220336 0.002193\n",
      " 0.00220348 0.0022262  0.00220755 0.002193   0.00219839 0.002193\n",
      " 0.00220879 0.002193   0.002193   0.002193   0.002193   0.00221243\n",
      " 0.002193   0.002193   0.00220412 0.0022295  0.002193   0.00220953\n",
      " 0.00220287 0.00222031 0.0022077  0.002193   0.002193   0.00221849\n",
      " 0.00220308 0.00219755 0.002193   0.002193   0.00221929 0.00219839\n",
      " 0.002193   0.00219808 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00220846 0.002193   0.00220283 0.00220229\n",
      " 0.002193   0.002193   0.00220328 0.002193   0.00220348 0.002193\n",
      " 0.002193   0.002193   0.0022088  0.00219755 0.002193   0.002193\n",
      " 0.002193   0.00220421 0.002193   0.00219755 0.002193   0.00219796\n",
      " 0.002193   0.002193   0.00222095 0.002193   0.00222512 0.002193\n",
      " 0.002193   0.002193   0.002193   0.0022037  0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00220336 0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00219755 0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.00220358 0.002193\n",
      " 0.00221931 0.00219915 0.002193   0.002193   0.002193   0.0021979\n",
      " 0.002193   0.00220328 0.002193   0.0022126  0.002193   0.00219839\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219853\n",
      " 0.002193   0.002193   0.00220914 0.0022075  0.002193   0.00221859\n",
      " 0.00222678 0.00220271 0.002193   0.002193   0.00219755 0.00220739\n",
      " 0.00219915 0.00222502 0.002193   0.00223094 0.00219755 0.002193\n",
      " 0.002193   0.002193   0.00221264 0.00219755 0.002193   0.00220896\n",
      " 0.002193   0.00219755 0.00220421 0.002193   0.00220846 0.00220314\n",
      " 0.002193   0.00219755 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219867\n",
      " 0.00219853 0.002193   0.00220342 0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219839 0.002193   0.002193   0.00219853 0.0021979\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00222878 0.00220807 0.00219796\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00221981\n",
      " 0.002193   0.002193   0.00219839 0.002193   0.002193  ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  67 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 1149/2000 [02:26<01:48,  7.86it/s]\n",
      "[2023-12-17T22:24:55.901284+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:24:55.903029+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:24:55.907058+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:24:55.910717+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:24:55.915667+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:24:55.918883+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:24:55.920324+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_11__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 11 accuracy:  0.9340659340659341\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220305 0.00219262 0.0021978  0.0022079  0.00219262 0.00219828\n",
      " 0.00219262 0.00219736 0.00219262 0.00219262 0.00219262 0.00221963\n",
      " 0.00221899 0.00219262 0.00223081 0.00219262 0.00219842 0.00219262\n",
      " 0.00221963 0.00219752 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219828 0.00219262 0.00219262 0.00220934\n",
      " 0.00219262 0.00221425 0.00219262 0.00219262 0.00219262 0.00219752\n",
      " 0.00219262 0.00219262 0.00221512 0.00220813 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219757 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00221851 0.00219262 0.00220736 0.00222466 0.002198\n",
      " 0.00219262 0.00219262 0.00219262 0.00220303 0.00219262 0.00220271\n",
      " 0.00219757 0.00219262 0.00224155 0.00219262 0.00221988 0.00219262\n",
      " 0.00219262 0.0022145  0.00221315 0.00219716 0.00219757 0.00219814\n",
      " 0.00220767 0.00219262 0.00219769 0.00219262 0.00220311 0.00219262\n",
      " 0.00219716 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00220396 0.00219716 0.00219262 0.00219262 0.00220865\n",
      " 0.00219842 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00220803 0.00221204 0.00219262 0.00223629 0.00219262 0.00219262\n",
      " 0.00219262 0.00219757 0.00219262 0.00219262 0.00219262 0.00219716\n",
      " 0.00220191 0.00219262 0.00219262 0.00219262 0.00219752 0.00219262\n",
      " 0.00219262 0.00219262 0.00221426 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219736 0.00221403 0.00219757 0.00219876 0.00219262\n",
      " 0.00219262 0.00220776 0.00219262 0.00222457 0.00221716 0.00219757\n",
      " 0.00219757 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219769 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00220877 0.00219262 0.00220445 0.00220354 0.00219262\n",
      " 0.00219262 0.00219828 0.00219262 0.00220191 0.00219262 0.00220191\n",
      " 0.00219262 0.00219262 0.0022145  0.00220416 0.00219262 0.0022473\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00220275 0.00219262 0.00219752 0.00219262 0.00219262 0.00219262\n",
      " 0.00220396 0.00219262 0.00219262 0.00219769 0.00219736 0.00219262\n",
      " 0.00221373 0.00219262 0.00219262 0.00219262 0.00219262 0.00220416\n",
      " 0.00219262 0.00220191 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219716\n",
      " 0.00225753 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.0021978\n",
      " 0.00219262 0.00219262 0.00219262 0.00221301 0.00220191 0.00219262\n",
      " 0.00219757 0.00219262 0.00219262 0.00219262 0.00221414 0.00220807\n",
      " 0.00219262 0.00219262 0.00220311 0.00220396 0.00222479 0.00219716\n",
      " 0.00220291 0.00219842 0.00219262 0.00219262 0.00220276 0.00219262\n",
      " 0.00221316 0.00219262 0.002198   0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00220288 0.00219262 0.00220297 0.00219262\n",
      " 0.00220309 0.00222581 0.00220716 0.00219262 0.002198   0.00219262\n",
      " 0.0022084  0.00219262 0.00219262 0.00219262 0.00219262 0.00221204\n",
      " 0.00219262 0.00219262 0.00220373 0.00223501 0.00219262 0.00220914\n",
      " 0.00220248 0.0022258  0.00220732 0.00219262 0.00219262 0.0022181\n",
      " 0.0022027  0.00219716 0.00219262 0.00219262 0.00222477 0.002198\n",
      " 0.00219262 0.00220351 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00220807 0.00219262 0.00220244 0.00220191\n",
      " 0.00219262 0.00219262 0.00220289 0.00219262 0.00220309 0.00219262\n",
      " 0.00219262 0.00219262 0.00220842 0.00219716 0.00219262 0.00219262\n",
      " 0.00219262 0.00220382 0.00219262 0.00219716 0.00219262 0.00219757\n",
      " 0.00219262 0.00219262 0.00222644 0.00219262 0.00222473 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00220331 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00220297 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219716 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.0022032  0.00219262\n",
      " 0.00221892 0.00220458 0.00219262 0.00219262 0.00219262 0.00219752\n",
      " 0.00219262 0.00220289 0.00219262 0.00221221 0.00219262 0.002198\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219814\n",
      " 0.00219262 0.00219262 0.00220875 0.00220711 0.00219262 0.0022182\n",
      " 0.00223228 0.00220232 0.00219262 0.00219262 0.00219716 0.002207\n",
      " 0.00219876 0.00222463 0.00219262 0.00223055 0.00219716 0.00219262\n",
      " 0.00219262 0.00219262 0.00221225 0.00219716 0.00219262 0.00221442\n",
      " 0.00219262 0.00219716 0.00220966 0.00219262 0.00220807 0.00220275\n",
      " 0.00219262 0.00219716 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219828\n",
      " 0.00219814 0.00219262 0.00220303 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.002198   0.00219262 0.00219262 0.00219814 0.00219752\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00223429 0.00220768 0.00219757\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00221942\n",
      " 0.00219262 0.00219262 0.002198   0.00219262 0.00219262]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002643533066495037\n",
      "Boosting iter: 13 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 33/20\n",
      "random state: 32\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220305 0.00219262 0.0021978  0.0022079  0.00219262 0.00219828\n",
      " 0.00219262 0.00219736 0.00219262 0.00219262 0.00219262 0.00221963\n",
      " 0.00221899 0.00219262 0.00223081 0.00219262 0.00219842 0.00219262\n",
      " 0.00221963 0.00219752 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219828 0.00219262 0.00219262 0.00220934\n",
      " 0.00219262 0.00221425 0.00219262 0.00219262 0.00219262 0.00219752\n",
      " 0.00219262 0.00219262 0.00221512 0.00220813 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219757 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00221851 0.00219262 0.00220736 0.00222466 0.002198\n",
      " 0.00219262 0.00219262 0.00219262 0.00220303 0.00219262 0.00220271\n",
      " 0.00219757 0.00219262 0.00224155 0.00219262 0.00221988 0.00219262\n",
      " 0.00219262 0.0022145  0.00221315 0.00219716 0.00219757 0.00219814\n",
      " 0.00220767 0.00219262 0.00219769 0.00219262 0.00220311 0.00219262\n",
      " 0.00219716 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00220396 0.00219716 0.00219262 0.00219262 0.00220865\n",
      " 0.00219842 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00220803 0.00221204 0.00219262 0.00223629 0.00219262 0.00219262\n",
      " 0.00219262 0.00219757 0.00219262 0.00219262 0.00219262 0.00219716\n",
      " 0.00220191 0.00219262 0.00219262 0.00219262 0.00219752 0.00219262\n",
      " 0.00219262 0.00219262 0.00221426 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219736 0.00221403 0.00219757 0.00219876 0.00219262\n",
      " 0.00219262 0.00220776 0.00219262 0.00222457 0.00221716 0.00219757\n",
      " 0.00219757 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219769 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00220877 0.00219262 0.00220445 0.00220354 0.00219262\n",
      " 0.00219262 0.00219828 0.00219262 0.00220191 0.00219262 0.00220191\n",
      " 0.00219262 0.00219262 0.0022145  0.00220416 0.00219262 0.0022473\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00220275 0.00219262 0.00219752 0.00219262 0.00219262 0.00219262\n",
      " 0.00220396 0.00219262 0.00219262 0.00219769 0.00219736 0.00219262\n",
      " 0.00221373 0.00219262 0.00219262 0.00219262 0.00219262 0.00220416\n",
      " 0.00219262 0.00220191 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219716\n",
      " 0.00225753 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.0021978\n",
      " 0.00219262 0.00219262 0.00219262 0.00221301 0.00220191 0.00219262\n",
      " 0.00219757 0.00219262 0.00219262 0.00219262 0.00221414 0.00220807\n",
      " 0.00219262 0.00219262 0.00220311 0.00220396 0.00222479 0.00219716\n",
      " 0.00220291 0.00219842 0.00219262 0.00219262 0.00220276 0.00219262\n",
      " 0.00221316 0.00219262 0.002198   0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00220288 0.00219262 0.00220297 0.00219262\n",
      " 0.00220309 0.00222581 0.00220716 0.00219262 0.002198   0.00219262\n",
      " 0.0022084  0.00219262 0.00219262 0.00219262 0.00219262 0.00221204\n",
      " 0.00219262 0.00219262 0.00220373 0.00223501 0.00219262 0.00220914\n",
      " 0.00220248 0.0022258  0.00220732 0.00219262 0.00219262 0.0022181\n",
      " 0.0022027  0.00219716 0.00219262 0.00219262 0.00222477 0.002198\n",
      " 0.00219262 0.00220351 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00220807 0.00219262 0.00220244 0.00220191\n",
      " 0.00219262 0.00219262 0.00220289 0.00219262 0.00220309 0.00219262\n",
      " 0.00219262 0.00219262 0.00220842 0.00219716 0.00219262 0.00219262\n",
      " 0.00219262 0.00220382 0.00219262 0.00219716 0.00219262 0.00219757\n",
      " 0.00219262 0.00219262 0.00222644 0.00219262 0.00222473 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00220331 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00220297 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219716 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.0022032  0.00219262\n",
      " 0.00221892 0.00220458 0.00219262 0.00219262 0.00219262 0.00219752\n",
      " 0.00219262 0.00220289 0.00219262 0.00221221 0.00219262 0.002198\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219814\n",
      " 0.00219262 0.00219262 0.00220875 0.00220711 0.00219262 0.0022182\n",
      " 0.00223228 0.00220232 0.00219262 0.00219262 0.00219716 0.002207\n",
      " 0.00219876 0.00222463 0.00219262 0.00223055 0.00219716 0.00219262\n",
      " 0.00219262 0.00219262 0.00221225 0.00219716 0.00219262 0.00221442\n",
      " 0.00219262 0.00219716 0.00220966 0.00219262 0.00220807 0.00220275\n",
      " 0.00219262 0.00219716 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219828\n",
      " 0.00219814 0.00219262 0.00220303 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.002198   0.00219262 0.00219262 0.00219814 0.00219752\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00223429 0.00220768 0.00219757\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00221942\n",
      " 0.00219262 0.00219262 0.002198   0.00219262 0.00219262]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        184, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  67 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 309 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([212, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████████████████████████████████▏                                                                                                  | 749/2000 [01:39<02:45,  7.56it/s]\n",
      "[2023-12-17T22:26:40.953020+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:26:40.955148+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:26:40.956935+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:26:40.959068+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:26:40.962848+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:26:40.964638+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:26:40.966386+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_12__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 12 accuracy:  0.9098901098901099\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220259 0.00219216 0.00219734 0.00220744 0.00219216 0.00219782\n",
      " 0.00219216 0.00219689 0.00219216 0.00219216 0.00219216 0.00222428\n",
      " 0.00221852 0.00219216 0.00223035 0.00219216 0.00219796 0.00219216\n",
      " 0.00222428 0.00219706 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219782 0.00219216 0.00219216 0.00220888\n",
      " 0.00219216 0.00221378 0.00219216 0.00219216 0.00219216 0.00219706\n",
      " 0.00219216 0.00219216 0.00221466 0.00220767 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219711 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00221804 0.00219216 0.0022069  0.00222933 0.00219754\n",
      " 0.00219216 0.00219216 0.00219216 0.00220257 0.00219216 0.00220225\n",
      " 0.00219711 0.00219216 0.00224625 0.00219216 0.00221941 0.00219216\n",
      " 0.00219216 0.00221404 0.00221269 0.0021967  0.00219711 0.00219768\n",
      " 0.00220721 0.00219216 0.00219723 0.00219216 0.00220265 0.00219216\n",
      " 0.0021967  0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.0022035  0.0021967  0.00219216 0.00219216 0.00220819\n",
      " 0.00219796 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00221266 0.00221668 0.00219216 0.00224098 0.00219216 0.00219216\n",
      " 0.00219216 0.00219711 0.00219216 0.00219216 0.00219216 0.0021967\n",
      " 0.00220145 0.00219216 0.00219216 0.00219216 0.00219706 0.00219216\n",
      " 0.00219216 0.00219216 0.0022189  0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219689 0.00221357 0.00219711 0.00220337 0.00219216\n",
      " 0.00219216 0.00221239 0.00219216 0.00222923 0.00221669 0.00219711\n",
      " 0.00219711 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219723 0.00219722 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00220831 0.00219216 0.00220907 0.00220308 0.00219216\n",
      " 0.00219216 0.00219782 0.00219216 0.00220145 0.00219216 0.00220652\n",
      " 0.00219216 0.00219216 0.00221915 0.0022037  0.00219216 0.00225201\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00220229 0.00219216 0.00219706 0.00219216 0.00219216 0.00219216\n",
      " 0.0022035  0.00219216 0.00219216 0.00219723 0.00219689 0.00219216\n",
      " 0.00221838 0.00219216 0.00219216 0.00219216 0.00219216 0.0022037\n",
      " 0.00219216 0.00220652 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.0021967\n",
      " 0.00226226 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219734\n",
      " 0.00219216 0.00219216 0.00219216 0.00221765 0.00220145 0.00219216\n",
      " 0.00219711 0.00219216 0.00219216 0.00219216 0.00221368 0.00220761\n",
      " 0.00219216 0.00219216 0.00220773 0.0022035  0.00222433 0.0021967\n",
      " 0.00220245 0.00219796 0.00219216 0.00219216 0.00220738 0.00219216\n",
      " 0.00221269 0.00219216 0.00219754 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00220242 0.00219216 0.00220251 0.00219216\n",
      " 0.00220263 0.00223048 0.0022067  0.00219216 0.00219754 0.00219216\n",
      " 0.00220794 0.00219216 0.00219216 0.00219216 0.00219216 0.00221158\n",
      " 0.00219216 0.00219216 0.00220327 0.00223454 0.00219216 0.00220868\n",
      " 0.00220202 0.00223047 0.00220685 0.00219216 0.00219216 0.00221763\n",
      " 0.00220224 0.0021967  0.00219216 0.00219216 0.00222431 0.00219754\n",
      " 0.00219216 0.00220305 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00220761 0.00219216 0.00220198 0.00220145\n",
      " 0.00219216 0.00219216 0.00220243 0.00219216 0.00220263 0.00219216\n",
      " 0.00219216 0.00219216 0.00220795 0.0021967  0.00219216 0.00219216\n",
      " 0.00219216 0.00220844 0.00219216 0.0021967  0.00219216 0.00219711\n",
      " 0.00219216 0.00219216 0.00223111 0.00219216 0.00222939 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00220285 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00220251 0.00219722 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.0021967  0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00220782 0.00219216\n",
      " 0.00222358 0.00220412 0.00219216 0.00219216 0.00219216 0.00219706\n",
      " 0.00219216 0.00220751 0.00219216 0.00221685 0.00219216 0.00220261\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219768\n",
      " 0.00219216 0.00219216 0.00220828 0.00221174 0.00219216 0.00222285\n",
      " 0.00223181 0.00220694 0.00219216 0.00219216 0.0021967  0.00221163\n",
      " 0.0021983  0.00222416 0.00219216 0.00223523 0.0021967  0.00219216\n",
      " 0.00219216 0.00219216 0.00221689 0.0021967  0.00219216 0.00221396\n",
      " 0.00219216 0.00220177 0.00220919 0.00219216 0.00220761 0.00220229\n",
      " 0.00219216 0.0021967  0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219782\n",
      " 0.00219768 0.00219216 0.00220765 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219754 0.00219216 0.00219216 0.00219768 0.00219706\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00223382 0.00220722 0.00219711\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00221896\n",
      " 0.00219216 0.00219216 0.00219754 0.00219216 0.00219216]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002304244228185672\n",
      "Boosting iter: 14 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 34/20\n",
      "random state: 33\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220259 0.00219216 0.00219734 0.00220744 0.00219216 0.00219782\n",
      " 0.00219216 0.00219689 0.00219216 0.00219216 0.00219216 0.00222428\n",
      " 0.00221852 0.00219216 0.00223035 0.00219216 0.00219796 0.00219216\n",
      " 0.00222428 0.00219706 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219782 0.00219216 0.00219216 0.00220888\n",
      " 0.00219216 0.00221378 0.00219216 0.00219216 0.00219216 0.00219706\n",
      " 0.00219216 0.00219216 0.00221466 0.00220767 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219711 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00221804 0.00219216 0.0022069  0.00222933 0.00219754\n",
      " 0.00219216 0.00219216 0.00219216 0.00220257 0.00219216 0.00220225\n",
      " 0.00219711 0.00219216 0.00224625 0.00219216 0.00221941 0.00219216\n",
      " 0.00219216 0.00221404 0.00221269 0.0021967  0.00219711 0.00219768\n",
      " 0.00220721 0.00219216 0.00219723 0.00219216 0.00220265 0.00219216\n",
      " 0.0021967  0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.0022035  0.0021967  0.00219216 0.00219216 0.00220819\n",
      " 0.00219796 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00221266 0.00221668 0.00219216 0.00224098 0.00219216 0.00219216\n",
      " 0.00219216 0.00219711 0.00219216 0.00219216 0.00219216 0.0021967\n",
      " 0.00220145 0.00219216 0.00219216 0.00219216 0.00219706 0.00219216\n",
      " 0.00219216 0.00219216 0.0022189  0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219689 0.00221357 0.00219711 0.00220337 0.00219216\n",
      " 0.00219216 0.00221239 0.00219216 0.00222923 0.00221669 0.00219711\n",
      " 0.00219711 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219723 0.00219722 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00220831 0.00219216 0.00220907 0.00220308 0.00219216\n",
      " 0.00219216 0.00219782 0.00219216 0.00220145 0.00219216 0.00220652\n",
      " 0.00219216 0.00219216 0.00221915 0.0022037  0.00219216 0.00225201\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00220229 0.00219216 0.00219706 0.00219216 0.00219216 0.00219216\n",
      " 0.0022035  0.00219216 0.00219216 0.00219723 0.00219689 0.00219216\n",
      " 0.00221838 0.00219216 0.00219216 0.00219216 0.00219216 0.0022037\n",
      " 0.00219216 0.00220652 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.0021967\n",
      " 0.00226226 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219734\n",
      " 0.00219216 0.00219216 0.00219216 0.00221765 0.00220145 0.00219216\n",
      " 0.00219711 0.00219216 0.00219216 0.00219216 0.00221368 0.00220761\n",
      " 0.00219216 0.00219216 0.00220773 0.0022035  0.00222433 0.0021967\n",
      " 0.00220245 0.00219796 0.00219216 0.00219216 0.00220738 0.00219216\n",
      " 0.00221269 0.00219216 0.00219754 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00220242 0.00219216 0.00220251 0.00219216\n",
      " 0.00220263 0.00223048 0.0022067  0.00219216 0.00219754 0.00219216\n",
      " 0.00220794 0.00219216 0.00219216 0.00219216 0.00219216 0.00221158\n",
      " 0.00219216 0.00219216 0.00220327 0.00223454 0.00219216 0.00220868\n",
      " 0.00220202 0.00223047 0.00220685 0.00219216 0.00219216 0.00221763\n",
      " 0.00220224 0.0021967  0.00219216 0.00219216 0.00222431 0.00219754\n",
      " 0.00219216 0.00220305 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00220761 0.00219216 0.00220198 0.00220145\n",
      " 0.00219216 0.00219216 0.00220243 0.00219216 0.00220263 0.00219216\n",
      " 0.00219216 0.00219216 0.00220795 0.0021967  0.00219216 0.00219216\n",
      " 0.00219216 0.00220844 0.00219216 0.0021967  0.00219216 0.00219711\n",
      " 0.00219216 0.00219216 0.00223111 0.00219216 0.00222939 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00220285 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00220251 0.00219722 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.0021967  0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00220782 0.00219216\n",
      " 0.00222358 0.00220412 0.00219216 0.00219216 0.00219216 0.00219706\n",
      " 0.00219216 0.00220751 0.00219216 0.00221685 0.00219216 0.00220261\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219768\n",
      " 0.00219216 0.00219216 0.00220828 0.00221174 0.00219216 0.00222285\n",
      " 0.00223181 0.00220694 0.00219216 0.00219216 0.0021967  0.00221163\n",
      " 0.0021983  0.00222416 0.00219216 0.00223523 0.0021967  0.00219216\n",
      " 0.00219216 0.00219216 0.00221689 0.0021967  0.00219216 0.00221396\n",
      " 0.00219216 0.00220177 0.00220919 0.00219216 0.00220761 0.00220229\n",
      " 0.00219216 0.0021967  0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219782\n",
      " 0.00219768 0.00219216 0.00220765 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219754 0.00219216 0.00219216 0.00219768 0.00219706\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00223382 0.00220722 0.00219711\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00221896\n",
      " 0.00219216 0.00219216 0.00219754 0.00219216 0.00219216]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        184, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([212, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████████████████████████████████████████████████                                                               | 1199/2000 [02:40<01:47,  7.47it/s]\n",
      "[2023-12-17T22:29:27.581042+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:29:27.583180+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:29:27.584898+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:29:27.586974+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:29:27.590653+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:29:27.592373+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:29:27.594042+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_13__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 13 accuracy:  0.9098901098901099\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220213 0.0021917  0.00219688 0.00220698 0.0021917  0.00219736\n",
      " 0.0021917  0.00219644 0.0021917  0.0021917  0.0021917  0.00222895\n",
      " 0.00222317 0.0021917  0.00223502 0.0021917  0.0021975  0.0021917\n",
      " 0.00222382 0.0021966  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219736 0.0021917  0.0021917  0.00220842\n",
      " 0.0021917  0.00221843 0.0021917  0.0021917  0.0021917  0.0021966\n",
      " 0.0021917  0.0021917  0.0022142  0.0022123  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219665 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0022227  0.0021917  0.00221153 0.002234   0.00219708\n",
      " 0.0021917  0.0021917  0.0021917  0.00220211 0.0021917  0.00220179\n",
      " 0.00219665 0.0021917  0.00225096 0.0021917  0.00221895 0.0021917\n",
      " 0.0021917  0.00221357 0.00221733 0.00219624 0.00219665 0.00219722\n",
      " 0.00220675 0.0021917  0.00219677 0.0021917  0.00220218 0.0021917\n",
      " 0.00219624 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00220304 0.00219624 0.0021917  0.0021917  0.00220772\n",
      " 0.0021975  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0022122  0.00221622 0.0021917  0.00224568 0.0021917  0.0021917\n",
      " 0.0021917  0.00219665 0.0021917  0.0021917  0.0021917  0.00219624\n",
      " 0.00220099 0.0021917  0.0021917  0.0021917  0.0021966  0.0021917\n",
      " 0.0021917  0.0021917  0.00222356 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00219644 0.0022131  0.00219665 0.00220291 0.0021917\n",
      " 0.0021917  0.00221703 0.0021917  0.00222876 0.00221623 0.00219665\n",
      " 0.00219665 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.00220184 0.00219676 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00220784 0.0021917  0.0022137  0.00220262 0.0021917\n",
      " 0.0021917  0.00219736 0.0021917  0.00220099 0.0021917  0.00220606\n",
      " 0.0021917  0.0021917  0.00221868 0.00220324 0.0021917  0.00225673\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.00220183 0.0021917  0.0021966  0.0021917  0.0021917  0.0021917\n",
      " 0.00220304 0.0021917  0.0021917  0.00219677 0.00219644 0.0021917\n",
      " 0.00222303 0.0021917  0.0021917  0.0021917  0.0021917  0.00220832\n",
      " 0.0021917  0.00220606 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00219676 0.0021917  0.00219624\n",
      " 0.00226179 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219688\n",
      " 0.0021917  0.0021917  0.0021917  0.0022223  0.00220099 0.0021917\n",
      " 0.00219665 0.0021917  0.0021917  0.0021917  0.00221321 0.00220715\n",
      " 0.0021917  0.0021917  0.00220727 0.00220304 0.00222386 0.00219624\n",
      " 0.00220199 0.0021975  0.0021917  0.0021917  0.00220692 0.0021917\n",
      " 0.00221223 0.0021917  0.00219708 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00220196 0.0021917  0.00220205 0.0021917\n",
      " 0.00220217 0.00223001 0.00220624 0.0021917  0.00219708 0.0021917\n",
      " 0.00220748 0.0021917  0.0021917  0.0021917  0.0021917  0.00221111\n",
      " 0.0021917  0.0021917  0.00220789 0.00223408 0.0021917  0.00220822\n",
      " 0.00220156 0.00223    0.00221148 0.0021917  0.0021917  0.00221717\n",
      " 0.00220177 0.00219624 0.0021917  0.0021917  0.00222897 0.00219708\n",
      " 0.0021917  0.00220259 0.0021917  0.0021917  0.0021917  0.00219676\n",
      " 0.0021917  0.0021917  0.00221224 0.0021917  0.00220152 0.00220099\n",
      " 0.0021917  0.0021917  0.00220197 0.0021917  0.00220217 0.0021917\n",
      " 0.0021917  0.0021917  0.00221258 0.00219624 0.0021917  0.0021917\n",
      " 0.0021917  0.00220798 0.0021917  0.00219624 0.0021917  0.00219665\n",
      " 0.0021917  0.0021917  0.00223579 0.0021917  0.00223407 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00220239 0.00219676 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00220205 0.00220182 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00219624 0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219676 0.0021917  0.00221245 0.0021917\n",
      " 0.00222311 0.00220366 0.0021917  0.0021917  0.0021917  0.0021966\n",
      " 0.0021917  0.00221214 0.0021917  0.0022215  0.0021917  0.00220215\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219722\n",
      " 0.0021917  0.0021917  0.00220782 0.00221638 0.0021917  0.00222239\n",
      " 0.00223135 0.00220647 0.0021917  0.0021917  0.00219624 0.00221117\n",
      " 0.00219784 0.00222883 0.0021917  0.00223476 0.00219624 0.0021917\n",
      " 0.0021917  0.0021917  0.00222154 0.00219624 0.0021917  0.00221349\n",
      " 0.0021917  0.00220131 0.00220873 0.0021917  0.00220715 0.00220691\n",
      " 0.0021917  0.00219624 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219736\n",
      " 0.00219722 0.0021917  0.00221228 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00219708 0.0021917  0.0021917  0.00219722 0.0021966\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0022385  0.00220676 0.00219665\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00221849\n",
      " 0.0021917  0.0021917  0.00219708 0.0021917  0.00219676]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002304204351201144\n",
      "Boosting iter: 15 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 35/20\n",
      "random state: 34\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220213 0.0021917  0.00219688 0.00220698 0.0021917  0.00219736\n",
      " 0.0021917  0.00219644 0.0021917  0.0021917  0.0021917  0.00222895\n",
      " 0.00222317 0.0021917  0.00223502 0.0021917  0.0021975  0.0021917\n",
      " 0.00222382 0.0021966  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219736 0.0021917  0.0021917  0.00220842\n",
      " 0.0021917  0.00221843 0.0021917  0.0021917  0.0021917  0.0021966\n",
      " 0.0021917  0.0021917  0.0022142  0.0022123  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219665 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0022227  0.0021917  0.00221153 0.002234   0.00219708\n",
      " 0.0021917  0.0021917  0.0021917  0.00220211 0.0021917  0.00220179\n",
      " 0.00219665 0.0021917  0.00225096 0.0021917  0.00221895 0.0021917\n",
      " 0.0021917  0.00221357 0.00221733 0.00219624 0.00219665 0.00219722\n",
      " 0.00220675 0.0021917  0.00219677 0.0021917  0.00220218 0.0021917\n",
      " 0.00219624 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00220304 0.00219624 0.0021917  0.0021917  0.00220772\n",
      " 0.0021975  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0022122  0.00221622 0.0021917  0.00224568 0.0021917  0.0021917\n",
      " 0.0021917  0.00219665 0.0021917  0.0021917  0.0021917  0.00219624\n",
      " 0.00220099 0.0021917  0.0021917  0.0021917  0.0021966  0.0021917\n",
      " 0.0021917  0.0021917  0.00222356 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00219644 0.0022131  0.00219665 0.00220291 0.0021917\n",
      " 0.0021917  0.00221703 0.0021917  0.00222876 0.00221623 0.00219665\n",
      " 0.00219665 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.00220184 0.00219676 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00220784 0.0021917  0.0022137  0.00220262 0.0021917\n",
      " 0.0021917  0.00219736 0.0021917  0.00220099 0.0021917  0.00220606\n",
      " 0.0021917  0.0021917  0.00221868 0.00220324 0.0021917  0.00225673\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.00220183 0.0021917  0.0021966  0.0021917  0.0021917  0.0021917\n",
      " 0.00220304 0.0021917  0.0021917  0.00219677 0.00219644 0.0021917\n",
      " 0.00222303 0.0021917  0.0021917  0.0021917  0.0021917  0.00220832\n",
      " 0.0021917  0.00220606 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00219676 0.0021917  0.00219624\n",
      " 0.00226179 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219688\n",
      " 0.0021917  0.0021917  0.0021917  0.0022223  0.00220099 0.0021917\n",
      " 0.00219665 0.0021917  0.0021917  0.0021917  0.00221321 0.00220715\n",
      " 0.0021917  0.0021917  0.00220727 0.00220304 0.00222386 0.00219624\n",
      " 0.00220199 0.0021975  0.0021917  0.0021917  0.00220692 0.0021917\n",
      " 0.00221223 0.0021917  0.00219708 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00220196 0.0021917  0.00220205 0.0021917\n",
      " 0.00220217 0.00223001 0.00220624 0.0021917  0.00219708 0.0021917\n",
      " 0.00220748 0.0021917  0.0021917  0.0021917  0.0021917  0.00221111\n",
      " 0.0021917  0.0021917  0.00220789 0.00223408 0.0021917  0.00220822\n",
      " 0.00220156 0.00223    0.00221148 0.0021917  0.0021917  0.00221717\n",
      " 0.00220177 0.00219624 0.0021917  0.0021917  0.00222897 0.00219708\n",
      " 0.0021917  0.00220259 0.0021917  0.0021917  0.0021917  0.00219676\n",
      " 0.0021917  0.0021917  0.00221224 0.0021917  0.00220152 0.00220099\n",
      " 0.0021917  0.0021917  0.00220197 0.0021917  0.00220217 0.0021917\n",
      " 0.0021917  0.0021917  0.00221258 0.00219624 0.0021917  0.0021917\n",
      " 0.0021917  0.00220798 0.0021917  0.00219624 0.0021917  0.00219665\n",
      " 0.0021917  0.0021917  0.00223579 0.0021917  0.00223407 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00220239 0.00219676 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00220205 0.00220182 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00219624 0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219676 0.0021917  0.00221245 0.0021917\n",
      " 0.00222311 0.00220366 0.0021917  0.0021917  0.0021917  0.0021966\n",
      " 0.0021917  0.00221214 0.0021917  0.0022215  0.0021917  0.00220215\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219722\n",
      " 0.0021917  0.0021917  0.00220782 0.00221638 0.0021917  0.00222239\n",
      " 0.00223135 0.00220647 0.0021917  0.0021917  0.00219624 0.00221117\n",
      " 0.00219784 0.00222883 0.0021917  0.00223476 0.00219624 0.0021917\n",
      " 0.0021917  0.0021917  0.00222154 0.00219624 0.0021917  0.00221349\n",
      " 0.0021917  0.00220131 0.00220873 0.0021917  0.00220715 0.00220691\n",
      " 0.0021917  0.00219624 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219736\n",
      " 0.00219722 0.0021917  0.00221228 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00219708 0.0021917  0.0021917  0.00219722 0.0021966\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0022385  0.00220676 0.00219665\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00221849\n",
      " 0.0021917  0.0021917  0.00219708 0.0021917  0.00219676]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  67 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([212, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████████████████████▍                                                                                                                          | 449/2000 [00:57<03:20,  7.75it/s]\n",
      "[2023-12-17T22:30:31.585357+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:30:31.587474+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:30:31.589165+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:30:31.591239+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:30:31.594930+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:30:31.596637+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:30:31.598381+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_14__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 14 accuracy:  0.9230769230769231\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220171 0.00219128 0.00219646 0.00220655 0.00219128 0.00219694\n",
      " 0.00219128 0.00219601 0.00219128 0.00219128 0.00219128 0.00222852\n",
      " 0.00222825 0.00219128 0.00224013 0.00219128 0.00219708 0.00219128\n",
      " 0.00222339 0.00219617 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219694 0.00219128 0.00219128 0.00220799\n",
      " 0.00219128 0.002218   0.00219128 0.00219128 0.00219128 0.00219617\n",
      " 0.00219128 0.00219128 0.00221377 0.00221187 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219623 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00222227 0.00219128 0.0022111  0.00223357 0.00219666\n",
      " 0.00219128 0.00219128 0.00219128 0.00220169 0.00219128 0.00220136\n",
      " 0.00219623 0.00219128 0.0022561  0.00219128 0.00222402 0.00219128\n",
      " 0.00219128 0.00221315 0.00222239 0.00219582 0.00219623 0.0021968\n",
      " 0.00220632 0.00219128 0.00219635 0.00219128 0.00220722 0.00219128\n",
      " 0.00219582 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00220261 0.00219582 0.00219128 0.00219128 0.0022073\n",
      " 0.00219708 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00221725 0.00221579 0.00219128 0.00225081 0.00219128 0.00219128\n",
      " 0.00219128 0.00219623 0.00219128 0.00219128 0.00219128 0.00219582\n",
      " 0.00220056 0.00219128 0.00219128 0.00219128 0.00219617 0.00219128\n",
      " 0.00219128 0.00219128 0.00222864 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219601 0.00221268 0.00219623 0.00220249 0.00219128\n",
      " 0.00219128 0.0022166  0.00219128 0.00222834 0.00222129 0.00219623\n",
      " 0.00219623 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00220141 0.00219633 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00220742 0.00219128 0.00221328 0.00220765 0.00219128\n",
      " 0.00219128 0.00219694 0.00219128 0.00220056 0.00219128 0.00220564\n",
      " 0.00219128 0.00219128 0.00221825 0.00220282 0.00219128 0.00226189\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00220141 0.00219128 0.00219617 0.00219128 0.00219128 0.00219128\n",
      " 0.00220261 0.00219128 0.00219128 0.00219635 0.00219601 0.00219128\n",
      " 0.0022226  0.00219128 0.00219128 0.00219128 0.00219128 0.0022079\n",
      " 0.00219128 0.00220564 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219633 0.00219128 0.00219582\n",
      " 0.00226696 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219646\n",
      " 0.00219128 0.00219128 0.00219128 0.00222737 0.00220056 0.00219128\n",
      " 0.00220167 0.00219128 0.00219128 0.00219128 0.00221827 0.00220672\n",
      " 0.00219128 0.00219128 0.00221231 0.00220261 0.00222343 0.00219582\n",
      " 0.00220157 0.00220252 0.00219128 0.00219128 0.00220649 0.00219128\n",
      " 0.00221181 0.00219128 0.00219666 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00220154 0.00219128 0.00220708 0.00219128\n",
      " 0.00220174 0.00222958 0.00221128 0.00219128 0.00219666 0.00219128\n",
      " 0.00220705 0.00219128 0.00219128 0.00219128 0.00219128 0.00221069\n",
      " 0.00219128 0.00219128 0.00221293 0.00223918 0.00219128 0.00220779\n",
      " 0.00220114 0.00222957 0.00221106 0.00219128 0.00219128 0.00222223\n",
      " 0.00220135 0.00219582 0.00219128 0.00219128 0.00223406 0.00219666\n",
      " 0.00219128 0.00220216 0.00219128 0.00219128 0.00219128 0.00219633\n",
      " 0.00219128 0.00219128 0.00221181 0.00219128 0.00220109 0.00220056\n",
      " 0.00219128 0.00219128 0.00220155 0.00219128 0.00220174 0.00219128\n",
      " 0.00219128 0.00219128 0.00221216 0.00219582 0.00219128 0.00219128\n",
      " 0.00219128 0.00220756 0.00219128 0.00219582 0.00219128 0.00219623\n",
      " 0.00219128 0.00219128 0.00223536 0.00219128 0.00223917 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00220197 0.00219633 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00220708 0.0022014  0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219582 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219633 0.00219128 0.00221202 0.00219128\n",
      " 0.00222268 0.00220324 0.00219128 0.00219128 0.00219128 0.00219617\n",
      " 0.00219128 0.00221171 0.00219128 0.00222658 0.00219671 0.00220173\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.0021968\n",
      " 0.00219128 0.00219128 0.0022074  0.00222144 0.00219128 0.00222196\n",
      " 0.00223644 0.00220605 0.00219128 0.00219128 0.00219582 0.00221074\n",
      " 0.00220286 0.00223392 0.00219128 0.00223986 0.00219582 0.00219128\n",
      " 0.00219128 0.00219128 0.00222111 0.00219582 0.00219128 0.00221307\n",
      " 0.00219128 0.00220088 0.00220831 0.00219128 0.00221219 0.00220648\n",
      " 0.00219128 0.00219582 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219694\n",
      " 0.0021968  0.00219128 0.00221186 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219666 0.00219128 0.00219128 0.0021968  0.00219617\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00223807 0.00220634 0.00219623\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00222356\n",
      " 0.00219128 0.00219128 0.00219666 0.00219128 0.00219633]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002474240651679884\n",
      "Boosting iter: 16 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 36/20\n",
      "random state: 35\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220171 0.00219128 0.00219646 0.00220655 0.00219128 0.00219694\n",
      " 0.00219128 0.00219601 0.00219128 0.00219128 0.00219128 0.00222852\n",
      " 0.00222825 0.00219128 0.00224013 0.00219128 0.00219708 0.00219128\n",
      " 0.00222339 0.00219617 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219694 0.00219128 0.00219128 0.00220799\n",
      " 0.00219128 0.002218   0.00219128 0.00219128 0.00219128 0.00219617\n",
      " 0.00219128 0.00219128 0.00221377 0.00221187 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219623 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00222227 0.00219128 0.0022111  0.00223357 0.00219666\n",
      " 0.00219128 0.00219128 0.00219128 0.00220169 0.00219128 0.00220136\n",
      " 0.00219623 0.00219128 0.0022561  0.00219128 0.00222402 0.00219128\n",
      " 0.00219128 0.00221315 0.00222239 0.00219582 0.00219623 0.0021968\n",
      " 0.00220632 0.00219128 0.00219635 0.00219128 0.00220722 0.00219128\n",
      " 0.00219582 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00220261 0.00219582 0.00219128 0.00219128 0.0022073\n",
      " 0.00219708 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00221725 0.00221579 0.00219128 0.00225081 0.00219128 0.00219128\n",
      " 0.00219128 0.00219623 0.00219128 0.00219128 0.00219128 0.00219582\n",
      " 0.00220056 0.00219128 0.00219128 0.00219128 0.00219617 0.00219128\n",
      " 0.00219128 0.00219128 0.00222864 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219601 0.00221268 0.00219623 0.00220249 0.00219128\n",
      " 0.00219128 0.0022166  0.00219128 0.00222834 0.00222129 0.00219623\n",
      " 0.00219623 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00220141 0.00219633 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00220742 0.00219128 0.00221328 0.00220765 0.00219128\n",
      " 0.00219128 0.00219694 0.00219128 0.00220056 0.00219128 0.00220564\n",
      " 0.00219128 0.00219128 0.00221825 0.00220282 0.00219128 0.00226189\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00220141 0.00219128 0.00219617 0.00219128 0.00219128 0.00219128\n",
      " 0.00220261 0.00219128 0.00219128 0.00219635 0.00219601 0.00219128\n",
      " 0.0022226  0.00219128 0.00219128 0.00219128 0.00219128 0.0022079\n",
      " 0.00219128 0.00220564 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219633 0.00219128 0.00219582\n",
      " 0.00226696 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219646\n",
      " 0.00219128 0.00219128 0.00219128 0.00222737 0.00220056 0.00219128\n",
      " 0.00220167 0.00219128 0.00219128 0.00219128 0.00221827 0.00220672\n",
      " 0.00219128 0.00219128 0.00221231 0.00220261 0.00222343 0.00219582\n",
      " 0.00220157 0.00220252 0.00219128 0.00219128 0.00220649 0.00219128\n",
      " 0.00221181 0.00219128 0.00219666 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00220154 0.00219128 0.00220708 0.00219128\n",
      " 0.00220174 0.00222958 0.00221128 0.00219128 0.00219666 0.00219128\n",
      " 0.00220705 0.00219128 0.00219128 0.00219128 0.00219128 0.00221069\n",
      " 0.00219128 0.00219128 0.00221293 0.00223918 0.00219128 0.00220779\n",
      " 0.00220114 0.00222957 0.00221106 0.00219128 0.00219128 0.00222223\n",
      " 0.00220135 0.00219582 0.00219128 0.00219128 0.00223406 0.00219666\n",
      " 0.00219128 0.00220216 0.00219128 0.00219128 0.00219128 0.00219633\n",
      " 0.00219128 0.00219128 0.00221181 0.00219128 0.00220109 0.00220056\n",
      " 0.00219128 0.00219128 0.00220155 0.00219128 0.00220174 0.00219128\n",
      " 0.00219128 0.00219128 0.00221216 0.00219582 0.00219128 0.00219128\n",
      " 0.00219128 0.00220756 0.00219128 0.00219582 0.00219128 0.00219623\n",
      " 0.00219128 0.00219128 0.00223536 0.00219128 0.00223917 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00220197 0.00219633 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00220708 0.0022014  0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219582 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219633 0.00219128 0.00221202 0.00219128\n",
      " 0.00222268 0.00220324 0.00219128 0.00219128 0.00219128 0.00219617\n",
      " 0.00219128 0.00221171 0.00219128 0.00222658 0.00219671 0.00220173\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.0021968\n",
      " 0.00219128 0.00219128 0.0022074  0.00222144 0.00219128 0.00222196\n",
      " 0.00223644 0.00220605 0.00219128 0.00219128 0.00219582 0.00221074\n",
      " 0.00220286 0.00223392 0.00219128 0.00223986 0.00219582 0.00219128\n",
      " 0.00219128 0.00219128 0.00222111 0.00219582 0.00219128 0.00221307\n",
      " 0.00219128 0.00220088 0.00220831 0.00219128 0.00221219 0.00220648\n",
      " 0.00219128 0.00219582 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219694\n",
      " 0.0021968  0.00219128 0.00221186 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219666 0.00219128 0.00219128 0.0021968  0.00219617\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00223807 0.00220634 0.00219623\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00222356\n",
      " 0.00219128 0.00219128 0.00219666 0.00219128 0.00219633]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 210 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████████████████████████████████████████████████████████████▉                                                                                   | 949/2000 [01:56<02:08,  8.17it/s]\n",
      "[2023-12-17T22:32:33.821479+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:32:33.823630+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:32:33.825288+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:32:33.827277+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:32:33.830885+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:32:33.832527+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:32:33.834156+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_15__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 15 accuracy:  0.9318681318681319\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220705 0.00219089 0.00219606 0.00220615 0.00219089 0.00219655\n",
      " 0.00219089 0.00219562 0.00219089 0.00219089 0.00219089 0.00223393\n",
      " 0.00222785 0.00219089 0.00224557 0.00219089 0.00219668 0.00219089\n",
      " 0.00222299 0.00219578 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219655 0.00219089 0.00219089 0.00220759\n",
      " 0.00219089 0.0022176  0.00219089 0.00219089 0.00219089 0.00219578\n",
      " 0.00219089 0.00219089 0.00221915 0.00221147 0.0021966  0.00219089\n",
      " 0.00219089 0.00219089 0.00219583 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00222187 0.00219089 0.00221647 0.00223317 0.00219627\n",
      " 0.00219089 0.00219089 0.00219089 0.00220129 0.00219089 0.00220097\n",
      " 0.00219583 0.00219089 0.00226158 0.00219089 0.00222362 0.00219089\n",
      " 0.00219089 0.00221852 0.00222199 0.00219542 0.00219583 0.0021964\n",
      " 0.00220593 0.00219089 0.00219595 0.00219089 0.00220682 0.00219089\n",
      " 0.00219542 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00220222 0.00219542 0.00219089 0.00219089 0.0022069\n",
      " 0.00219668 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00221685 0.00221539 0.00219089 0.00225628 0.00219089 0.00219089\n",
      " 0.00219089 0.00219583 0.00219089 0.00219089 0.00219089 0.00219542\n",
      " 0.00220017 0.00219089 0.00219089 0.00219089 0.00219578 0.00219089\n",
      " 0.00219089 0.00219089 0.00223405 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219562 0.00221228 0.00219583 0.00220784 0.00219089\n",
      " 0.00219089 0.00221621 0.00219089 0.00222794 0.00222089 0.00219583\n",
      " 0.00219583 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00220102 0.00219594 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00220702 0.00219089 0.00221288 0.00221301 0.00219089\n",
      " 0.00219089 0.00219655 0.00219089 0.00220017 0.00219089 0.00220524\n",
      " 0.00219089 0.00219089 0.00221786 0.00220242 0.00219089 0.00226738\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00220101 0.00219089 0.00219578 0.00219089 0.00219089 0.00219089\n",
      " 0.00220796 0.00219089 0.00219089 0.00219595 0.00219562 0.00219089\n",
      " 0.0022222  0.00219089 0.00219089 0.00219089 0.00219089 0.0022075\n",
      " 0.00219089 0.00220524 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219594 0.00219089 0.00219542\n",
      " 0.00227246 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219606\n",
      " 0.00219089 0.00219089 0.00219089 0.00222697 0.00220017 0.00219089\n",
      " 0.00220127 0.00219089 0.00219089 0.00219089 0.00222365 0.00220633\n",
      " 0.00219089 0.00219089 0.00221768 0.00220222 0.00222303 0.00219542\n",
      " 0.00220117 0.00220213 0.00219089 0.00219089 0.0022061  0.0021966\n",
      " 0.00221141 0.00219089 0.00219627 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00220688 0.00219089 0.00220668 0.00219089\n",
      " 0.00220135 0.00222918 0.00221088 0.00219089 0.00219627 0.00219089\n",
      " 0.00220666 0.00219089 0.00219089 0.00219089 0.00219089 0.00221029\n",
      " 0.00219089 0.00219089 0.00221254 0.00224462 0.00219089 0.0022074\n",
      " 0.00220074 0.00222917 0.00221066 0.00219089 0.00219089 0.00222183\n",
      " 0.00220096 0.00219542 0.00219089 0.00219089 0.00223949 0.00219627\n",
      " 0.00219089 0.00220177 0.00219089 0.00219089 0.00219089 0.00219594\n",
      " 0.00219089 0.00219089 0.00221142 0.00219089 0.0022007  0.00220017\n",
      " 0.00219089 0.00219089 0.00220115 0.00219089 0.00220135 0.00219089\n",
      " 0.00219089 0.0021966  0.00221176 0.00219542 0.00219089 0.00219089\n",
      " 0.00219089 0.00220716 0.00219089 0.00219542 0.00219089 0.00219583\n",
      " 0.00219089 0.00219089 0.00224079 0.00219089 0.00224461 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00220157 0.00219594 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00221244 0.00220101 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219542 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219594 0.00219089 0.00221162 0.00219089\n",
      " 0.00222228 0.00220859 0.00219089 0.00219089 0.00219089 0.00219578\n",
      " 0.00219089 0.00221132 0.00219089 0.00222618 0.00219631 0.00220133\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.0021964\n",
      " 0.00219089 0.00219089 0.002207   0.00222104 0.00219089 0.00222156\n",
      " 0.00223604 0.00220565 0.00219089 0.00219089 0.00219542 0.00221034\n",
      " 0.00220247 0.00223352 0.00219089 0.0022453  0.00219542 0.00219089\n",
      " 0.00219089 0.00219089 0.00222071 0.00219542 0.00219089 0.00221267\n",
      " 0.00219089 0.00220049 0.00221367 0.00219089 0.00221756 0.00220609\n",
      " 0.00219089 0.00219542 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219655\n",
      " 0.0021964  0.00219089 0.00221146 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219627 0.00219089 0.00219089 0.0021964  0.00219578\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.0021966  0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00223767 0.00220594 0.00219583\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00222896\n",
      " 0.00219089 0.00219089 0.00219627 0.00219089 0.00219594]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0026048839357009812\n",
      "Boosting iter: 17 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 37/20\n",
      "random state: 36\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220705 0.00219089 0.00219606 0.00220615 0.00219089 0.00219655\n",
      " 0.00219089 0.00219562 0.00219089 0.00219089 0.00219089 0.00223393\n",
      " 0.00222785 0.00219089 0.00224557 0.00219089 0.00219668 0.00219089\n",
      " 0.00222299 0.00219578 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219655 0.00219089 0.00219089 0.00220759\n",
      " 0.00219089 0.0022176  0.00219089 0.00219089 0.00219089 0.00219578\n",
      " 0.00219089 0.00219089 0.00221915 0.00221147 0.0021966  0.00219089\n",
      " 0.00219089 0.00219089 0.00219583 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00222187 0.00219089 0.00221647 0.00223317 0.00219627\n",
      " 0.00219089 0.00219089 0.00219089 0.00220129 0.00219089 0.00220097\n",
      " 0.00219583 0.00219089 0.00226158 0.00219089 0.00222362 0.00219089\n",
      " 0.00219089 0.00221852 0.00222199 0.00219542 0.00219583 0.0021964\n",
      " 0.00220593 0.00219089 0.00219595 0.00219089 0.00220682 0.00219089\n",
      " 0.00219542 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00220222 0.00219542 0.00219089 0.00219089 0.0022069\n",
      " 0.00219668 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00221685 0.00221539 0.00219089 0.00225628 0.00219089 0.00219089\n",
      " 0.00219089 0.00219583 0.00219089 0.00219089 0.00219089 0.00219542\n",
      " 0.00220017 0.00219089 0.00219089 0.00219089 0.00219578 0.00219089\n",
      " 0.00219089 0.00219089 0.00223405 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219562 0.00221228 0.00219583 0.00220784 0.00219089\n",
      " 0.00219089 0.00221621 0.00219089 0.00222794 0.00222089 0.00219583\n",
      " 0.00219583 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00220102 0.00219594 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00220702 0.00219089 0.00221288 0.00221301 0.00219089\n",
      " 0.00219089 0.00219655 0.00219089 0.00220017 0.00219089 0.00220524\n",
      " 0.00219089 0.00219089 0.00221786 0.00220242 0.00219089 0.00226738\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00220101 0.00219089 0.00219578 0.00219089 0.00219089 0.00219089\n",
      " 0.00220796 0.00219089 0.00219089 0.00219595 0.00219562 0.00219089\n",
      " 0.0022222  0.00219089 0.00219089 0.00219089 0.00219089 0.0022075\n",
      " 0.00219089 0.00220524 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219594 0.00219089 0.00219542\n",
      " 0.00227246 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219606\n",
      " 0.00219089 0.00219089 0.00219089 0.00222697 0.00220017 0.00219089\n",
      " 0.00220127 0.00219089 0.00219089 0.00219089 0.00222365 0.00220633\n",
      " 0.00219089 0.00219089 0.00221768 0.00220222 0.00222303 0.00219542\n",
      " 0.00220117 0.00220213 0.00219089 0.00219089 0.0022061  0.0021966\n",
      " 0.00221141 0.00219089 0.00219627 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00220688 0.00219089 0.00220668 0.00219089\n",
      " 0.00220135 0.00222918 0.00221088 0.00219089 0.00219627 0.00219089\n",
      " 0.00220666 0.00219089 0.00219089 0.00219089 0.00219089 0.00221029\n",
      " 0.00219089 0.00219089 0.00221254 0.00224462 0.00219089 0.0022074\n",
      " 0.00220074 0.00222917 0.00221066 0.00219089 0.00219089 0.00222183\n",
      " 0.00220096 0.00219542 0.00219089 0.00219089 0.00223949 0.00219627\n",
      " 0.00219089 0.00220177 0.00219089 0.00219089 0.00219089 0.00219594\n",
      " 0.00219089 0.00219089 0.00221142 0.00219089 0.0022007  0.00220017\n",
      " 0.00219089 0.00219089 0.00220115 0.00219089 0.00220135 0.00219089\n",
      " 0.00219089 0.0021966  0.00221176 0.00219542 0.00219089 0.00219089\n",
      " 0.00219089 0.00220716 0.00219089 0.00219542 0.00219089 0.00219583\n",
      " 0.00219089 0.00219089 0.00224079 0.00219089 0.00224461 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00220157 0.00219594 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00221244 0.00220101 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219542 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219594 0.00219089 0.00221162 0.00219089\n",
      " 0.00222228 0.00220859 0.00219089 0.00219089 0.00219089 0.00219578\n",
      " 0.00219089 0.00221132 0.00219089 0.00222618 0.00219631 0.00220133\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.0021964\n",
      " 0.00219089 0.00219089 0.002207   0.00222104 0.00219089 0.00222156\n",
      " 0.00223604 0.00220565 0.00219089 0.00219089 0.00219542 0.00221034\n",
      " 0.00220247 0.00223352 0.00219089 0.0022453  0.00219542 0.00219089\n",
      " 0.00219089 0.00219089 0.00222071 0.00219542 0.00219089 0.00221267\n",
      " 0.00219089 0.00220049 0.00221367 0.00219089 0.00221756 0.00220609\n",
      " 0.00219089 0.00219542 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219655\n",
      " 0.0021964  0.00219089 0.00221146 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219627 0.00219089 0.00219089 0.0021964  0.00219578\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.0021966  0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00223767 0.00220594 0.00219583\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00222896\n",
      " 0.00219089 0.00219089 0.00219627 0.00219089 0.00219594]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 210 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████████████████████████████████████████████████                                                               | 1199/2000 [02:29<01:40,  8.00it/s]\n",
      "[2023-12-17T22:35:09.691545+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:35:09.693114+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:35:09.694444+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:35:09.699267+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:35:09.703897+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:35:09.705437+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:35:09.708954+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_16__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 16 accuracy:  0.9296703296703297\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00221233 0.00219048 0.00219566 0.00220575 0.00219048 0.00219614\n",
      " 0.00219048 0.00219522 0.00219048 0.00219048 0.00219048 0.00223927\n",
      " 0.00222745 0.00219048 0.00224516 0.00219048 0.00219628 0.00219048\n",
      " 0.0022283  0.00219538 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219614 0.00219048 0.00219048 0.00221287\n",
      " 0.00219048 0.00221719 0.00219048 0.00219048 0.00219048 0.00219538\n",
      " 0.00219048 0.00219048 0.00222445 0.00221107 0.0021962  0.00219048\n",
      " 0.00219048 0.00219048 0.00219543 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00222146 0.00219048 0.00221606 0.00223276 0.00219586\n",
      " 0.00219048 0.00219048 0.00219048 0.00220089 0.00219048 0.00220057\n",
      " 0.00219543 0.00219048 0.00226117 0.00219048 0.00222321 0.00219048\n",
      " 0.00219048 0.00222382 0.00222159 0.00219502 0.00219543 0.002196\n",
      " 0.0022112  0.00219048 0.00219555 0.00219048 0.00220642 0.00219048\n",
      " 0.00219502 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00220182 0.00219502 0.00219048 0.00219048 0.0022065\n",
      " 0.00220193 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00221645 0.00221499 0.00219048 0.00226167 0.00219048 0.00219048\n",
      " 0.00219048 0.00219543 0.00219048 0.00219048 0.00219048 0.00219502\n",
      " 0.00219976 0.00219048 0.00219048 0.00219048 0.00219538 0.00219048\n",
      " 0.00219048 0.00219048 0.00223939 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219522 0.00221187 0.00219543 0.00220743 0.00219048\n",
      " 0.00219048 0.0022158  0.00219048 0.00223326 0.00222049 0.00219543\n",
      " 0.00219543 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00220062 0.00219554 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00220662 0.00219048 0.00221247 0.0022183  0.00219048\n",
      " 0.00219048 0.00219614 0.00219048 0.00219976 0.00219048 0.00220484\n",
      " 0.00219048 0.00219048 0.00221745 0.00220202 0.00219048 0.0022728\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00220061 0.00219048 0.00219538 0.00219048 0.00219048 0.00219048\n",
      " 0.00220756 0.00219048 0.00219048 0.00219555 0.00219522 0.00219048\n",
      " 0.0022218  0.00219048 0.00219048 0.00219048 0.00219048 0.0022071\n",
      " 0.00219048 0.00220484 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219554 0.00219048 0.00219502\n",
      " 0.00227789 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219566\n",
      " 0.00219048 0.00219048 0.00219048 0.00222657 0.00219976 0.00219048\n",
      " 0.00220087 0.00219048 0.00219048 0.00219048 0.00222897 0.0022116\n",
      " 0.00219048 0.00219048 0.00222298 0.00220182 0.00222834 0.00219502\n",
      " 0.00220077 0.00220172 0.00219048 0.00219048 0.0022057  0.0021962\n",
      " 0.002211   0.00219048 0.00219586 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00220648 0.00219048 0.00220628 0.00219048\n",
      " 0.00220094 0.00222877 0.00221048 0.00219048 0.00219586 0.00219048\n",
      " 0.00220625 0.00219048 0.00219048 0.00219048 0.00219048 0.00220989\n",
      " 0.00219048 0.00219048 0.00221213 0.00224998 0.00219048 0.00220699\n",
      " 0.00220034 0.00222876 0.00221025 0.00219048 0.00219048 0.00222143\n",
      " 0.00220055 0.00219502 0.00219048 0.00219048 0.00224484 0.00219586\n",
      " 0.00219048 0.00220136 0.00219048 0.00219048 0.00219048 0.00219554\n",
      " 0.00219048 0.00219048 0.0022167  0.00219048 0.00220029 0.00219976\n",
      " 0.00219048 0.00219048 0.00220075 0.00219048 0.00220094 0.00219048\n",
      " 0.00219048 0.0021962  0.00221136 0.00219502 0.00219048 0.00219048\n",
      " 0.00219048 0.00220676 0.00219048 0.00219502 0.00219048 0.00219543\n",
      " 0.00219048 0.00219048 0.00224038 0.00219048 0.0022442  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00220683 0.00219554 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00221203 0.0022006  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219502 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219554 0.00219048 0.00221122 0.00219048\n",
      " 0.00222188 0.00220818 0.00219048 0.00219048 0.00219048 0.00219538\n",
      " 0.00219048 0.0022166  0.00219048 0.00222577 0.00219591 0.00220093\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00220165\n",
      " 0.00219048 0.00219048 0.0022066  0.00222063 0.00219048 0.00222687\n",
      " 0.00224138 0.00220525 0.00219048 0.00219048 0.00219502 0.00220994\n",
      " 0.00220207 0.00223885 0.00219048 0.00225067 0.00219502 0.00219048\n",
      " 0.00219048 0.00219048 0.0022203  0.00219502 0.00219048 0.00221227\n",
      " 0.00219048 0.00220009 0.00221326 0.00219048 0.00222286 0.00220568\n",
      " 0.00219048 0.00219502 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219614\n",
      " 0.00220165 0.00219048 0.00221106 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219586 0.00219048 0.00219048 0.002196   0.00219538\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.0021962  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00224302 0.00220554 0.00219543\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00223429\n",
      " 0.00219048 0.00219048 0.00219586 0.00219048 0.00219554]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0025687711105727555\n",
      "Boosting iter: 18 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 38/20\n",
      "random state: 37\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00221233 0.00219048 0.00219566 0.00220575 0.00219048 0.00219614\n",
      " 0.00219048 0.00219522 0.00219048 0.00219048 0.00219048 0.00223927\n",
      " 0.00222745 0.00219048 0.00224516 0.00219048 0.00219628 0.00219048\n",
      " 0.0022283  0.00219538 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219614 0.00219048 0.00219048 0.00221287\n",
      " 0.00219048 0.00221719 0.00219048 0.00219048 0.00219048 0.00219538\n",
      " 0.00219048 0.00219048 0.00222445 0.00221107 0.0021962  0.00219048\n",
      " 0.00219048 0.00219048 0.00219543 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00222146 0.00219048 0.00221606 0.00223276 0.00219586\n",
      " 0.00219048 0.00219048 0.00219048 0.00220089 0.00219048 0.00220057\n",
      " 0.00219543 0.00219048 0.00226117 0.00219048 0.00222321 0.00219048\n",
      " 0.00219048 0.00222382 0.00222159 0.00219502 0.00219543 0.002196\n",
      " 0.0022112  0.00219048 0.00219555 0.00219048 0.00220642 0.00219048\n",
      " 0.00219502 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00220182 0.00219502 0.00219048 0.00219048 0.0022065\n",
      " 0.00220193 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00221645 0.00221499 0.00219048 0.00226167 0.00219048 0.00219048\n",
      " 0.00219048 0.00219543 0.00219048 0.00219048 0.00219048 0.00219502\n",
      " 0.00219976 0.00219048 0.00219048 0.00219048 0.00219538 0.00219048\n",
      " 0.00219048 0.00219048 0.00223939 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219522 0.00221187 0.00219543 0.00220743 0.00219048\n",
      " 0.00219048 0.0022158  0.00219048 0.00223326 0.00222049 0.00219543\n",
      " 0.00219543 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00220062 0.00219554 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00220662 0.00219048 0.00221247 0.0022183  0.00219048\n",
      " 0.00219048 0.00219614 0.00219048 0.00219976 0.00219048 0.00220484\n",
      " 0.00219048 0.00219048 0.00221745 0.00220202 0.00219048 0.0022728\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00220061 0.00219048 0.00219538 0.00219048 0.00219048 0.00219048\n",
      " 0.00220756 0.00219048 0.00219048 0.00219555 0.00219522 0.00219048\n",
      " 0.0022218  0.00219048 0.00219048 0.00219048 0.00219048 0.0022071\n",
      " 0.00219048 0.00220484 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219554 0.00219048 0.00219502\n",
      " 0.00227789 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219566\n",
      " 0.00219048 0.00219048 0.00219048 0.00222657 0.00219976 0.00219048\n",
      " 0.00220087 0.00219048 0.00219048 0.00219048 0.00222897 0.0022116\n",
      " 0.00219048 0.00219048 0.00222298 0.00220182 0.00222834 0.00219502\n",
      " 0.00220077 0.00220172 0.00219048 0.00219048 0.0022057  0.0021962\n",
      " 0.002211   0.00219048 0.00219586 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00220648 0.00219048 0.00220628 0.00219048\n",
      " 0.00220094 0.00222877 0.00221048 0.00219048 0.00219586 0.00219048\n",
      " 0.00220625 0.00219048 0.00219048 0.00219048 0.00219048 0.00220989\n",
      " 0.00219048 0.00219048 0.00221213 0.00224998 0.00219048 0.00220699\n",
      " 0.00220034 0.00222876 0.00221025 0.00219048 0.00219048 0.00222143\n",
      " 0.00220055 0.00219502 0.00219048 0.00219048 0.00224484 0.00219586\n",
      " 0.00219048 0.00220136 0.00219048 0.00219048 0.00219048 0.00219554\n",
      " 0.00219048 0.00219048 0.0022167  0.00219048 0.00220029 0.00219976\n",
      " 0.00219048 0.00219048 0.00220075 0.00219048 0.00220094 0.00219048\n",
      " 0.00219048 0.0021962  0.00221136 0.00219502 0.00219048 0.00219048\n",
      " 0.00219048 0.00220676 0.00219048 0.00219502 0.00219048 0.00219543\n",
      " 0.00219048 0.00219048 0.00224038 0.00219048 0.0022442  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00220683 0.00219554 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00221203 0.0022006  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219502 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219554 0.00219048 0.00221122 0.00219048\n",
      " 0.00222188 0.00220818 0.00219048 0.00219048 0.00219048 0.00219538\n",
      " 0.00219048 0.0022166  0.00219048 0.00222577 0.00219591 0.00220093\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00220165\n",
      " 0.00219048 0.00219048 0.0022066  0.00222063 0.00219048 0.00222687\n",
      " 0.00224138 0.00220525 0.00219048 0.00219048 0.00219502 0.00220994\n",
      " 0.00220207 0.00223885 0.00219048 0.00225067 0.00219502 0.00219048\n",
      " 0.00219048 0.00219048 0.0022203  0.00219502 0.00219048 0.00221227\n",
      " 0.00219048 0.00220009 0.00221326 0.00219048 0.00222286 0.00220568\n",
      " 0.00219048 0.00219502 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219614\n",
      " 0.00220165 0.00219048 0.00221106 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219586 0.00219048 0.00219048 0.002196   0.00219538\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.0021962  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00224302 0.00220554 0.00219543\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00223429\n",
      " 0.00219048 0.00219048 0.00219586 0.00219048 0.00219554]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 360,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 210 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  67 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  34 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████████████████▎                                                                                                              | 599/2000 [01:05<02:34,  9.08it/s]\n",
      "[2023-12-17T22:36:21.787939+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:36:21.789937+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:36:21.791148+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:36:21.792622+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:36:21.795237+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:36:21.796794+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:36:21.798066+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_17__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 17 accuracy:  0.9362637362637363\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00221194 0.00219011 0.00219528 0.00220537 0.00219011 0.00219576\n",
      " 0.00219011 0.00219484 0.00219011 0.00219011 0.00219011 0.00224487\n",
      " 0.00222706 0.00219011 0.00225077 0.00219011 0.0021959  0.00219011\n",
      " 0.00222792 0.002195   0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219576 0.00219011 0.00219011 0.00221248\n",
      " 0.00219011 0.00221681 0.00219011 0.00219011 0.00219011 0.002195\n",
      " 0.00219011 0.00219011 0.00223001 0.00221069 0.00219582 0.00219011\n",
      " 0.00219011 0.00219011 0.00219505 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00222108 0.00219011 0.00221568 0.00223237 0.00219548\n",
      " 0.00219011 0.00219011 0.00219011 0.00220051 0.00219011 0.00220018\n",
      " 0.00219505 0.00219011 0.00226682 0.00219011 0.00222283 0.00219011\n",
      " 0.00219011 0.00222344 0.0022212  0.00219464 0.00219505 0.00219562\n",
      " 0.00221673 0.00219011 0.00219517 0.00219011 0.00220603 0.00219011\n",
      " 0.00219464 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00220143 0.00219464 0.00219011 0.00219011 0.00220612\n",
      " 0.00220155 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00222199 0.0022146  0.00219011 0.00226732 0.00219011 0.00219011\n",
      " 0.00219011 0.00219505 0.00219011 0.00219011 0.00219011 0.00219464\n",
      " 0.00219938 0.00219011 0.00219011 0.00219011 0.002195   0.00219011\n",
      " 0.00219011 0.00219011 0.002239   0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219484 0.00221149 0.00219505 0.00220705 0.00219011\n",
      " 0.00219011 0.00221542 0.00219011 0.00223884 0.0022201  0.00219505\n",
      " 0.00219505 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00220024 0.00219516 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00220624 0.00219011 0.00221209 0.00222385 0.00219011\n",
      " 0.00219011 0.00219576 0.00219011 0.00219938 0.00219011 0.00220446\n",
      " 0.00219011 0.00219011 0.00221707 0.00220164 0.00219011 0.00227848\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00220023 0.00219011 0.002195   0.00219011 0.00219011 0.00219011\n",
      " 0.00220718 0.00219011 0.00219011 0.00219517 0.00219484 0.00219011\n",
      " 0.00222141 0.00219011 0.00219011 0.00219011 0.00219011 0.00220672\n",
      " 0.00219011 0.00220446 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219516 0.00219011 0.00219464\n",
      " 0.00228359 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219528\n",
      " 0.00219011 0.00219011 0.00219596 0.00223214 0.00219938 0.00219011\n",
      " 0.00220049 0.00219011 0.00219011 0.00219011 0.00222858 0.00221713\n",
      " 0.00219011 0.00219011 0.00222854 0.00220143 0.00222796 0.00219464\n",
      " 0.00220039 0.00220134 0.00219011 0.00219011 0.00220531 0.00219582\n",
      " 0.00221062 0.00219011 0.00219548 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.0022061  0.00219011 0.00220589 0.00219011\n",
      " 0.00220056 0.00223435 0.0022101  0.00219011 0.00219548 0.00219011\n",
      " 0.00220587 0.00219011 0.00219011 0.00219011 0.00219011 0.00220951\n",
      " 0.00219011 0.00219011 0.00221175 0.00225561 0.00219011 0.00220661\n",
      " 0.00219996 0.00223433 0.00220987 0.00219011 0.00219011 0.00222104\n",
      " 0.00220017 0.00219464 0.00219011 0.00219011 0.00225045 0.00219548\n",
      " 0.00219011 0.00220098 0.00219011 0.00219011 0.00219011 0.00219516\n",
      " 0.00219011 0.00219011 0.00221632 0.00219011 0.00219991 0.00219938\n",
      " 0.00219011 0.00219011 0.00220037 0.00219011 0.00220056 0.00219011\n",
      " 0.00219011 0.00219582 0.00221689 0.00219464 0.00219011 0.00219011\n",
      " 0.00219011 0.00221228 0.00219011 0.00219464 0.00219011 0.00219505\n",
      " 0.00219011 0.00219011 0.00224598 0.00219011 0.00224981 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00220645 0.00219516 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00221165 0.00220022 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219464 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00220103 0.00219011 0.00221084 0.00219011\n",
      " 0.00222149 0.0022078  0.00219011 0.00219011 0.00219011 0.002195\n",
      " 0.00219011 0.00221622 0.00219011 0.00222539 0.00219553 0.00220055\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00220127\n",
      " 0.00219011 0.00219011 0.00220622 0.00222025 0.00219011 0.00223244\n",
      " 0.00224699 0.00220487 0.00219011 0.00219011 0.00219464 0.00220956\n",
      " 0.00220168 0.00224445 0.00219011 0.00225028 0.00219464 0.00219011\n",
      " 0.00219011 0.00219011 0.00221992 0.00219464 0.00219011 0.00221188\n",
      " 0.00219011 0.00219971 0.00221288 0.00219011 0.00222247 0.0022053\n",
      " 0.00219011 0.00219464 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219576\n",
      " 0.00220716 0.00219011 0.00221067 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219548 0.00219011 0.00219011 0.00219562 0.002195\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219582 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00224862 0.00220515 0.00219505\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.0022339\n",
      " 0.00219011 0.00219011 0.00219548 0.00219011 0.00219516]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002670849097163872\n",
      "Boosting iter: 19 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 39/20\n",
      "random state: 38\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00221194 0.00219011 0.00219528 0.00220537 0.00219011 0.00219576\n",
      " 0.00219011 0.00219484 0.00219011 0.00219011 0.00219011 0.00224487\n",
      " 0.00222706 0.00219011 0.00225077 0.00219011 0.0021959  0.00219011\n",
      " 0.00222792 0.002195   0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219576 0.00219011 0.00219011 0.00221248\n",
      " 0.00219011 0.00221681 0.00219011 0.00219011 0.00219011 0.002195\n",
      " 0.00219011 0.00219011 0.00223001 0.00221069 0.00219582 0.00219011\n",
      " 0.00219011 0.00219011 0.00219505 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00222108 0.00219011 0.00221568 0.00223237 0.00219548\n",
      " 0.00219011 0.00219011 0.00219011 0.00220051 0.00219011 0.00220018\n",
      " 0.00219505 0.00219011 0.00226682 0.00219011 0.00222283 0.00219011\n",
      " 0.00219011 0.00222344 0.0022212  0.00219464 0.00219505 0.00219562\n",
      " 0.00221673 0.00219011 0.00219517 0.00219011 0.00220603 0.00219011\n",
      " 0.00219464 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00220143 0.00219464 0.00219011 0.00219011 0.00220612\n",
      " 0.00220155 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00222199 0.0022146  0.00219011 0.00226732 0.00219011 0.00219011\n",
      " 0.00219011 0.00219505 0.00219011 0.00219011 0.00219011 0.00219464\n",
      " 0.00219938 0.00219011 0.00219011 0.00219011 0.002195   0.00219011\n",
      " 0.00219011 0.00219011 0.002239   0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219484 0.00221149 0.00219505 0.00220705 0.00219011\n",
      " 0.00219011 0.00221542 0.00219011 0.00223884 0.0022201  0.00219505\n",
      " 0.00219505 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00220024 0.00219516 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00220624 0.00219011 0.00221209 0.00222385 0.00219011\n",
      " 0.00219011 0.00219576 0.00219011 0.00219938 0.00219011 0.00220446\n",
      " 0.00219011 0.00219011 0.00221707 0.00220164 0.00219011 0.00227848\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00220023 0.00219011 0.002195   0.00219011 0.00219011 0.00219011\n",
      " 0.00220718 0.00219011 0.00219011 0.00219517 0.00219484 0.00219011\n",
      " 0.00222141 0.00219011 0.00219011 0.00219011 0.00219011 0.00220672\n",
      " 0.00219011 0.00220446 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219516 0.00219011 0.00219464\n",
      " 0.00228359 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219528\n",
      " 0.00219011 0.00219011 0.00219596 0.00223214 0.00219938 0.00219011\n",
      " 0.00220049 0.00219011 0.00219011 0.00219011 0.00222858 0.00221713\n",
      " 0.00219011 0.00219011 0.00222854 0.00220143 0.00222796 0.00219464\n",
      " 0.00220039 0.00220134 0.00219011 0.00219011 0.00220531 0.00219582\n",
      " 0.00221062 0.00219011 0.00219548 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.0022061  0.00219011 0.00220589 0.00219011\n",
      " 0.00220056 0.00223435 0.0022101  0.00219011 0.00219548 0.00219011\n",
      " 0.00220587 0.00219011 0.00219011 0.00219011 0.00219011 0.00220951\n",
      " 0.00219011 0.00219011 0.00221175 0.00225561 0.00219011 0.00220661\n",
      " 0.00219996 0.00223433 0.00220987 0.00219011 0.00219011 0.00222104\n",
      " 0.00220017 0.00219464 0.00219011 0.00219011 0.00225045 0.00219548\n",
      " 0.00219011 0.00220098 0.00219011 0.00219011 0.00219011 0.00219516\n",
      " 0.00219011 0.00219011 0.00221632 0.00219011 0.00219991 0.00219938\n",
      " 0.00219011 0.00219011 0.00220037 0.00219011 0.00220056 0.00219011\n",
      " 0.00219011 0.00219582 0.00221689 0.00219464 0.00219011 0.00219011\n",
      " 0.00219011 0.00221228 0.00219011 0.00219464 0.00219011 0.00219505\n",
      " 0.00219011 0.00219011 0.00224598 0.00219011 0.00224981 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00220645 0.00219516 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00221165 0.00220022 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219464 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00220103 0.00219011 0.00221084 0.00219011\n",
      " 0.00222149 0.0022078  0.00219011 0.00219011 0.00219011 0.002195\n",
      " 0.00219011 0.00221622 0.00219011 0.00222539 0.00219553 0.00220055\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00220127\n",
      " 0.00219011 0.00219011 0.00220622 0.00222025 0.00219011 0.00223244\n",
      " 0.00224699 0.00220487 0.00219011 0.00219011 0.00219464 0.00220956\n",
      " 0.00220168 0.00224445 0.00219011 0.00225028 0.00219464 0.00219011\n",
      " 0.00219011 0.00219011 0.00221992 0.00219464 0.00219011 0.00221188\n",
      " 0.00219011 0.00219971 0.00221288 0.00219011 0.00222247 0.0022053\n",
      " 0.00219011 0.00219464 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219576\n",
      " 0.00220716 0.00219011 0.00221067 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219548 0.00219011 0.00219011 0.00219562 0.002195\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219582 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00224862 0.00220515 0.00219505\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.0022339\n",
      " 0.00219011 0.00219011 0.00219548 0.00219011 0.00219516]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 360,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 210 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  34 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████████████████████████████████                                                                                               | 799/2000 [01:30<02:15,  8.85it/s]\n",
      "[2023-12-17T22:37:58.143356+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:37:58.145254+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:37:58.147575+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:37:58.149837+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:37:58.153613+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:37:58.155121+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:37:58.156627+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_18__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 18 accuracy:  0.9252747252747253\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00221706 0.00218969 0.00219486 0.00220495 0.00218969 0.00219535\n",
      " 0.00218969 0.00219442 0.00218969 0.00218969 0.00218969 0.00225007\n",
      " 0.00223222 0.00218969 0.00225598 0.00218969 0.00219549 0.00218969\n",
      " 0.00223307 0.00219458 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00219535 0.00218969 0.00218969 0.00221206\n",
      " 0.00218969 0.00221639 0.00218969 0.00218969 0.00218969 0.00219458\n",
      " 0.00218969 0.00218969 0.00222959 0.00221027 0.0021954  0.00218969\n",
      " 0.00218969 0.00218969 0.00219464 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00222066 0.00218969 0.00221526 0.00223195 0.00219507\n",
      " 0.00218969 0.00218969 0.00218969 0.00220009 0.00218969 0.00219977\n",
      " 0.00219464 0.00218969 0.00227207 0.00218969 0.00222797 0.00218969\n",
      " 0.00218969 0.00222858 0.00222078 0.00219423 0.00219464 0.00219521\n",
      " 0.00221631 0.00218969 0.00219476 0.00218969 0.00221114 0.00218969\n",
      " 0.00219423 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00220102 0.00219423 0.00218969 0.00218969 0.00221122\n",
      " 0.00220113 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00222157 0.00221973 0.00218969 0.00227257 0.00218969 0.00218969\n",
      " 0.00218969 0.00219464 0.00218969 0.00218969 0.00218969 0.00219423\n",
      " 0.00219897 0.00218969 0.00218969 0.00218969 0.00219458 0.00218969\n",
      " 0.00218969 0.00218969 0.00223857 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00219442 0.00221107 0.00219464 0.00220663 0.00218969\n",
      " 0.00218969 0.002215   0.00218969 0.00224403 0.00221968 0.00219464\n",
      " 0.00219464 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00219982 0.00219474 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00220582 0.00218969 0.00221167 0.00222342 0.00218969\n",
      " 0.00218969 0.00219535 0.00218969 0.00219897 0.00218969 0.00220404\n",
      " 0.00218969 0.00218969 0.0022222  0.00220122 0.00218969 0.00228376\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00220532 0.00218969 0.00219458 0.00218969 0.00218969 0.00218969\n",
      " 0.00220676 0.00218969 0.00218969 0.00219476 0.00219442 0.00218969\n",
      " 0.00222099 0.00218969 0.00218969 0.00218969 0.00218969 0.0022063\n",
      " 0.00218969 0.00220404 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00219474 0.00218969 0.00219423\n",
      " 0.00228887 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00219486\n",
      " 0.00218969 0.00218969 0.00219555 0.00223171 0.00219897 0.00218969\n",
      " 0.00220007 0.00218969 0.00218969 0.00218969 0.00223374 0.00221671\n",
      " 0.00218969 0.00218969 0.0022337  0.00220102 0.00222754 0.00219423\n",
      " 0.00219997 0.00220092 0.00218969 0.00218969 0.0022049  0.0021954\n",
      " 0.0022102  0.00218969 0.00219507 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00220568 0.00218969 0.00220548 0.00218969\n",
      " 0.00220015 0.00223952 0.00220968 0.00218969 0.00219507 0.00218969\n",
      " 0.00220545 0.00218969 0.00218969 0.00218969 0.00218969 0.00220909\n",
      " 0.00218969 0.00218969 0.00221687 0.00225518 0.00218969 0.00220619\n",
      " 0.00219954 0.00223391 0.00220945 0.00218969 0.00218969 0.00222618\n",
      " 0.00219975 0.00219423 0.00218969 0.00218969 0.00225003 0.00219507\n",
      " 0.00218969 0.00220056 0.00218969 0.00218969 0.00218969 0.00219474\n",
      " 0.00219518 0.00218969 0.0022159  0.00218969 0.0021995  0.00219897\n",
      " 0.00218969 0.00218969 0.00219995 0.00218969 0.00220566 0.00218969\n",
      " 0.00218969 0.0021954  0.00222202 0.00219423 0.00218969 0.00218969\n",
      " 0.00218969 0.00221186 0.00218969 0.00219423 0.00218969 0.00219464\n",
      " 0.00218969 0.00218969 0.00225118 0.00218969 0.00225502 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00220603 0.00219474 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00221677 0.0021998  0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00219423 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00220061 0.00218969 0.00221042 0.00218969\n",
      " 0.00222107 0.00220738 0.00218969 0.00218969 0.00218969 0.00219458\n",
      " 0.00218969 0.0022158  0.00218969 0.00223054 0.00219511 0.00220013\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00220085\n",
      " 0.00218969 0.00219518 0.0022058  0.00221983 0.00218969 0.00223761\n",
      " 0.00224656 0.00220445 0.00218969 0.00218969 0.00219423 0.00220914\n",
      " 0.00220678 0.00224402 0.00218969 0.00224985 0.00219423 0.00218969\n",
      " 0.00218969 0.00218969 0.0022195  0.00219423 0.00218969 0.00221146\n",
      " 0.00218969 0.00219929 0.00221246 0.00219518 0.00222205 0.00220488\n",
      " 0.00218969 0.00219423 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00219535\n",
      " 0.00220674 0.00218969 0.00221025 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00219507 0.00218969 0.00218969 0.00219521 0.00219458\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.0021954  0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.0022482  0.00220474 0.00219464\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00223907\n",
      " 0.00218969 0.00218969 0.00219507 0.00218969 0.00219474]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0025022473149690356\n",
      "Boosting iter: 20 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 40/20\n",
      "random state: 39\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00221706 0.00218969 0.00219486 0.00220495 0.00218969 0.00219535\n",
      " 0.00218969 0.00219442 0.00218969 0.00218969 0.00218969 0.00225007\n",
      " 0.00223222 0.00218969 0.00225598 0.00218969 0.00219549 0.00218969\n",
      " 0.00223307 0.00219458 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00219535 0.00218969 0.00218969 0.00221206\n",
      " 0.00218969 0.00221639 0.00218969 0.00218969 0.00218969 0.00219458\n",
      " 0.00218969 0.00218969 0.00222959 0.00221027 0.0021954  0.00218969\n",
      " 0.00218969 0.00218969 0.00219464 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00222066 0.00218969 0.00221526 0.00223195 0.00219507\n",
      " 0.00218969 0.00218969 0.00218969 0.00220009 0.00218969 0.00219977\n",
      " 0.00219464 0.00218969 0.00227207 0.00218969 0.00222797 0.00218969\n",
      " 0.00218969 0.00222858 0.00222078 0.00219423 0.00219464 0.00219521\n",
      " 0.00221631 0.00218969 0.00219476 0.00218969 0.00221114 0.00218969\n",
      " 0.00219423 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00220102 0.00219423 0.00218969 0.00218969 0.00221122\n",
      " 0.00220113 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00222157 0.00221973 0.00218969 0.00227257 0.00218969 0.00218969\n",
      " 0.00218969 0.00219464 0.00218969 0.00218969 0.00218969 0.00219423\n",
      " 0.00219897 0.00218969 0.00218969 0.00218969 0.00219458 0.00218969\n",
      " 0.00218969 0.00218969 0.00223857 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00219442 0.00221107 0.00219464 0.00220663 0.00218969\n",
      " 0.00218969 0.002215   0.00218969 0.00224403 0.00221968 0.00219464\n",
      " 0.00219464 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00219982 0.00219474 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00220582 0.00218969 0.00221167 0.00222342 0.00218969\n",
      " 0.00218969 0.00219535 0.00218969 0.00219897 0.00218969 0.00220404\n",
      " 0.00218969 0.00218969 0.0022222  0.00220122 0.00218969 0.00228376\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00220532 0.00218969 0.00219458 0.00218969 0.00218969 0.00218969\n",
      " 0.00220676 0.00218969 0.00218969 0.00219476 0.00219442 0.00218969\n",
      " 0.00222099 0.00218969 0.00218969 0.00218969 0.00218969 0.0022063\n",
      " 0.00218969 0.00220404 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00219474 0.00218969 0.00219423\n",
      " 0.00228887 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00219486\n",
      " 0.00218969 0.00218969 0.00219555 0.00223171 0.00219897 0.00218969\n",
      " 0.00220007 0.00218969 0.00218969 0.00218969 0.00223374 0.00221671\n",
      " 0.00218969 0.00218969 0.0022337  0.00220102 0.00222754 0.00219423\n",
      " 0.00219997 0.00220092 0.00218969 0.00218969 0.0022049  0.0021954\n",
      " 0.0022102  0.00218969 0.00219507 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00220568 0.00218969 0.00220548 0.00218969\n",
      " 0.00220015 0.00223952 0.00220968 0.00218969 0.00219507 0.00218969\n",
      " 0.00220545 0.00218969 0.00218969 0.00218969 0.00218969 0.00220909\n",
      " 0.00218969 0.00218969 0.00221687 0.00225518 0.00218969 0.00220619\n",
      " 0.00219954 0.00223391 0.00220945 0.00218969 0.00218969 0.00222618\n",
      " 0.00219975 0.00219423 0.00218969 0.00218969 0.00225003 0.00219507\n",
      " 0.00218969 0.00220056 0.00218969 0.00218969 0.00218969 0.00219474\n",
      " 0.00219518 0.00218969 0.0022159  0.00218969 0.0021995  0.00219897\n",
      " 0.00218969 0.00218969 0.00219995 0.00218969 0.00220566 0.00218969\n",
      " 0.00218969 0.0021954  0.00222202 0.00219423 0.00218969 0.00218969\n",
      " 0.00218969 0.00221186 0.00218969 0.00219423 0.00218969 0.00219464\n",
      " 0.00218969 0.00218969 0.00225118 0.00218969 0.00225502 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00220603 0.00219474 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00221677 0.0021998  0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00219423 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00220061 0.00218969 0.00221042 0.00218969\n",
      " 0.00222107 0.00220738 0.00218969 0.00218969 0.00218969 0.00219458\n",
      " 0.00218969 0.0022158  0.00218969 0.00223054 0.00219511 0.00220013\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00220085\n",
      " 0.00218969 0.00219518 0.0022058  0.00221983 0.00218969 0.00223761\n",
      " 0.00224656 0.00220445 0.00218969 0.00218969 0.00219423 0.00220914\n",
      " 0.00220678 0.00224402 0.00218969 0.00224985 0.00219423 0.00218969\n",
      " 0.00218969 0.00218969 0.0022195  0.00219423 0.00218969 0.00221146\n",
      " 0.00218969 0.00219929 0.00221246 0.00219518 0.00222205 0.00220488\n",
      " 0.00218969 0.00219423 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00219535\n",
      " 0.00220674 0.00218969 0.00221025 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00219507 0.00218969 0.00218969 0.00219521 0.00219458\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.0021954  0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.0022482  0.00220474 0.00219464\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00223907\n",
      " 0.00218969 0.00218969 0.00219507 0.00218969 0.00219474]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 272, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 210 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  34 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True,  True, False, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████████████████████████████████                                                                                               | 799/2000 [01:45<02:39,  7.54it/s]\n",
      "[2023-12-17T22:39:50.219211+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:39:50.221384+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:39:50.223154+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:39:50.225570+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:39:50.229379+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:39:50.231266+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:39:50.232987+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_19__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 19 accuracy:  0.9340659340659341\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00222252 0.0021893  0.00219448 0.00220456 0.0021893  0.00219496\n",
      " 0.0021893  0.00219403 0.0021893  0.0021893  0.0021893  0.0022556\n",
      " 0.00223182 0.0021893  0.00226153 0.0021893  0.0021951  0.0021893\n",
      " 0.00223268 0.00219419 0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.00220075 0.0021893  0.0021893  0.00221167\n",
      " 0.0021893  0.002216   0.0021893  0.0021893  0.0021893  0.00219419\n",
      " 0.0021893  0.0021893  0.00223507 0.00220988 0.00219501 0.0021893\n",
      " 0.0021893  0.0021893  0.00219425 0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.00222027 0.0021893  0.00221487 0.00223156 0.00219468\n",
      " 0.0021893  0.0021893  0.0021893  0.0021997  0.0021893  0.00219938\n",
      " 0.00219425 0.0021893  0.00227766 0.0021893  0.00222758 0.0021893\n",
      " 0.0021893  0.00222819 0.00222039 0.00219384 0.00219425 0.00219482\n",
      " 0.00222176 0.0021893  0.00219437 0.0021893  0.00221658 0.0021893\n",
      " 0.00219384 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.00220063 0.00219384 0.0021893  0.0021893  0.00221083\n",
      " 0.00220074 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.00222118 0.00221934 0.0021893  0.00227816 0.0021893  0.0021893\n",
      " 0.0021893  0.00219425 0.0021893  0.0021893  0.0021893  0.00219962\n",
      " 0.00219858 0.0021893  0.0021893  0.0021893  0.00219419 0.0021893\n",
      " 0.0021893  0.0021893  0.00223818 0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.00219403 0.00221068 0.00219425 0.00220624 0.0021893\n",
      " 0.0021893  0.0022146  0.0021893  0.00224955 0.00221929 0.00219425\n",
      " 0.00219425 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.00219943 0.00220014 0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.00220543 0.0021893  0.00221128 0.00222889 0.0021893\n",
      " 0.0021893  0.00219496 0.0021893  0.00219858 0.0021893  0.00220365\n",
      " 0.0021893  0.0021893  0.00222181 0.00220083 0.0021893  0.00228937\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.00220493 0.0021893  0.00219419 0.0021893  0.0021893  0.0021893\n",
      " 0.00220637 0.0021893  0.0021893  0.00219437 0.00219403 0.0021893\n",
      " 0.0022206  0.0021893  0.0021893  0.0021893  0.0021893  0.00220591\n",
      " 0.0021893  0.00220946 0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.00219435 0.0021893  0.00219384\n",
      " 0.0022945  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.00219448\n",
      " 0.0021893  0.0021893  0.00219516 0.00223132 0.00219858 0.0021893\n",
      " 0.00219968 0.0021893  0.0021893  0.0021893  0.00223923 0.00221632\n",
      " 0.0021893  0.0021893  0.0022333  0.00220063 0.00222714 0.00219384\n",
      " 0.00219958 0.00220054 0.0021893  0.0021893  0.00220451 0.00219501\n",
      " 0.00220981 0.0021893  0.00219468 0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0022111  0.0021893  0.00220509 0.0021893\n",
      " 0.00219976 0.00224503 0.00220929 0.0021893  0.00219468 0.0021893\n",
      " 0.00221088 0.0021893  0.0021893  0.0021893  0.0021893  0.0022087\n",
      " 0.0021893  0.0021893  0.00221648 0.00226072 0.0021893  0.0022058\n",
      " 0.00219915 0.00223352 0.00220906 0.0021893  0.0021893  0.00222579\n",
      " 0.00219937 0.00219384 0.0021893  0.0021893  0.00225556 0.00219468\n",
      " 0.0021893  0.00220018 0.0021893  0.0021893  0.0021893  0.00219435\n",
      " 0.00219479 0.0021893  0.0022155  0.0021893  0.00219911 0.00219858\n",
      " 0.0021893  0.0021893  0.00219956 0.0021893  0.00220527 0.0021893\n",
      " 0.0021893  0.00219501 0.00222163 0.00219384 0.0021893  0.0021893\n",
      " 0.0021893  0.00221147 0.0021893  0.00219384 0.0021893  0.00219425\n",
      " 0.0021893  0.0021893  0.00225672 0.0021893  0.00226057 0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.00220564 0.00219435 0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.00222222 0.00219942 0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.00219384 0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.00220022 0.0021893  0.00221003 0.0021893\n",
      " 0.00222068 0.00220699 0.0021893  0.0021893  0.0021893  0.00219419\n",
      " 0.0021893  0.0022154  0.0021893  0.00223602 0.00219473 0.00219974\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.00220046\n",
      " 0.0021893  0.00219479 0.00220541 0.00221944 0.0021893  0.00224311\n",
      " 0.00224616 0.00220987 0.0021893  0.0021893  0.00219384 0.00220875\n",
      " 0.00220639 0.00224954 0.0021893  0.00224945 0.00219384 0.0021893\n",
      " 0.0021893  0.0021893  0.00221911 0.00219384 0.0021893  0.00221107\n",
      " 0.0021893  0.0021989  0.00221207 0.00219479 0.00222166 0.0022045\n",
      " 0.0021893  0.00219384 0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.00219496\n",
      " 0.00220635 0.0021893  0.00220986 0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.00219468 0.0021893  0.0021893  0.00219482 0.00219419\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.00219501 0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0022478  0.00220435 0.00219425\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.00224458\n",
      " 0.0021893  0.0021893  0.00219468 0.0021893  0.00219435]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002633369102196049\n",
      "Finished run 1 / 3\n",
      "Run 3 / 3\n",
      "Boosting iter: 1 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 41/20\n",
      "random state: 40\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  None\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████        | 1899/2000 [03:02<00:09, 10.42it/s]\n",
      "[2023-12-17T22:42:58.529255+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:42:58.531392+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:42:58.533076+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:42:58.535101+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:42:58.538817+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:42:58.540528+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:42:58.542228+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_0__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 0 accuracy:  0.9252747252747253\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220292 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00220292 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00220292\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.00251627230906622\n",
      "Boosting iter: 2 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 42/20\n",
      "random state: 41\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220292 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00220292 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00220292\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00220292 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00220292 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00220292 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739\n",
      " 0.00219739 0.00219739 0.00219739 0.00219739 0.00219739]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 253, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 232, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 293 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True, False,  True, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False,  True, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([215, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                   | 1349/2000 [02:53<01:23,  7.77it/s]\n",
      "[2023-12-17T22:45:58.198785+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:45:58.200773+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:45:58.201976+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:45:58.203438+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:45:58.206091+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:45:58.207638+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:45:58.208852+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_1__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 1 accuracy:  0.8879120879120879\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220241 0.00219688 0.00219688 0.00220698 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00220241\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00220143 0.00219688 0.00220241 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00220241 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00220698\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00220698 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00220241 0.00220241 0.00220143\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00220143\n",
      " 0.00220698 0.00220143 0.00219688 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241\n",
      " 0.00219688 0.00219688 0.00220241 0.00220143 0.00219688 0.00220241\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00220143 0.00220143\n",
      " 0.00219688 0.00220143 0.00219688 0.00220698 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00220241 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002069523106334788\n",
      "Boosting iter: 3 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 43/20\n",
      "random state: 42\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220241 0.00219688 0.00219688 0.00220698 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00220241\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00220143 0.00219688 0.00220241 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00220241 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00220698\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00220698 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00220241 0.00220241 0.00220143\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00220143\n",
      " 0.00220698 0.00220143 0.00219688 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688 0.00220143\n",
      " 0.00219688 0.00219688 0.00220241 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00220241 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241\n",
      " 0.00219688 0.00219688 0.00220241 0.00220143 0.00219688 0.00220241\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00220143 0.00220143\n",
      " 0.00219688 0.00220143 0.00219688 0.00220698 0.00220143 0.00219688\n",
      " 0.00219688 0.00219688 0.00220143 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00220143 0.00220241 0.00219688 0.00220143 0.00219688\n",
      " 0.00219688 0.00220143 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00220241 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00220241 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00220143 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688\n",
      " 0.00219688 0.00219688 0.00219688 0.00219688 0.00219688]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 152, 397, 449,  70,  85,  97, 181,\n",
      "         83, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 232, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 293 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  91   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 158  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 123  59  25 137\n",
      " 119 207 310 316 129 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True,  True, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True, False,  True, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([215, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████████████████▌                                                                                                                                  | 349/2000 [00:43<03:25,  8.04it/s]\n",
      "[2023-12-17T22:46:47.725734+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:46:47.727856+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:46:47.729561+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:46:47.731698+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:46:47.735297+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:46:47.737015+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:46:47.738649+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_2__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 2 accuracy:  0.9296703296703297\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220201 0.00219648 0.00219648 0.00220657 0.00219648 0.00220215\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220215\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00219648\n",
      " 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220201 0.00220215 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00219648 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220215 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.0022077  0.00219648\n",
      " 0.00219648 0.00219648 0.00220672 0.00220103 0.00219648 0.00220201\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201 0.00219648\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220201 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220201 0.00220103 0.00219648 0.00220201 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.0022077  0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220215 0.00220201 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00220103 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00221228\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220201 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00221228 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.0022077  0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00220201 0.00220201 0.00220103\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00219648 0.00220672 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00220103 0.00219648 0.00219648 0.00220672\n",
      " 0.00220657 0.00220103 0.00219648 0.00219648 0.00220672 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.0022077  0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220215 0.00219648 0.00220215 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.0022077  0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220201 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201\n",
      " 0.00219648 0.00219648 0.0022077  0.00220103 0.00219648 0.00220201\n",
      " 0.0022077  0.00219648 0.00219648 0.00219648 0.00220103 0.00220103\n",
      " 0.00219648 0.00220103 0.00219648 0.00220657 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648 0.00220215\n",
      " 0.00219648 0.00220103 0.0022077  0.00219648 0.00220103 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220215\n",
      " 0.00220201 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002580824186467436\n",
      "Boosting iter: 4 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 44/20\n",
      "random state: 43\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220201 0.00219648 0.00219648 0.00220657 0.00219648 0.00220215\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220215\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00219648\n",
      " 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220201 0.00220215 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00219648 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220215 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.0022077  0.00219648\n",
      " 0.00219648 0.00219648 0.00220672 0.00220103 0.00219648 0.00220201\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201 0.00219648\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220201 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220201 0.00220103 0.00219648 0.00220201 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.0022077  0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220215 0.00220201 0.00219648\n",
      " 0.00219648 0.00220215 0.00219648 0.00220103 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00221228\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220201 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00221228 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.0022077  0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00220201 0.00220201 0.00220103\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00220103 0.00219648 0.00219648 0.00219648\n",
      " 0.00220215 0.00219648 0.00219648 0.00219648 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00219648 0.00220672 0.00219648 0.00219648\n",
      " 0.00219648 0.00220215 0.00220103 0.00219648 0.00219648 0.00220672\n",
      " 0.00220657 0.00220103 0.00219648 0.00219648 0.00220672 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648 0.00220103\n",
      " 0.00219648 0.00219648 0.00220201 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.0022077  0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00220215 0.00219648 0.00220215 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.0022077  0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00220201 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201\n",
      " 0.00219648 0.00219648 0.0022077  0.00220103 0.00219648 0.00220201\n",
      " 0.0022077  0.00219648 0.00219648 0.00219648 0.00220103 0.00220103\n",
      " 0.00219648 0.00220103 0.00219648 0.00220657 0.00220103 0.00219648\n",
      " 0.00219648 0.00219648 0.00220103 0.00220103 0.00219648 0.00220215\n",
      " 0.00219648 0.00220103 0.0022077  0.00219648 0.00220103 0.00219648\n",
      " 0.00219648 0.00220103 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00220215\n",
      " 0.00220201 0.00219648 0.00220215 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00220201 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00220103 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648\n",
      " 0.00219648 0.00219648 0.00219648 0.00219648 0.00219648]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 152, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 293 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 158  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 129 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True,  True, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([215, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 1149/2000 [02:29<01:50,  7.71it/s]\n",
      "[2023-12-17T22:49:22.914155+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:49:22.916304+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:49:22.918072+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:49:22.920185+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:49:22.923858+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:49:22.925676+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:49:22.927323+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_3__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 3 accuracy:  0.9098901098901099\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220155 0.00219602 0.00219602 0.00220611 0.00219602 0.0022017\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220679\n",
      " 0.0022011  0.00219602 0.00220665 0.00219602 0.00219602 0.00219602\n",
      " 0.00220679 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220155 0.00220679 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220679 0.00219602 0.0022011  0.00220566 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.0022017  0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220665 0.00219602 0.00220724 0.00219602\n",
      " 0.00219602 0.00219602 0.00221136 0.00220057 0.00219602 0.00220155\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00220155 0.00219602\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220155 0.00220057 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220155 0.00220057 0.00219602 0.00220665 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00221235 0.00220566 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.0022011  0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.0022011  0.00219602 0.0022017  0.00220155 0.00219602\n",
      " 0.00219602 0.0022017  0.00219602 0.00220057 0.00219602 0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00219602 0.00219602 0.00221181\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220155 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00221693 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00220057 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00221235 0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00220155 0.00220665 0.00220057\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602\n",
      " 0.0022011  0.0022017  0.00220566 0.00219602 0.00219602 0.00219602\n",
      " 0.0022017  0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00219602 0.00219602 0.00219602 0.00221136 0.00219602 0.00219602\n",
      " 0.00219602 0.00220679 0.00220057 0.00219602 0.00219602 0.00221136\n",
      " 0.00220611 0.00220057 0.00219602 0.00219602 0.00221136 0.00219602\n",
      " 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00219602 0.0022011  0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00219602 0.0022011  0.00219602\n",
      " 0.00219602 0.00219602 0.00220566 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00220724 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022017  0.00219602 0.00220679 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00221235 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220155 0.00219602 0.00220566 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220155\n",
      " 0.00219602 0.00219602 0.00220724 0.00220057 0.00219602 0.00220665\n",
      " 0.00220724 0.00219602 0.00219602 0.00219602 0.00220057 0.00220566\n",
      " 0.00219602 0.00220566 0.00219602 0.00220611 0.00220057 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00220057 0.00219602 0.00220679\n",
      " 0.00219602 0.00220057 0.00220724 0.00219602 0.00220057 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.0022017\n",
      " 0.00220155 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00220155 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220566 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.0022011\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0023105879357532355\n",
      "Boosting iter: 5 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 45/20\n",
      "random state: 44\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220155 0.00219602 0.00219602 0.00220611 0.00219602 0.0022017\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220679\n",
      " 0.0022011  0.00219602 0.00220665 0.00219602 0.00219602 0.00219602\n",
      " 0.00220679 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220155 0.00220679 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220679 0.00219602 0.0022011  0.00220566 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.0022017  0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220665 0.00219602 0.00220724 0.00219602\n",
      " 0.00219602 0.00219602 0.00221136 0.00220057 0.00219602 0.00220155\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00220155 0.00219602\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220155 0.00220057 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220155 0.00220057 0.00219602 0.00220665 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00221235 0.00220566 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.0022011  0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.0022011  0.00219602 0.0022017  0.00220155 0.00219602\n",
      " 0.00219602 0.0022017  0.00219602 0.00220057 0.00219602 0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00219602 0.00219602 0.00221181\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220155 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00221693 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00220057 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00221235 0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00220155 0.00220665 0.00220057\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602\n",
      " 0.0022011  0.0022017  0.00220566 0.00219602 0.00219602 0.00219602\n",
      " 0.0022017  0.00219602 0.00219602 0.00219602 0.00219602 0.00220057\n",
      " 0.00219602 0.00219602 0.00219602 0.00221136 0.00219602 0.00219602\n",
      " 0.00219602 0.00220679 0.00220057 0.00219602 0.00219602 0.00221136\n",
      " 0.00220611 0.00220057 0.00219602 0.00219602 0.00221136 0.00219602\n",
      " 0.00219602 0.0022011  0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00219602 0.0022011  0.00220057\n",
      " 0.00219602 0.00219602 0.00220155 0.00219602 0.0022011  0.00219602\n",
      " 0.00219602 0.00219602 0.00220566 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00220724 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.0022017  0.00219602 0.00220679 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220057 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00221235 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00220155 0.00219602 0.00220566 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00220155\n",
      " 0.00219602 0.00219602 0.00220724 0.00220057 0.00219602 0.00220665\n",
      " 0.00220724 0.00219602 0.00219602 0.00219602 0.00220057 0.00220566\n",
      " 0.00219602 0.00220566 0.00219602 0.00220611 0.00220057 0.00219602\n",
      " 0.00219602 0.00219602 0.00220057 0.00220057 0.00219602 0.00220679\n",
      " 0.00219602 0.00220057 0.00220724 0.00219602 0.00220057 0.00219602\n",
      " 0.00219602 0.00220057 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.0022017\n",
      " 0.00220155 0.00219602 0.0022017  0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00220155 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00220566 0.00219602 0.00219602\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602 0.0022011\n",
      " 0.00219602 0.00219602 0.00219602 0.00219602 0.00219602]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 293 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 129 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([214, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████████████████▌                                                                                                                                  | 349/2000 [00:39<03:05,  8.89it/s]\n",
      "[2023-12-17T22:50:08.249334+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:50:08.251502+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:50:08.253204+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:50:08.255316+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:50:08.259053+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:50:08.260797+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:50:08.262524+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_4__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 4 accuracy:  0.9208791208791208\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220112 0.00219559 0.00219559 0.00220568 0.00219559 0.00220127\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00221178\n",
      " 0.00220067 0.00219559 0.00220622 0.00219559 0.00219559 0.00219559\n",
      " 0.00221178 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220112 0.00220636 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220636 0.00219559 0.00220067 0.00221065 0.00220099\n",
      " 0.00219559 0.00219559 0.00219559 0.00220127 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220622 0.00219559 0.00220681 0.00219559\n",
      " 0.00219559 0.00219559 0.00221093 0.00220014 0.00219559 0.00220112\n",
      " 0.00220099 0.00219559 0.00220067 0.00219559 0.00220112 0.00219559\n",
      " 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220112 0.00220014 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220112 0.00220014 0.00219559 0.00221164 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220608 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220555 0.00219559 0.00221192 0.00220523 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220067 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220067 0.00219559 0.00220127 0.00220653 0.00219559\n",
      " 0.00219559 0.00220127 0.00219559 0.00220014 0.00219559 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00220099 0.00219559 0.00221682\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220112 0.00219559 0.00219559 0.00220067 0.00219559 0.00219559\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00220099\n",
      " 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00222194 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00220014 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00221192 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00220112 0.00221164 0.00220014\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220555 0.00219559 0.00220099 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220067 0.00219559 0.00220099 0.00219559\n",
      " 0.00220608 0.00220127 0.00220523 0.00219559 0.00220099 0.00219559\n",
      " 0.00220127 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00219559 0.00219559 0.00219559 0.00221093 0.00219559 0.00220099\n",
      " 0.00219559 0.00221178 0.00220555 0.00219559 0.00219559 0.00221093\n",
      " 0.00220568 0.00220014 0.00219559 0.00219559 0.00221093 0.00220099\n",
      " 0.00219559 0.00220067 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220014 0.00219559 0.00220067 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00219559 0.00220608 0.00219559\n",
      " 0.00219559 0.00219559 0.00220523 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00220681 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220127 0.00219559 0.00220636 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220099 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00220099 0.00219559\n",
      " 0.00221192 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220112 0.00219559 0.00220523 0.00219559 0.00220099\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220112\n",
      " 0.00219559 0.00219559 0.00220681 0.00220014 0.00219559 0.00220622\n",
      " 0.00220681 0.00219559 0.00219559 0.00219559 0.00220014 0.00220523\n",
      " 0.00219559 0.00220523 0.00219559 0.0022111  0.00220014 0.00219559\n",
      " 0.00219559 0.00219559 0.00220555 0.00220014 0.00219559 0.00220636\n",
      " 0.00219559 0.00220014 0.00220681 0.00219559 0.00220014 0.00220099\n",
      " 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220127\n",
      " 0.00220112 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220099 0.00219559 0.00219559 0.00220112 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220523 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220608\n",
      " 0.00219559 0.00219559 0.00220099 0.00219559 0.00219559]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0024531187774958023\n",
      "Boosting iter: 6 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 46/20\n",
      "random state: 45\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220112 0.00219559 0.00219559 0.00220568 0.00219559 0.00220127\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00221178\n",
      " 0.00220067 0.00219559 0.00220622 0.00219559 0.00219559 0.00219559\n",
      " 0.00221178 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220112 0.00220636 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220636 0.00219559 0.00220067 0.00221065 0.00220099\n",
      " 0.00219559 0.00219559 0.00219559 0.00220127 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220622 0.00219559 0.00220681 0.00219559\n",
      " 0.00219559 0.00219559 0.00221093 0.00220014 0.00219559 0.00220112\n",
      " 0.00220099 0.00219559 0.00220067 0.00219559 0.00220112 0.00219559\n",
      " 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220112 0.00220014 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220112 0.00220014 0.00219559 0.00221164 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220608 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220555 0.00219559 0.00221192 0.00220523 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220067 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220067 0.00219559 0.00220127 0.00220653 0.00219559\n",
      " 0.00219559 0.00220127 0.00219559 0.00220014 0.00219559 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00220099 0.00219559 0.00221682\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220112 0.00219559 0.00219559 0.00220067 0.00219559 0.00219559\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00220099\n",
      " 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00222194 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00220014 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00221192 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00220112 0.00221164 0.00220014\n",
      " 0.00220099 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00220555 0.00219559 0.00220099 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220067 0.00219559 0.00220099 0.00219559\n",
      " 0.00220608 0.00220127 0.00220523 0.00219559 0.00220099 0.00219559\n",
      " 0.00220127 0.00219559 0.00219559 0.00219559 0.00219559 0.00220014\n",
      " 0.00219559 0.00219559 0.00219559 0.00221093 0.00219559 0.00220099\n",
      " 0.00219559 0.00221178 0.00220555 0.00219559 0.00219559 0.00221093\n",
      " 0.00220568 0.00220014 0.00219559 0.00219559 0.00221093 0.00220099\n",
      " 0.00219559 0.00220067 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220014 0.00219559 0.00220067 0.00220014\n",
      " 0.00219559 0.00219559 0.00220112 0.00219559 0.00220608 0.00219559\n",
      " 0.00219559 0.00219559 0.00220523 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00220681 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00220127 0.00219559 0.00220636 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220099 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220014 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00220099 0.00219559\n",
      " 0.00221192 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220112 0.00219559 0.00220523 0.00219559 0.00220099\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220112\n",
      " 0.00219559 0.00219559 0.00220681 0.00220014 0.00219559 0.00220622\n",
      " 0.00220681 0.00219559 0.00219559 0.00219559 0.00220014 0.00220523\n",
      " 0.00219559 0.00220523 0.00219559 0.0022111  0.00220014 0.00219559\n",
      " 0.00219559 0.00219559 0.00220555 0.00220014 0.00219559 0.00220636\n",
      " 0.00219559 0.00220014 0.00220681 0.00219559 0.00220014 0.00220099\n",
      " 0.00219559 0.00220014 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220127\n",
      " 0.00220112 0.00219559 0.00220127 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00220099 0.00219559 0.00219559 0.00220112 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00220523 0.00219559 0.00219559\n",
      " 0.00219559 0.00219559 0.00219559 0.00219559 0.00219559 0.00220608\n",
      " 0.00219559 0.00219559 0.00220099 0.00219559 0.00219559]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 152, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 293 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 158  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 123  59  25 137\n",
      " 119 207 310 316 129 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True,  True, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([215, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                           | 1249/2000 [02:46<01:39,  7.52it/s]\n",
      "[2023-12-17T22:53:00.518409+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:53:00.520531+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:53:00.522264+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:53:00.524314+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:53:00.528023+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:53:00.529752+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:53:00.531456+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_5__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 5 accuracy:  0.9032967032967033\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220557 0.00219512 0.00219512 0.00220521 0.00219512 0.00220079\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.0022113\n",
      " 0.00220511 0.00219512 0.00221067 0.00219512 0.00219512 0.00219512\n",
      " 0.0022113  0.00220002 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00220079 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220571 0.00219512 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00220065 0.00220588 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00221081 0.00219512 0.00220511 0.00221511 0.00220051\n",
      " 0.00219512 0.00219512 0.00219512 0.00220079 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00221067 0.00219512 0.00220634 0.00219512\n",
      " 0.00219512 0.00220002 0.00221045 0.00219967 0.00219512 0.00220065\n",
      " 0.00220543 0.00219512 0.0022002  0.00219512 0.00220065 0.00219512\n",
      " 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220065 0.00219967 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220557 0.00220458 0.00219512 0.0022161  0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219967\n",
      " 0.00219967 0.00219512 0.00219512 0.00219512 0.00220002 0.00219512\n",
      " 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.0022056  0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220507 0.00219512 0.00221144 0.00220968 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.0022002  0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220511 0.00219512 0.00220079 0.00220605 0.00219512\n",
      " 0.00219512 0.00220079 0.00219512 0.00219967 0.00219512 0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00220051 0.00219512 0.00221634\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220051 0.00219512 0.00220002 0.00219512 0.00219512 0.00219512\n",
      " 0.00220065 0.00219512 0.00219512 0.0022002  0.00219512 0.00219512\n",
      " 0.00220543 0.00219512 0.00219512 0.00219512 0.00219512 0.00220051\n",
      " 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219967\n",
      " 0.00222643 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220458 0.00219967 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00221144 0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00220065 0.0022161  0.00219967\n",
      " 0.00220543 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220507 0.00219512 0.00220051 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.0022002  0.00219512 0.00220051 0.00219512\n",
      " 0.0022056  0.00220571 0.00220968 0.00219512 0.00220051 0.00219512\n",
      " 0.00220571 0.00219512 0.00219512 0.00219512 0.00219512 0.00220458\n",
      " 0.00219512 0.00219512 0.00219512 0.00221539 0.00219512 0.00220051\n",
      " 0.00220002 0.00221624 0.00220507 0.00219512 0.00219512 0.00221539\n",
      " 0.00220521 0.00219967 0.00219512 0.00219512 0.00221045 0.00220051\n",
      " 0.00219512 0.0022002  0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219967 0.00219512 0.0022002  0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00219512 0.0022056  0.00219512\n",
      " 0.00219512 0.00219512 0.00220475 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00220634 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00220571 0.00219512 0.00221081 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220051 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00220051 0.00219512\n",
      " 0.00221144 0.00219512 0.00219512 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00220065 0.00219512 0.00220475 0.00219512 0.00220051\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00220065\n",
      " 0.00219512 0.00219512 0.00221127 0.00219967 0.00219512 0.00220574\n",
      " 0.00221127 0.00219512 0.00219512 0.00219512 0.00219967 0.00220475\n",
      " 0.00219512 0.00220475 0.00219512 0.00221062 0.00219967 0.00219512\n",
      " 0.00219512 0.00219512 0.00221    0.00219967 0.00219512 0.00220588\n",
      " 0.00219512 0.00219967 0.00220634 0.00219512 0.00219967 0.00220051\n",
      " 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00220079\n",
      " 0.00220065 0.00219512 0.00220079 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220051 0.00219512 0.00219512 0.00220065 0.00220002\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220968 0.00220002 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00221053\n",
      " 0.00219512 0.00219512 0.00220051 0.00219512 0.00219512]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0022319271049430866\n",
      "Boosting iter: 7 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 47/20\n",
      "random state: 46\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220557 0.00219512 0.00219512 0.00220521 0.00219512 0.00220079\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.0022113\n",
      " 0.00220511 0.00219512 0.00221067 0.00219512 0.00219512 0.00219512\n",
      " 0.0022113  0.00220002 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00220079 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220571 0.00219512 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00220065 0.00220588 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00221081 0.00219512 0.00220511 0.00221511 0.00220051\n",
      " 0.00219512 0.00219512 0.00219512 0.00220079 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00221067 0.00219512 0.00220634 0.00219512\n",
      " 0.00219512 0.00220002 0.00221045 0.00219967 0.00219512 0.00220065\n",
      " 0.00220543 0.00219512 0.0022002  0.00219512 0.00220065 0.00219512\n",
      " 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220065 0.00219967 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220557 0.00220458 0.00219512 0.0022161  0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219967\n",
      " 0.00219967 0.00219512 0.00219512 0.00219512 0.00220002 0.00219512\n",
      " 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.0022056  0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220507 0.00219512 0.00221144 0.00220968 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.0022002  0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220511 0.00219512 0.00220079 0.00220605 0.00219512\n",
      " 0.00219512 0.00220079 0.00219512 0.00219967 0.00219512 0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00220051 0.00219512 0.00221634\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220051 0.00219512 0.00220002 0.00219512 0.00219512 0.00219512\n",
      " 0.00220065 0.00219512 0.00219512 0.0022002  0.00219512 0.00219512\n",
      " 0.00220543 0.00219512 0.00219512 0.00219512 0.00219512 0.00220051\n",
      " 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219967\n",
      " 0.00222643 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220458 0.00219967 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00221144 0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00220065 0.0022161  0.00219967\n",
      " 0.00220543 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00220507 0.00219512 0.00220051 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.0022002  0.00219512 0.00220051 0.00219512\n",
      " 0.0022056  0.00220571 0.00220968 0.00219512 0.00220051 0.00219512\n",
      " 0.00220571 0.00219512 0.00219512 0.00219512 0.00219512 0.00220458\n",
      " 0.00219512 0.00219512 0.00219512 0.00221539 0.00219512 0.00220051\n",
      " 0.00220002 0.00221624 0.00220507 0.00219512 0.00219512 0.00221539\n",
      " 0.00220521 0.00219967 0.00219512 0.00219512 0.00221045 0.00220051\n",
      " 0.00219512 0.0022002  0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219967 0.00219512 0.0022002  0.00219967\n",
      " 0.00219512 0.00219512 0.00220065 0.00219512 0.0022056  0.00219512\n",
      " 0.00219512 0.00219512 0.00220475 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00220634 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00220571 0.00219512 0.00221081 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220051 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219967 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00220051 0.00219512\n",
      " 0.00221144 0.00219512 0.00219512 0.00219512 0.00219512 0.00220002\n",
      " 0.00219512 0.00220065 0.00219512 0.00220475 0.00219512 0.00220051\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00220065\n",
      " 0.00219512 0.00219512 0.00221127 0.00219967 0.00219512 0.00220574\n",
      " 0.00221127 0.00219512 0.00219512 0.00219512 0.00219967 0.00220475\n",
      " 0.00219512 0.00220475 0.00219512 0.00221062 0.00219967 0.00219512\n",
      " 0.00219512 0.00219512 0.00221    0.00219967 0.00219512 0.00220588\n",
      " 0.00219512 0.00219967 0.00220634 0.00219512 0.00219967 0.00220051\n",
      " 0.00219512 0.00219967 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00220079\n",
      " 0.00220065 0.00219512 0.00220079 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00220051 0.00219512 0.00219512 0.00220065 0.00220002\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00220968 0.00220002 0.00219512\n",
      " 0.00219512 0.00219512 0.00219512 0.00219512 0.00219512 0.00221053\n",
      " 0.00219512 0.00219512 0.00220051 0.00219512 0.00219512]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  67 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([214, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████        | 1899/2000 [04:07<00:13,  7.67it/s]\n",
      "[2023-12-17T22:57:14.255692+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:57:14.257830+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:57:14.259563+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:57:14.261600+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:57:14.265307+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:57:14.267061+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:57:14.268732+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_6__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 6 accuracy:  0.8967032967032967\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220507 0.00219463 0.00219463 0.00220471 0.00219463 0.0022003\n",
      " 0.00219463 0.00219937 0.00219463 0.00219463 0.00219463 0.0022108\n",
      " 0.00220462 0.00219463 0.00221017 0.00219463 0.00219463 0.00219463\n",
      " 0.0022108  0.00219953 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.0022003  0.00219463 0.00219463 0.00219937\n",
      " 0.00219463 0.00220521 0.00219463 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00220016 0.00221015 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00221032 0.00219463 0.00220938 0.00221461 0.00220002\n",
      " 0.00219463 0.00219463 0.00219463 0.00220505 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00221495 0.00219463 0.00220584 0.00219463\n",
      " 0.00219463 0.00219953 0.00220996 0.00219917 0.00219463 0.00220016\n",
      " 0.0022097  0.00219463 0.0021997  0.00219463 0.00220016 0.00219463\n",
      " 0.00219917 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220016 0.00219917 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220507 0.00220885 0.00219463 0.0022156  0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219917\n",
      " 0.00220392 0.00219463 0.00219463 0.00219463 0.00219953 0.00219463\n",
      " 0.00219463 0.00219463 0.00220392 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219937 0.00220987 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220457 0.00219463 0.00221572 0.00221396 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.0021997  0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220462 0.00219463 0.0022003  0.00220556 0.00219463\n",
      " 0.00219463 0.0022003  0.00219463 0.00220392 0.00219463 0.00220392\n",
      " 0.00219463 0.00219463 0.00220016 0.00220002 0.00219463 0.00222063\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220477 0.00219463 0.00219953 0.00219463 0.00219463 0.00219463\n",
      " 0.00220016 0.00219463 0.00219463 0.0021997  0.00219937 0.00219463\n",
      " 0.00220493 0.00219463 0.00219463 0.00219463 0.00219463 0.00220002\n",
      " 0.00219463 0.00220392 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219917\n",
      " 0.00223074 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00220885 0.00220392 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00221094 0.00220392\n",
      " 0.00219463 0.00219463 0.00220016 0.00220016 0.0022156  0.00219917\n",
      " 0.00220493 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220934 0.00219463 0.00220002 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.0021997  0.00219463 0.00220002 0.00219463\n",
      " 0.00220511 0.00220521 0.00220919 0.00219463 0.00220002 0.00219463\n",
      " 0.00220521 0.00219463 0.00219463 0.00219463 0.00219463 0.00220885\n",
      " 0.00219463 0.00219463 0.00219463 0.00221968 0.00219463 0.00220002\n",
      " 0.00219953 0.00221574 0.00220934 0.00219463 0.00219463 0.00221489\n",
      " 0.00220471 0.00219917 0.00219463 0.00219463 0.00221473 0.00220002\n",
      " 0.00219463 0.0021997  0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00220392 0.00219463 0.00220446 0.00220392\n",
      " 0.00219463 0.00219463 0.00220491 0.00219463 0.00220511 0.00219463\n",
      " 0.00219463 0.00219463 0.00220426 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00220584 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00220521 0.00219463 0.00221032 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00220002 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00220002 0.00219463\n",
      " 0.00221572 0.00219463 0.00219463 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00220491 0.00219463 0.00220902 0.00219463 0.00220002\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00220016\n",
      " 0.00219463 0.00219463 0.00221077 0.00220392 0.00219463 0.00221001\n",
      " 0.00221077 0.00219937 0.00219463 0.00219463 0.00219917 0.00220902\n",
      " 0.00219463 0.00220902 0.00219463 0.0022149  0.00219917 0.00219463\n",
      " 0.00219463 0.00219463 0.00221427 0.00219917 0.00219463 0.00220539\n",
      " 0.00219463 0.00219917 0.00220584 0.00219463 0.00220392 0.00220477\n",
      " 0.00219463 0.00219917 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.0022003\n",
      " 0.00220016 0.00219463 0.00220505 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220002 0.00219463 0.00219463 0.00220016 0.00219953\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00221396 0.00219953 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00221003\n",
      " 0.00219463 0.00219463 0.00220002 0.00219463 0.00219463]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0021580214308772787\n",
      "Boosting iter: 8 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 48/20\n",
      "random state: 47\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220507 0.00219463 0.00219463 0.00220471 0.00219463 0.0022003\n",
      " 0.00219463 0.00219937 0.00219463 0.00219463 0.00219463 0.0022108\n",
      " 0.00220462 0.00219463 0.00221017 0.00219463 0.00219463 0.00219463\n",
      " 0.0022108  0.00219953 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.0022003  0.00219463 0.00219463 0.00219937\n",
      " 0.00219463 0.00220521 0.00219463 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00220016 0.00221015 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00221032 0.00219463 0.00220938 0.00221461 0.00220002\n",
      " 0.00219463 0.00219463 0.00219463 0.00220505 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00221495 0.00219463 0.00220584 0.00219463\n",
      " 0.00219463 0.00219953 0.00220996 0.00219917 0.00219463 0.00220016\n",
      " 0.0022097  0.00219463 0.0021997  0.00219463 0.00220016 0.00219463\n",
      " 0.00219917 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220016 0.00219917 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220507 0.00220885 0.00219463 0.0022156  0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219917\n",
      " 0.00220392 0.00219463 0.00219463 0.00219463 0.00219953 0.00219463\n",
      " 0.00219463 0.00219463 0.00220392 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219937 0.00220987 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220457 0.00219463 0.00221572 0.00221396 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.0021997  0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220462 0.00219463 0.0022003  0.00220556 0.00219463\n",
      " 0.00219463 0.0022003  0.00219463 0.00220392 0.00219463 0.00220392\n",
      " 0.00219463 0.00219463 0.00220016 0.00220002 0.00219463 0.00222063\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220477 0.00219463 0.00219953 0.00219463 0.00219463 0.00219463\n",
      " 0.00220016 0.00219463 0.00219463 0.0021997  0.00219937 0.00219463\n",
      " 0.00220493 0.00219463 0.00219463 0.00219463 0.00219463 0.00220002\n",
      " 0.00219463 0.00220392 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219917\n",
      " 0.00223074 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00220885 0.00220392 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00221094 0.00220392\n",
      " 0.00219463 0.00219463 0.00220016 0.00220016 0.0022156  0.00219917\n",
      " 0.00220493 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00220934 0.00219463 0.00220002 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.0021997  0.00219463 0.00220002 0.00219463\n",
      " 0.00220511 0.00220521 0.00220919 0.00219463 0.00220002 0.00219463\n",
      " 0.00220521 0.00219463 0.00219463 0.00219463 0.00219463 0.00220885\n",
      " 0.00219463 0.00219463 0.00219463 0.00221968 0.00219463 0.00220002\n",
      " 0.00219953 0.00221574 0.00220934 0.00219463 0.00219463 0.00221489\n",
      " 0.00220471 0.00219917 0.00219463 0.00219463 0.00221473 0.00220002\n",
      " 0.00219463 0.0021997  0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00220392 0.00219463 0.00220446 0.00220392\n",
      " 0.00219463 0.00219463 0.00220491 0.00219463 0.00220511 0.00219463\n",
      " 0.00219463 0.00219463 0.00220426 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00220584 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00220521 0.00219463 0.00221032 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00220002 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219917 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00220002 0.00219463\n",
      " 0.00221572 0.00219463 0.00219463 0.00219463 0.00219463 0.00219953\n",
      " 0.00219463 0.00220491 0.00219463 0.00220902 0.00219463 0.00220002\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00220016\n",
      " 0.00219463 0.00219463 0.00221077 0.00220392 0.00219463 0.00221001\n",
      " 0.00221077 0.00219937 0.00219463 0.00219463 0.00219917 0.00220902\n",
      " 0.00219463 0.00220902 0.00219463 0.0022149  0.00219917 0.00219463\n",
      " 0.00219463 0.00219463 0.00221427 0.00219917 0.00219463 0.00220539\n",
      " 0.00219463 0.00219917 0.00220584 0.00219463 0.00220392 0.00220477\n",
      " 0.00219463 0.00219917 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.0022003\n",
      " 0.00220016 0.00219463 0.00220505 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00220002 0.00219463 0.00219463 0.00220016 0.00219953\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00221396 0.00219953 0.00219463\n",
      " 0.00219463 0.00219463 0.00219463 0.00219463 0.00219463 0.00221003\n",
      " 0.00219463 0.00219463 0.00220002 0.00219463 0.00219463]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 158  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([214, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████████████████▉                                                                               | 999/2000 [02:11<02:12,  7.58it/s]\n",
      "[2023-12-17T22:59:32.148939+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:59:32.150489+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T22:59:32.151798+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T22:59:32.153405+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T22:59:32.160951+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:59:32.162415+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T22:59:32.165974+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_7__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 7 accuracy:  0.9428571428571428\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220472 0.00219427 0.00219427 0.00220436 0.00219427 0.00219994\n",
      " 0.00219427 0.00219901 0.00219427 0.00219427 0.00219427 0.00221045\n",
      " 0.00220426 0.00219427 0.00221601 0.00219427 0.00219427 0.00219427\n",
      " 0.00221045 0.00219918 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219994 0.00219427 0.00219427 0.00219901\n",
      " 0.00219427 0.00220486 0.00219427 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.0021998  0.0022098  0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00220996 0.00219427 0.00220903 0.00222046 0.00219966\n",
      " 0.00219427 0.00219427 0.00219427 0.0022047  0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.0022208  0.00219427 0.00220549 0.00219427\n",
      " 0.00219427 0.00220534 0.0022096  0.00219882 0.00219427 0.0021998\n",
      " 0.00220934 0.00219427 0.00219935 0.00219427 0.0021998  0.00219427\n",
      " 0.00219882 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.0021998  0.00219882 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220472 0.00220849 0.00219427 0.00222145 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219882\n",
      " 0.00220357 0.00219427 0.00219427 0.00219427 0.00219918 0.00219427\n",
      " 0.00219427 0.00219427 0.00220975 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219901 0.00220951 0.00219427 0.00220042 0.00219427\n",
      " 0.00219427 0.00220422 0.00219427 0.00221536 0.0022136  0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219935 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00220426 0.00219427 0.00220611 0.00220521 0.00219427\n",
      " 0.00219427 0.00219994 0.00219427 0.00220357 0.00219427 0.00220357\n",
      " 0.00219427 0.00219427 0.00220597 0.00220583 0.00219427 0.00222649\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220442 0.00219427 0.00219918 0.00219427 0.00219427 0.00219427\n",
      " 0.0021998  0.00219427 0.00219427 0.00219935 0.00219901 0.00219427\n",
      " 0.00220458 0.00219427 0.00219427 0.00219427 0.00219427 0.00220583\n",
      " 0.00219427 0.00220357 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219882\n",
      " 0.00223663 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00220849 0.00220357 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00221059 0.00220357\n",
      " 0.00219427 0.00219427 0.0021998  0.0021998  0.00222145 0.00219882\n",
      " 0.00220458 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220898 0.00219427 0.00219966 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219935 0.00219427 0.00219966 0.00219427\n",
      " 0.00220475 0.00221104 0.00220883 0.00219427 0.00219966 0.00219427\n",
      " 0.00220486 0.00219427 0.00219427 0.00219427 0.00219427 0.00220849\n",
      " 0.00219427 0.00219427 0.00220042 0.00221932 0.00219427 0.00220583\n",
      " 0.00219918 0.0022216  0.00220898 0.00219427 0.00219427 0.00221454\n",
      " 0.00220436 0.00219882 0.00219427 0.00219427 0.00221437 0.00219966\n",
      " 0.00219427 0.00219935 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00220357 0.00219427 0.0022041  0.00220357\n",
      " 0.00219427 0.00219427 0.00220455 0.00219427 0.00220475 0.00219427\n",
      " 0.00219427 0.00219427 0.00221008 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00220549 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00221104 0.00219427 0.00221615 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219966 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219966 0.00219427\n",
      " 0.00221536 0.00220042 0.00219427 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00220455 0.00219427 0.00220867 0.00219427 0.00219966\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.0021998\n",
      " 0.00219427 0.00219427 0.00221041 0.00220357 0.00219427 0.00220965\n",
      " 0.00221661 0.00219901 0.00219427 0.00219427 0.00219882 0.00220867\n",
      " 0.00220042 0.00221486 0.00219427 0.00222075 0.00219882 0.00219427\n",
      " 0.00219427 0.00219427 0.00221392 0.00219882 0.00219427 0.00220503\n",
      " 0.00219427 0.00219882 0.00220549 0.00219427 0.00220357 0.00220442\n",
      " 0.00219427 0.00219882 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219994\n",
      " 0.0021998  0.00219427 0.0022047  0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219966 0.00219427 0.00219427 0.0021998  0.00219918\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.0022136  0.00219918 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00220968\n",
      " 0.00219427 0.00219427 0.00219966 0.00219427 0.00219427]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0027989634885745187\n",
      "Boosting iter: 9 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 49/20\n",
      "random state: 48\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220472 0.00219427 0.00219427 0.00220436 0.00219427 0.00219994\n",
      " 0.00219427 0.00219901 0.00219427 0.00219427 0.00219427 0.00221045\n",
      " 0.00220426 0.00219427 0.00221601 0.00219427 0.00219427 0.00219427\n",
      " 0.00221045 0.00219918 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219994 0.00219427 0.00219427 0.00219901\n",
      " 0.00219427 0.00220486 0.00219427 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.0021998  0.0022098  0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00220996 0.00219427 0.00220903 0.00222046 0.00219966\n",
      " 0.00219427 0.00219427 0.00219427 0.0022047  0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.0022208  0.00219427 0.00220549 0.00219427\n",
      " 0.00219427 0.00220534 0.0022096  0.00219882 0.00219427 0.0021998\n",
      " 0.00220934 0.00219427 0.00219935 0.00219427 0.0021998  0.00219427\n",
      " 0.00219882 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.0021998  0.00219882 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220472 0.00220849 0.00219427 0.00222145 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219882\n",
      " 0.00220357 0.00219427 0.00219427 0.00219427 0.00219918 0.00219427\n",
      " 0.00219427 0.00219427 0.00220975 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219901 0.00220951 0.00219427 0.00220042 0.00219427\n",
      " 0.00219427 0.00220422 0.00219427 0.00221536 0.0022136  0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219935 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00220426 0.00219427 0.00220611 0.00220521 0.00219427\n",
      " 0.00219427 0.00219994 0.00219427 0.00220357 0.00219427 0.00220357\n",
      " 0.00219427 0.00219427 0.00220597 0.00220583 0.00219427 0.00222649\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220442 0.00219427 0.00219918 0.00219427 0.00219427 0.00219427\n",
      " 0.0021998  0.00219427 0.00219427 0.00219935 0.00219901 0.00219427\n",
      " 0.00220458 0.00219427 0.00219427 0.00219427 0.00219427 0.00220583\n",
      " 0.00219427 0.00220357 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219882\n",
      " 0.00223663 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00220849 0.00220357 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00221059 0.00220357\n",
      " 0.00219427 0.00219427 0.0021998  0.0021998  0.00222145 0.00219882\n",
      " 0.00220458 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00220898 0.00219427 0.00219966 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219935 0.00219427 0.00219966 0.00219427\n",
      " 0.00220475 0.00221104 0.00220883 0.00219427 0.00219966 0.00219427\n",
      " 0.00220486 0.00219427 0.00219427 0.00219427 0.00219427 0.00220849\n",
      " 0.00219427 0.00219427 0.00220042 0.00221932 0.00219427 0.00220583\n",
      " 0.00219918 0.0022216  0.00220898 0.00219427 0.00219427 0.00221454\n",
      " 0.00220436 0.00219882 0.00219427 0.00219427 0.00221437 0.00219966\n",
      " 0.00219427 0.00219935 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00220357 0.00219427 0.0022041  0.00220357\n",
      " 0.00219427 0.00219427 0.00220455 0.00219427 0.00220475 0.00219427\n",
      " 0.00219427 0.00219427 0.00221008 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00220549 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00221104 0.00219427 0.00221615 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219966 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219882 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219966 0.00219427\n",
      " 0.00221536 0.00220042 0.00219427 0.00219427 0.00219427 0.00219918\n",
      " 0.00219427 0.00220455 0.00219427 0.00220867 0.00219427 0.00219966\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.0021998\n",
      " 0.00219427 0.00219427 0.00221041 0.00220357 0.00219427 0.00220965\n",
      " 0.00221661 0.00219901 0.00219427 0.00219427 0.00219882 0.00220867\n",
      " 0.00220042 0.00221486 0.00219427 0.00222075 0.00219882 0.00219427\n",
      " 0.00219427 0.00219427 0.00221392 0.00219882 0.00219427 0.00220503\n",
      " 0.00219427 0.00219882 0.00220549 0.00219427 0.00220357 0.00220442\n",
      " 0.00219427 0.00219882 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219994\n",
      " 0.0021998  0.00219427 0.0022047  0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219966 0.00219427 0.00219427 0.0021998  0.00219918\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.0022136  0.00219918 0.00219427\n",
      " 0.00219427 0.00219427 0.00219427 0.00219427 0.00219427 0.00220968\n",
      " 0.00219427 0.00219427 0.00219966 0.00219427 0.00219427]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  80,  81,  82,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 152, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 405,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  80, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 158  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 123  59  25 137\n",
      " 119 207 310 316 129 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True,  True, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True,  True, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([215, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                   | 1349/2000 [02:53<01:23,  7.79it/s]\n",
      "[2023-12-17T23:02:31.396108+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:02:31.398272+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:02:31.399996+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T23:02:31.402066+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T23:02:31.405814+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:02:31.407560+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:02:31.409243+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_8__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 8 accuracy:  0.9054945054945055\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220425 0.0021938  0.0021938  0.00220389 0.0021938  0.00219947\n",
      " 0.0021938  0.00219854 0.0021938  0.0021938  0.0021938  0.00221497\n",
      " 0.00220877 0.0021938  0.00222054 0.0021938  0.0021938  0.0021938\n",
      " 0.00221497 0.00219871 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219947 0.0021938  0.0021938  0.00219854\n",
      " 0.0021938  0.00220439 0.0021938  0.0021938  0.0021938  0.00219871\n",
      " 0.0021938  0.0021938  0.0022043  0.00220932 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219876 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00221448 0.0021938  0.00220855 0.00221999 0.00219919\n",
      " 0.0021938  0.0021938  0.0021938  0.00220422 0.0021938  0.00219871\n",
      " 0.00219876 0.0021938  0.00222534 0.0021938  0.00221    0.0021938\n",
      " 0.0021938  0.00220985 0.00220913 0.00219835 0.00219876 0.00219933\n",
      " 0.00220887 0.0021938  0.00219888 0.0021938  0.0022043  0.0021938\n",
      " 0.00219835 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219933 0.00219835 0.0021938  0.0021938  0.00220367\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00220922 0.00220802 0.0021938  0.002226   0.0021938  0.0021938\n",
      " 0.0021938  0.00219876 0.0021938  0.0021938  0.0021938  0.00219835\n",
      " 0.0022031  0.0021938  0.0021938  0.0021938  0.00219871 0.0021938\n",
      " 0.0021938  0.0021938  0.00220927 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219854 0.00220904 0.00219876 0.00219995 0.0021938\n",
      " 0.0021938  0.00220375 0.0021938  0.00221989 0.00221313 0.00219876\n",
      " 0.00219876 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00219888 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00220379 0.0021938  0.00220564 0.00220473 0.0021938\n",
      " 0.0021938  0.00219947 0.0021938  0.0022031  0.0021938  0.0022031\n",
      " 0.0021938  0.0021938  0.00221048 0.00220536 0.0021938  0.00223104\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00220394 0.0021938  0.00219871 0.0021938  0.0021938  0.0021938\n",
      " 0.00219933 0.0021938  0.0021938  0.00219888 0.00219854 0.0021938\n",
      " 0.00220908 0.0021938  0.0021938  0.0021938  0.0021938  0.00220536\n",
      " 0.0021938  0.0022031  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219835\n",
      " 0.0022412  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00220802 0.0022031  0.0021938\n",
      " 0.00219876 0.0021938  0.0021938  0.0021938  0.00221012 0.0022031\n",
      " 0.0021938  0.0021938  0.0022043  0.00219933 0.002226   0.00219835\n",
      " 0.00220411 0.0021938  0.0021938  0.0021938  0.00219876 0.0021938\n",
      " 0.00220851 0.0021938  0.00219919 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219888 0.0021938  0.00220416 0.0021938\n",
      " 0.00220428 0.00221556 0.00220836 0.0021938  0.00219919 0.0021938\n",
      " 0.00220439 0.0021938  0.0021938  0.0021938  0.0021938  0.00220802\n",
      " 0.0021938  0.0021938  0.00220492 0.00221885 0.0021938  0.00221034\n",
      " 0.00220367 0.00222112 0.00220851 0.0021938  0.0021938  0.00221406\n",
      " 0.00220389 0.00219835 0.0021938  0.0021938  0.0022139  0.00219919\n",
      " 0.0021938  0.00219888 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0022031  0.0021938  0.00220363 0.0022031\n",
      " 0.0021938  0.0021938  0.00220408 0.0021938  0.00220428 0.0021938\n",
      " 0.0021938  0.0021938  0.00220961 0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.00220501 0.0021938  0.00219835 0.0021938  0.00219876\n",
      " 0.0021938  0.0021938  0.00221556 0.0021938  0.00222068 0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00220416 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.00219919 0.0021938\n",
      " 0.00221489 0.00219995 0.0021938  0.0021938  0.0021938  0.00219871\n",
      " 0.0021938  0.00220408 0.0021938  0.00220819 0.0021938  0.00219919\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219933\n",
      " 0.0021938  0.0021938  0.00220994 0.0022031  0.0021938  0.00221417\n",
      " 0.00221614 0.00220351 0.0021938  0.0021938  0.00219835 0.00220819\n",
      " 0.00219995 0.00221438 0.0021938  0.00222028 0.00219835 0.0021938\n",
      " 0.0021938  0.0021938  0.00221344 0.00219835 0.0021938  0.00220456\n",
      " 0.0021938  0.00219835 0.00220501 0.0021938  0.0022031  0.00220394\n",
      " 0.0021938  0.00219835 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219947\n",
      " 0.00219933 0.0021938  0.00220422 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219919 0.0021938  0.0021938  0.00219933 0.00219871\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00221813 0.00220367 0.00219876\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0022092\n",
      " 0.0021938  0.0021938  0.00219919 0.0021938  0.0021938 ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002256159830820475\n",
      "Boosting iter: 10 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 50/20\n",
      "random state: 49\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220425 0.0021938  0.0021938  0.00220389 0.0021938  0.00219947\n",
      " 0.0021938  0.00219854 0.0021938  0.0021938  0.0021938  0.00221497\n",
      " 0.00220877 0.0021938  0.00222054 0.0021938  0.0021938  0.0021938\n",
      " 0.00221497 0.00219871 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219947 0.0021938  0.0021938  0.00219854\n",
      " 0.0021938  0.00220439 0.0021938  0.0021938  0.0021938  0.00219871\n",
      " 0.0021938  0.0021938  0.0022043  0.00220932 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219876 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00221448 0.0021938  0.00220855 0.00221999 0.00219919\n",
      " 0.0021938  0.0021938  0.0021938  0.00220422 0.0021938  0.00219871\n",
      " 0.00219876 0.0021938  0.00222534 0.0021938  0.00221    0.0021938\n",
      " 0.0021938  0.00220985 0.00220913 0.00219835 0.00219876 0.00219933\n",
      " 0.00220887 0.0021938  0.00219888 0.0021938  0.0022043  0.0021938\n",
      " 0.00219835 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219933 0.00219835 0.0021938  0.0021938  0.00220367\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00220922 0.00220802 0.0021938  0.002226   0.0021938  0.0021938\n",
      " 0.0021938  0.00219876 0.0021938  0.0021938  0.0021938  0.00219835\n",
      " 0.0022031  0.0021938  0.0021938  0.0021938  0.00219871 0.0021938\n",
      " 0.0021938  0.0021938  0.00220927 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219854 0.00220904 0.00219876 0.00219995 0.0021938\n",
      " 0.0021938  0.00220375 0.0021938  0.00221989 0.00221313 0.00219876\n",
      " 0.00219876 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00219888 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00220379 0.0021938  0.00220564 0.00220473 0.0021938\n",
      " 0.0021938  0.00219947 0.0021938  0.0022031  0.0021938  0.0022031\n",
      " 0.0021938  0.0021938  0.00221048 0.00220536 0.0021938  0.00223104\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.00220394 0.0021938  0.00219871 0.0021938  0.0021938  0.0021938\n",
      " 0.00219933 0.0021938  0.0021938  0.00219888 0.00219854 0.0021938\n",
      " 0.00220908 0.0021938  0.0021938  0.0021938  0.0021938  0.00220536\n",
      " 0.0021938  0.0022031  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219835\n",
      " 0.0022412  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00220802 0.0022031  0.0021938\n",
      " 0.00219876 0.0021938  0.0021938  0.0021938  0.00221012 0.0022031\n",
      " 0.0021938  0.0021938  0.0022043  0.00219933 0.002226   0.00219835\n",
      " 0.00220411 0.0021938  0.0021938  0.0021938  0.00219876 0.0021938\n",
      " 0.00220851 0.0021938  0.00219919 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.00219888 0.0021938  0.00220416 0.0021938\n",
      " 0.00220428 0.00221556 0.00220836 0.0021938  0.00219919 0.0021938\n",
      " 0.00220439 0.0021938  0.0021938  0.0021938  0.0021938  0.00220802\n",
      " 0.0021938  0.0021938  0.00220492 0.00221885 0.0021938  0.00221034\n",
      " 0.00220367 0.00222112 0.00220851 0.0021938  0.0021938  0.00221406\n",
      " 0.00220389 0.00219835 0.0021938  0.0021938  0.0022139  0.00219919\n",
      " 0.0021938  0.00219888 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0022031  0.0021938  0.00220363 0.0022031\n",
      " 0.0021938  0.0021938  0.00220408 0.0021938  0.00220428 0.0021938\n",
      " 0.0021938  0.0021938  0.00220961 0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.00220501 0.0021938  0.00219835 0.0021938  0.00219876\n",
      " 0.0021938  0.0021938  0.00221556 0.0021938  0.00222068 0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00220416 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00219835 0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.00219919 0.0021938\n",
      " 0.00221489 0.00219995 0.0021938  0.0021938  0.0021938  0.00219871\n",
      " 0.0021938  0.00220408 0.0021938  0.00220819 0.0021938  0.00219919\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219933\n",
      " 0.0021938  0.0021938  0.00220994 0.0022031  0.0021938  0.00221417\n",
      " 0.00221614 0.00220351 0.0021938  0.0021938  0.00219835 0.00220819\n",
      " 0.00219995 0.00221438 0.0021938  0.00222028 0.00219835 0.0021938\n",
      " 0.0021938  0.0021938  0.00221344 0.00219835 0.0021938  0.00220456\n",
      " 0.0021938  0.00219835 0.00220501 0.0021938  0.0022031  0.00220394\n",
      " 0.0021938  0.00219835 0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.00219947\n",
      " 0.00219933 0.0021938  0.00220422 0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.00219919 0.0021938  0.0021938  0.00219933 0.00219871\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0021938\n",
      " 0.0021938  0.0021938  0.0021938  0.00221813 0.00220367 0.00219876\n",
      " 0.0021938  0.0021938  0.0021938  0.0021938  0.0021938  0.0022092\n",
      " 0.0021938  0.0021938  0.00219919 0.0021938  0.0021938 ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([212, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████▌                                                                                                                              | 399/2000 [00:49<03:18,  8.06it/s]\n",
      "[2023-12-17T23:03:26.960251+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:03:26.962430+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:03:26.964134+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T23:03:26.966215+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T23:03:26.969857+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:03:26.971585+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:03:26.973267+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_9__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 9 accuracy:  0.9428571428571428\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220389 0.00219345 0.00219345 0.00220353 0.00219345 0.00219912\n",
      " 0.00219345 0.00219819 0.00219345 0.00219345 0.00219345 0.00221461\n",
      " 0.0022146  0.00219345 0.0022264  0.00219345 0.00219345 0.00219345\n",
      " 0.00221461 0.00219835 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219912 0.00219345 0.00219345 0.00220434\n",
      " 0.00219345 0.00220403 0.00219345 0.00219345 0.00219345 0.00219835\n",
      " 0.00219345 0.00219345 0.00221011 0.00220897 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.0021984  0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00221412 0.00219345 0.0022082  0.00221963 0.00219884\n",
      " 0.00219345 0.00219345 0.00219345 0.00220387 0.00219345 0.00219835\n",
      " 0.0021984  0.00219345 0.00223121 0.00219345 0.00220964 0.00219345\n",
      " 0.00219345 0.00220949 0.00220877 0.00219799 0.0021984  0.00219898\n",
      " 0.00220851 0.00219345 0.00219852 0.00219345 0.00220394 0.00219345\n",
      " 0.00219799 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219898 0.00219799 0.00219345 0.00219345 0.00220949\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00220887 0.00220767 0.00219345 0.00223187 0.00219345 0.00219345\n",
      " 0.00219345 0.0021984  0.00219345 0.00219345 0.00219345 0.00219799\n",
      " 0.00220274 0.00219345 0.00219345 0.00219345 0.00219835 0.00219345\n",
      " 0.00219345 0.00219345 0.0022151  0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219819 0.00221487 0.0021984  0.0021996  0.00219345\n",
      " 0.00219345 0.00220339 0.00219345 0.00221954 0.00221277 0.0021984\n",
      " 0.0021984  0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219852 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00220961 0.00219345 0.00220528 0.00220438 0.00219345\n",
      " 0.00219345 0.00219912 0.00219345 0.00220274 0.00219345 0.00220274\n",
      " 0.00219345 0.00219345 0.00221012 0.002205   0.00219345 0.00223693\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00220359 0.00219345 0.00219835 0.00219345 0.00219345 0.00219345\n",
      " 0.00219898 0.00219345 0.00219345 0.00219852 0.00219819 0.00219345\n",
      " 0.00220873 0.00219345 0.00219345 0.00219345 0.00219345 0.002205\n",
      " 0.00219345 0.00220274 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219799\n",
      " 0.00224712 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00221385 0.00220274 0.00219345\n",
      " 0.0021984  0.00219345 0.00219345 0.00219345 0.00220976 0.00220891\n",
      " 0.00219345 0.00219345 0.00220394 0.00219898 0.00222564 0.00219799\n",
      " 0.00220375 0.00219345 0.00219345 0.00219345 0.0021984  0.00219345\n",
      " 0.00220815 0.00219345 0.00219884 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219852 0.00219345 0.0022038  0.00219345\n",
      " 0.00220392 0.0022214  0.002208   0.00219345 0.00219884 0.00219345\n",
      " 0.00220403 0.00219345 0.00219345 0.00219345 0.00219345 0.00220767\n",
      " 0.00219345 0.00219345 0.00220457 0.0022247  0.00219345 0.00220998\n",
      " 0.00220332 0.00222076 0.00220815 0.00219345 0.00219345 0.00221371\n",
      " 0.00220353 0.00219799 0.00219345 0.00219345 0.00221974 0.00219884\n",
      " 0.00219345 0.00219852 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00220891 0.00219345 0.00220327 0.00220274\n",
      " 0.00219345 0.00219345 0.00220373 0.00219345 0.00220392 0.00219345\n",
      " 0.00219345 0.00219345 0.00220925 0.00219799 0.00219345 0.00219345\n",
      " 0.00219345 0.00220466 0.00219345 0.00219799 0.00219345 0.0021984\n",
      " 0.00219345 0.00219345 0.0022214  0.00219345 0.00222033 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00220415 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.0022038  0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219799 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219884 0.00219345\n",
      " 0.00221453 0.0021996  0.00219345 0.00219345 0.00219345 0.00219835\n",
      " 0.00219345 0.00220373 0.00219345 0.00220784 0.00219345 0.00219884\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219898\n",
      " 0.00219345 0.00219345 0.00220959 0.00220274 0.00219345 0.00221381\n",
      " 0.00222198 0.00220315 0.00219345 0.00219345 0.00219799 0.00220784\n",
      " 0.0021996  0.00222023 0.00219345 0.00222614 0.00219799 0.00219345\n",
      " 0.00219345 0.00219345 0.00221309 0.00219799 0.00219345 0.00220421\n",
      " 0.00219345 0.00219799 0.00220466 0.00219345 0.00220891 0.00220359\n",
      " 0.00219345 0.00219799 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219912\n",
      " 0.00219898 0.00219345 0.00220387 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219884 0.00219345 0.00219345 0.00219898 0.00219835\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00222398 0.00220332 0.0021984\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00221503\n",
      " 0.00219345 0.00219345 0.00219884 0.00219345 0.00219345]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0027960283714454385\n",
      "Boosting iter: 11 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 51/20\n",
      "random state: 50\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220389 0.00219345 0.00219345 0.00220353 0.00219345 0.00219912\n",
      " 0.00219345 0.00219819 0.00219345 0.00219345 0.00219345 0.00221461\n",
      " 0.0022146  0.00219345 0.0022264  0.00219345 0.00219345 0.00219345\n",
      " 0.00221461 0.00219835 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219912 0.00219345 0.00219345 0.00220434\n",
      " 0.00219345 0.00220403 0.00219345 0.00219345 0.00219345 0.00219835\n",
      " 0.00219345 0.00219345 0.00221011 0.00220897 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.0021984  0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00221412 0.00219345 0.0022082  0.00221963 0.00219884\n",
      " 0.00219345 0.00219345 0.00219345 0.00220387 0.00219345 0.00219835\n",
      " 0.0021984  0.00219345 0.00223121 0.00219345 0.00220964 0.00219345\n",
      " 0.00219345 0.00220949 0.00220877 0.00219799 0.0021984  0.00219898\n",
      " 0.00220851 0.00219345 0.00219852 0.00219345 0.00220394 0.00219345\n",
      " 0.00219799 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219898 0.00219799 0.00219345 0.00219345 0.00220949\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00220887 0.00220767 0.00219345 0.00223187 0.00219345 0.00219345\n",
      " 0.00219345 0.0021984  0.00219345 0.00219345 0.00219345 0.00219799\n",
      " 0.00220274 0.00219345 0.00219345 0.00219345 0.00219835 0.00219345\n",
      " 0.00219345 0.00219345 0.0022151  0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219819 0.00221487 0.0021984  0.0021996  0.00219345\n",
      " 0.00219345 0.00220339 0.00219345 0.00221954 0.00221277 0.0021984\n",
      " 0.0021984  0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219852 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00220961 0.00219345 0.00220528 0.00220438 0.00219345\n",
      " 0.00219345 0.00219912 0.00219345 0.00220274 0.00219345 0.00220274\n",
      " 0.00219345 0.00219345 0.00221012 0.002205   0.00219345 0.00223693\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00220359 0.00219345 0.00219835 0.00219345 0.00219345 0.00219345\n",
      " 0.00219898 0.00219345 0.00219345 0.00219852 0.00219819 0.00219345\n",
      " 0.00220873 0.00219345 0.00219345 0.00219345 0.00219345 0.002205\n",
      " 0.00219345 0.00220274 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219799\n",
      " 0.00224712 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00221385 0.00220274 0.00219345\n",
      " 0.0021984  0.00219345 0.00219345 0.00219345 0.00220976 0.00220891\n",
      " 0.00219345 0.00219345 0.00220394 0.00219898 0.00222564 0.00219799\n",
      " 0.00220375 0.00219345 0.00219345 0.00219345 0.0021984  0.00219345\n",
      " 0.00220815 0.00219345 0.00219884 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219852 0.00219345 0.0022038  0.00219345\n",
      " 0.00220392 0.0022214  0.002208   0.00219345 0.00219884 0.00219345\n",
      " 0.00220403 0.00219345 0.00219345 0.00219345 0.00219345 0.00220767\n",
      " 0.00219345 0.00219345 0.00220457 0.0022247  0.00219345 0.00220998\n",
      " 0.00220332 0.00222076 0.00220815 0.00219345 0.00219345 0.00221371\n",
      " 0.00220353 0.00219799 0.00219345 0.00219345 0.00221974 0.00219884\n",
      " 0.00219345 0.00219852 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00220891 0.00219345 0.00220327 0.00220274\n",
      " 0.00219345 0.00219345 0.00220373 0.00219345 0.00220392 0.00219345\n",
      " 0.00219345 0.00219345 0.00220925 0.00219799 0.00219345 0.00219345\n",
      " 0.00219345 0.00220466 0.00219345 0.00219799 0.00219345 0.0021984\n",
      " 0.00219345 0.00219345 0.0022214  0.00219345 0.00222033 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00220415 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.0022038  0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219799 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219884 0.00219345\n",
      " 0.00221453 0.0021996  0.00219345 0.00219345 0.00219345 0.00219835\n",
      " 0.00219345 0.00220373 0.00219345 0.00220784 0.00219345 0.00219884\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219898\n",
      " 0.00219345 0.00219345 0.00220959 0.00220274 0.00219345 0.00221381\n",
      " 0.00222198 0.00220315 0.00219345 0.00219345 0.00219799 0.00220784\n",
      " 0.0021996  0.00222023 0.00219345 0.00222614 0.00219799 0.00219345\n",
      " 0.00219345 0.00219345 0.00221309 0.00219799 0.00219345 0.00220421\n",
      " 0.00219345 0.00219799 0.00220466 0.00219345 0.00220891 0.00220359\n",
      " 0.00219345 0.00219799 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219912\n",
      " 0.00219898 0.00219345 0.00220387 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219884 0.00219345 0.00219345 0.00219898 0.00219835\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345\n",
      " 0.00219345 0.00219345 0.00219345 0.00222398 0.00220332 0.0021984\n",
      " 0.00219345 0.00219345 0.00219345 0.00219345 0.00219345 0.00221503\n",
      " 0.00219345 0.00219345 0.00219884 0.00219345 0.00219345]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████████████████████████████████▏                                                                                                  | 749/2000 [01:37<02:42,  7.69it/s]\n",
      "[2023-12-17T23:05:10.390556+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:05:10.392820+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:05:10.394529+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T23:05:10.396557+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T23:05:10.400254+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:05:10.402015+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:05:10.403683+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_10__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 10 accuracy:  0.9142857142857143\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220344 0.002193   0.00219818 0.00220829 0.002193   0.00219867\n",
      " 0.002193   0.00219774 0.002193   0.002193   0.002193   0.00221416\n",
      " 0.00221938 0.002193   0.0022312  0.002193   0.002193   0.002193\n",
      " 0.00221416 0.0021979  0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00219867 0.002193   0.002193   0.00220389\n",
      " 0.002193   0.00220879 0.002193   0.002193   0.002193   0.0021979\n",
      " 0.002193   0.002193   0.00220966 0.00220852 0.002193   0.002193\n",
      " 0.002193   0.002193   0.00219796 0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.0022189  0.002193   0.00220775 0.00221918 0.00219839\n",
      " 0.002193   0.002193   0.002193   0.00220342 0.002193   0.0022031\n",
      " 0.00219796 0.002193   0.00223602 0.002193   0.00221441 0.002193\n",
      " 0.002193   0.00220904 0.00221354 0.00219755 0.00219796 0.00219853\n",
      " 0.00220806 0.002193   0.00219808 0.002193   0.00220349 0.002193\n",
      " 0.00219755 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219853 0.00219755 0.002193   0.002193   0.00220904\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00220842 0.00221243 0.002193   0.00223668 0.002193   0.002193\n",
      " 0.002193   0.00219796 0.002193   0.002193   0.002193   0.00219755\n",
      " 0.00220229 0.002193   0.002193   0.002193   0.0021979  0.002193\n",
      " 0.002193   0.002193   0.00221465 0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219774 0.00221442 0.00219796 0.00219915 0.002193\n",
      " 0.002193   0.00220815 0.002193   0.00221908 0.00221755 0.00219796\n",
      " 0.00219796 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00219808 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.00220916 0.002193   0.00220483 0.00220393 0.002193\n",
      " 0.002193   0.00219867 0.002193   0.00220229 0.002193   0.00220229\n",
      " 0.002193   0.002193   0.00221489 0.00220455 0.002193   0.00224176\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00220314 0.002193   0.0021979  0.002193   0.002193   0.002193\n",
      " 0.00219853 0.002193   0.002193   0.00219808 0.00219774 0.002193\n",
      " 0.00220828 0.002193   0.002193   0.002193   0.002193   0.00220455\n",
      " 0.002193   0.00220229 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219755\n",
      " 0.00225197 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219818\n",
      " 0.002193   0.002193   0.002193   0.0022134  0.00220229 0.002193\n",
      " 0.00219796 0.002193   0.002193   0.002193   0.00221453 0.00220846\n",
      " 0.002193   0.002193   0.00220349 0.00219853 0.00222518 0.00219755\n",
      " 0.0022033  0.002193   0.002193   0.002193   0.00220315 0.002193\n",
      " 0.0022077  0.002193   0.00219839 0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00220327 0.002193   0.00220336 0.002193\n",
      " 0.00220348 0.0022262  0.00220755 0.002193   0.00219839 0.002193\n",
      " 0.00220879 0.002193   0.002193   0.002193   0.002193   0.00221243\n",
      " 0.002193   0.002193   0.00220412 0.0022295  0.002193   0.00220953\n",
      " 0.00220287 0.00222031 0.0022077  0.002193   0.002193   0.00221849\n",
      " 0.00220308 0.00219755 0.002193   0.002193   0.00221929 0.00219839\n",
      " 0.002193   0.00219808 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00220846 0.002193   0.00220283 0.00220229\n",
      " 0.002193   0.002193   0.00220328 0.002193   0.00220348 0.002193\n",
      " 0.002193   0.002193   0.0022088  0.00219755 0.002193   0.002193\n",
      " 0.002193   0.00220421 0.002193   0.00219755 0.002193   0.00219796\n",
      " 0.002193   0.002193   0.00222095 0.002193   0.00222512 0.002193\n",
      " 0.002193   0.002193   0.002193   0.0022037  0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00220336 0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00219755 0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.00220358 0.002193\n",
      " 0.00221931 0.00219915 0.002193   0.002193   0.002193   0.0021979\n",
      " 0.002193   0.00220328 0.002193   0.0022126  0.002193   0.00219839\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219853\n",
      " 0.002193   0.002193   0.00220914 0.0022075  0.002193   0.00221859\n",
      " 0.00222678 0.00220271 0.002193   0.002193   0.00219755 0.00220739\n",
      " 0.00219915 0.00222502 0.002193   0.00223094 0.00219755 0.002193\n",
      " 0.002193   0.002193   0.00221264 0.00219755 0.002193   0.00220896\n",
      " 0.002193   0.00219755 0.00220421 0.002193   0.00220846 0.00220314\n",
      " 0.002193   0.00219755 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219867\n",
      " 0.00219853 0.002193   0.00220342 0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219839 0.002193   0.002193   0.00219853 0.0021979\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00222878 0.00220807 0.00219796\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00221981\n",
      " 0.002193   0.002193   0.00219839 0.002193   0.002193  ]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0023596904453190145\n",
      "Boosting iter: 12 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 52/20\n",
      "random state: 51\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220344 0.002193   0.00219818 0.00220829 0.002193   0.00219867\n",
      " 0.002193   0.00219774 0.002193   0.002193   0.002193   0.00221416\n",
      " 0.00221938 0.002193   0.0022312  0.002193   0.002193   0.002193\n",
      " 0.00221416 0.0021979  0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00219867 0.002193   0.002193   0.00220389\n",
      " 0.002193   0.00220879 0.002193   0.002193   0.002193   0.0021979\n",
      " 0.002193   0.002193   0.00220966 0.00220852 0.002193   0.002193\n",
      " 0.002193   0.002193   0.00219796 0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.0022189  0.002193   0.00220775 0.00221918 0.00219839\n",
      " 0.002193   0.002193   0.002193   0.00220342 0.002193   0.0022031\n",
      " 0.00219796 0.002193   0.00223602 0.002193   0.00221441 0.002193\n",
      " 0.002193   0.00220904 0.00221354 0.00219755 0.00219796 0.00219853\n",
      " 0.00220806 0.002193   0.00219808 0.002193   0.00220349 0.002193\n",
      " 0.00219755 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219853 0.00219755 0.002193   0.002193   0.00220904\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00220842 0.00221243 0.002193   0.00223668 0.002193   0.002193\n",
      " 0.002193   0.00219796 0.002193   0.002193   0.002193   0.00219755\n",
      " 0.00220229 0.002193   0.002193   0.002193   0.0021979  0.002193\n",
      " 0.002193   0.002193   0.00221465 0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219774 0.00221442 0.00219796 0.00219915 0.002193\n",
      " 0.002193   0.00220815 0.002193   0.00221908 0.00221755 0.00219796\n",
      " 0.00219796 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00219808 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.00220916 0.002193   0.00220483 0.00220393 0.002193\n",
      " 0.002193   0.00219867 0.002193   0.00220229 0.002193   0.00220229\n",
      " 0.002193   0.002193   0.00221489 0.00220455 0.002193   0.00224176\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.00220314 0.002193   0.0021979  0.002193   0.002193   0.002193\n",
      " 0.00219853 0.002193   0.002193   0.00219808 0.00219774 0.002193\n",
      " 0.00220828 0.002193   0.002193   0.002193   0.002193   0.00220455\n",
      " 0.002193   0.00220229 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219755\n",
      " 0.00225197 0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219818\n",
      " 0.002193   0.002193   0.002193   0.0022134  0.00220229 0.002193\n",
      " 0.00219796 0.002193   0.002193   0.002193   0.00221453 0.00220846\n",
      " 0.002193   0.002193   0.00220349 0.00219853 0.00222518 0.00219755\n",
      " 0.0022033  0.002193   0.002193   0.002193   0.00220315 0.002193\n",
      " 0.0022077  0.002193   0.00219839 0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00220327 0.002193   0.00220336 0.002193\n",
      " 0.00220348 0.0022262  0.00220755 0.002193   0.00219839 0.002193\n",
      " 0.00220879 0.002193   0.002193   0.002193   0.002193   0.00221243\n",
      " 0.002193   0.002193   0.00220412 0.0022295  0.002193   0.00220953\n",
      " 0.00220287 0.00222031 0.0022077  0.002193   0.002193   0.00221849\n",
      " 0.00220308 0.00219755 0.002193   0.002193   0.00221929 0.00219839\n",
      " 0.002193   0.00219808 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.00220846 0.002193   0.00220283 0.00220229\n",
      " 0.002193   0.002193   0.00220328 0.002193   0.00220348 0.002193\n",
      " 0.002193   0.002193   0.0022088  0.00219755 0.002193   0.002193\n",
      " 0.002193   0.00220421 0.002193   0.00219755 0.002193   0.00219796\n",
      " 0.002193   0.002193   0.00222095 0.002193   0.00222512 0.002193\n",
      " 0.002193   0.002193   0.002193   0.0022037  0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00220336 0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00219755 0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.00220358 0.002193\n",
      " 0.00221931 0.00219915 0.002193   0.002193   0.002193   0.0021979\n",
      " 0.002193   0.00220328 0.002193   0.0022126  0.002193   0.00219839\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219853\n",
      " 0.002193   0.002193   0.00220914 0.0022075  0.002193   0.00221859\n",
      " 0.00222678 0.00220271 0.002193   0.002193   0.00219755 0.00220739\n",
      " 0.00219915 0.00222502 0.002193   0.00223094 0.00219755 0.002193\n",
      " 0.002193   0.002193   0.00221264 0.00219755 0.002193   0.00220896\n",
      " 0.002193   0.00219755 0.00220421 0.002193   0.00220846 0.00220314\n",
      " 0.002193   0.00219755 0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00219867\n",
      " 0.00219853 0.002193   0.00220342 0.002193   0.002193   0.002193\n",
      " 0.002193   0.00219839 0.002193   0.002193   0.00219853 0.0021979\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.002193\n",
      " 0.002193   0.002193   0.002193   0.00222878 0.00220807 0.00219796\n",
      " 0.002193   0.002193   0.002193   0.002193   0.002193   0.00221981\n",
      " 0.002193   0.002193   0.00219839 0.002193   0.002193  ]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  67 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                   | 1349/2000 [02:42<01:18,  8.29it/s]\n",
      "[2023-12-17T23:07:59.207389+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:07:59.209493+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:07:59.211313+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T23:07:59.213518+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T23:07:59.217237+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:07:59.219050+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:07:59.220687+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_11__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 11 accuracy:  0.9340659340659341\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220305 0.00219262 0.0021978  0.0022079  0.00219262 0.00219828\n",
      " 0.00219262 0.00219736 0.00219262 0.00219262 0.00219262 0.00221963\n",
      " 0.00221899 0.00219262 0.00223081 0.00219262 0.00219842 0.00219262\n",
      " 0.00221963 0.00219752 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219828 0.00219262 0.00219262 0.00220934\n",
      " 0.00219262 0.00221425 0.00219262 0.00219262 0.00219262 0.00219752\n",
      " 0.00219262 0.00219262 0.00221512 0.00220813 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219757 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00221851 0.00219262 0.00220736 0.00222466 0.002198\n",
      " 0.00219262 0.00219262 0.00219262 0.00220303 0.00219262 0.00220271\n",
      " 0.00219757 0.00219262 0.00224155 0.00219262 0.00221988 0.00219262\n",
      " 0.00219262 0.0022145  0.00221315 0.00219716 0.00219757 0.00219814\n",
      " 0.00220767 0.00219262 0.00219769 0.00219262 0.00220311 0.00219262\n",
      " 0.00219716 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00220396 0.00219716 0.00219262 0.00219262 0.00220865\n",
      " 0.00219842 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00220803 0.00221204 0.00219262 0.00223629 0.00219262 0.00219262\n",
      " 0.00219262 0.00219757 0.00219262 0.00219262 0.00219262 0.00219716\n",
      " 0.00220191 0.00219262 0.00219262 0.00219262 0.00219752 0.00219262\n",
      " 0.00219262 0.00219262 0.00221426 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219736 0.00221403 0.00219757 0.00219876 0.00219262\n",
      " 0.00219262 0.00220776 0.00219262 0.00222457 0.00221716 0.00219757\n",
      " 0.00219757 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219769 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00220877 0.00219262 0.00220445 0.00220354 0.00219262\n",
      " 0.00219262 0.00219828 0.00219262 0.00220191 0.00219262 0.00220191\n",
      " 0.00219262 0.00219262 0.0022145  0.00220416 0.00219262 0.0022473\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00220275 0.00219262 0.00219752 0.00219262 0.00219262 0.00219262\n",
      " 0.00220396 0.00219262 0.00219262 0.00219769 0.00219736 0.00219262\n",
      " 0.00221373 0.00219262 0.00219262 0.00219262 0.00219262 0.00220416\n",
      " 0.00219262 0.00220191 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219716\n",
      " 0.00225753 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.0021978\n",
      " 0.00219262 0.00219262 0.00219262 0.00221301 0.00220191 0.00219262\n",
      " 0.00219757 0.00219262 0.00219262 0.00219262 0.00221414 0.00220807\n",
      " 0.00219262 0.00219262 0.00220311 0.00220396 0.00222479 0.00219716\n",
      " 0.00220291 0.00219842 0.00219262 0.00219262 0.00220276 0.00219262\n",
      " 0.00221316 0.00219262 0.002198   0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00220288 0.00219262 0.00220297 0.00219262\n",
      " 0.00220309 0.00222581 0.00220716 0.00219262 0.002198   0.00219262\n",
      " 0.0022084  0.00219262 0.00219262 0.00219262 0.00219262 0.00221204\n",
      " 0.00219262 0.00219262 0.00220373 0.00223501 0.00219262 0.00220914\n",
      " 0.00220248 0.0022258  0.00220732 0.00219262 0.00219262 0.0022181\n",
      " 0.0022027  0.00219716 0.00219262 0.00219262 0.00222477 0.002198\n",
      " 0.00219262 0.00220351 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00220807 0.00219262 0.00220244 0.00220191\n",
      " 0.00219262 0.00219262 0.00220289 0.00219262 0.00220309 0.00219262\n",
      " 0.00219262 0.00219262 0.00220842 0.00219716 0.00219262 0.00219262\n",
      " 0.00219262 0.00220382 0.00219262 0.00219716 0.00219262 0.00219757\n",
      " 0.00219262 0.00219262 0.00222644 0.00219262 0.00222473 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00220331 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00220297 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219716 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.0022032  0.00219262\n",
      " 0.00221892 0.00220458 0.00219262 0.00219262 0.00219262 0.00219752\n",
      " 0.00219262 0.00220289 0.00219262 0.00221221 0.00219262 0.002198\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219814\n",
      " 0.00219262 0.00219262 0.00220875 0.00220711 0.00219262 0.0022182\n",
      " 0.00223228 0.00220232 0.00219262 0.00219262 0.00219716 0.002207\n",
      " 0.00219876 0.00222463 0.00219262 0.00223055 0.00219716 0.00219262\n",
      " 0.00219262 0.00219262 0.00221225 0.00219716 0.00219262 0.00221442\n",
      " 0.00219262 0.00219716 0.00220966 0.00219262 0.00220807 0.00220275\n",
      " 0.00219262 0.00219716 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219828\n",
      " 0.00219814 0.00219262 0.00220303 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.002198   0.00219262 0.00219262 0.00219814 0.00219752\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00223429 0.00220768 0.00219757\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00221942\n",
      " 0.00219262 0.00219262 0.002198   0.00219262 0.00219262]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002643533066495037\n",
      "Boosting iter: 13 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 53/20\n",
      "random state: 52\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220305 0.00219262 0.0021978  0.0022079  0.00219262 0.00219828\n",
      " 0.00219262 0.00219736 0.00219262 0.00219262 0.00219262 0.00221963\n",
      " 0.00221899 0.00219262 0.00223081 0.00219262 0.00219842 0.00219262\n",
      " 0.00221963 0.00219752 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219828 0.00219262 0.00219262 0.00220934\n",
      " 0.00219262 0.00221425 0.00219262 0.00219262 0.00219262 0.00219752\n",
      " 0.00219262 0.00219262 0.00221512 0.00220813 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219757 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00221851 0.00219262 0.00220736 0.00222466 0.002198\n",
      " 0.00219262 0.00219262 0.00219262 0.00220303 0.00219262 0.00220271\n",
      " 0.00219757 0.00219262 0.00224155 0.00219262 0.00221988 0.00219262\n",
      " 0.00219262 0.0022145  0.00221315 0.00219716 0.00219757 0.00219814\n",
      " 0.00220767 0.00219262 0.00219769 0.00219262 0.00220311 0.00219262\n",
      " 0.00219716 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00220396 0.00219716 0.00219262 0.00219262 0.00220865\n",
      " 0.00219842 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00220803 0.00221204 0.00219262 0.00223629 0.00219262 0.00219262\n",
      " 0.00219262 0.00219757 0.00219262 0.00219262 0.00219262 0.00219716\n",
      " 0.00220191 0.00219262 0.00219262 0.00219262 0.00219752 0.00219262\n",
      " 0.00219262 0.00219262 0.00221426 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219736 0.00221403 0.00219757 0.00219876 0.00219262\n",
      " 0.00219262 0.00220776 0.00219262 0.00222457 0.00221716 0.00219757\n",
      " 0.00219757 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219769 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00220877 0.00219262 0.00220445 0.00220354 0.00219262\n",
      " 0.00219262 0.00219828 0.00219262 0.00220191 0.00219262 0.00220191\n",
      " 0.00219262 0.00219262 0.0022145  0.00220416 0.00219262 0.0022473\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00220275 0.00219262 0.00219752 0.00219262 0.00219262 0.00219262\n",
      " 0.00220396 0.00219262 0.00219262 0.00219769 0.00219736 0.00219262\n",
      " 0.00221373 0.00219262 0.00219262 0.00219262 0.00219262 0.00220416\n",
      " 0.00219262 0.00220191 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219716\n",
      " 0.00225753 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.0021978\n",
      " 0.00219262 0.00219262 0.00219262 0.00221301 0.00220191 0.00219262\n",
      " 0.00219757 0.00219262 0.00219262 0.00219262 0.00221414 0.00220807\n",
      " 0.00219262 0.00219262 0.00220311 0.00220396 0.00222479 0.00219716\n",
      " 0.00220291 0.00219842 0.00219262 0.00219262 0.00220276 0.00219262\n",
      " 0.00221316 0.00219262 0.002198   0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00220288 0.00219262 0.00220297 0.00219262\n",
      " 0.00220309 0.00222581 0.00220716 0.00219262 0.002198   0.00219262\n",
      " 0.0022084  0.00219262 0.00219262 0.00219262 0.00219262 0.00221204\n",
      " 0.00219262 0.00219262 0.00220373 0.00223501 0.00219262 0.00220914\n",
      " 0.00220248 0.0022258  0.00220732 0.00219262 0.00219262 0.0022181\n",
      " 0.0022027  0.00219716 0.00219262 0.00219262 0.00222477 0.002198\n",
      " 0.00219262 0.00220351 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00220807 0.00219262 0.00220244 0.00220191\n",
      " 0.00219262 0.00219262 0.00220289 0.00219262 0.00220309 0.00219262\n",
      " 0.00219262 0.00219262 0.00220842 0.00219716 0.00219262 0.00219262\n",
      " 0.00219262 0.00220382 0.00219262 0.00219716 0.00219262 0.00219757\n",
      " 0.00219262 0.00219262 0.00222644 0.00219262 0.00222473 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00220331 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00220297 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219716 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.0022032  0.00219262\n",
      " 0.00221892 0.00220458 0.00219262 0.00219262 0.00219262 0.00219752\n",
      " 0.00219262 0.00220289 0.00219262 0.00221221 0.00219262 0.002198\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219814\n",
      " 0.00219262 0.00219262 0.00220875 0.00220711 0.00219262 0.0022182\n",
      " 0.00223228 0.00220232 0.00219262 0.00219262 0.00219716 0.002207\n",
      " 0.00219876 0.00222463 0.00219262 0.00223055 0.00219716 0.00219262\n",
      " 0.00219262 0.00219262 0.00221225 0.00219716 0.00219262 0.00221442\n",
      " 0.00219262 0.00219716 0.00220966 0.00219262 0.00220807 0.00220275\n",
      " 0.00219262 0.00219716 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219828\n",
      " 0.00219814 0.00219262 0.00220303 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.002198   0.00219262 0.00219262 0.00219814 0.00219752\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262\n",
      " 0.00219262 0.00219262 0.00219262 0.00223429 0.00220768 0.00219757\n",
      " 0.00219262 0.00219262 0.00219262 0.00219262 0.00219262 0.00221942\n",
      " 0.00219262 0.00219262 0.002198   0.00219262 0.00219262]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        358, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        184, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  67 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 309 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([212, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████████████████▍                                                                                                                      | 499/2000 [01:03<03:11,  7.85it/s]\n",
      "[2023-12-17T23:09:08.890049+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:09:08.892189+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:09:08.893972+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T23:09:08.896120+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T23:09:08.899902+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:09:08.901667+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:09:08.903411+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_12__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 12 accuracy:  0.9098901098901099\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220259 0.00219216 0.00219734 0.00220744 0.00219216 0.00219782\n",
      " 0.00219216 0.00219689 0.00219216 0.00219216 0.00219216 0.00222428\n",
      " 0.00221852 0.00219216 0.00223035 0.00219216 0.00219796 0.00219216\n",
      " 0.00222428 0.00219706 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219782 0.00219216 0.00219216 0.00220888\n",
      " 0.00219216 0.00221378 0.00219216 0.00219216 0.00219216 0.00219706\n",
      " 0.00219216 0.00219216 0.00221466 0.00220767 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219711 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00221804 0.00219216 0.0022069  0.00222933 0.00219754\n",
      " 0.00219216 0.00219216 0.00219216 0.00220257 0.00219216 0.00220225\n",
      " 0.00219711 0.00219216 0.00224625 0.00219216 0.00221941 0.00219216\n",
      " 0.00219216 0.00221404 0.00221269 0.0021967  0.00219711 0.00219768\n",
      " 0.00220721 0.00219216 0.00219723 0.00219216 0.00220265 0.00219216\n",
      " 0.0021967  0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.0022035  0.0021967  0.00219216 0.00219216 0.00220819\n",
      " 0.00219796 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00221266 0.00221668 0.00219216 0.00224098 0.00219216 0.00219216\n",
      " 0.00219216 0.00219711 0.00219216 0.00219216 0.00219216 0.0021967\n",
      " 0.00220145 0.00219216 0.00219216 0.00219216 0.00219706 0.00219216\n",
      " 0.00219216 0.00219216 0.0022189  0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219689 0.00221357 0.00219711 0.00220337 0.00219216\n",
      " 0.00219216 0.00221239 0.00219216 0.00222923 0.00221669 0.00219711\n",
      " 0.00219711 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219723 0.00219722 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00220831 0.00219216 0.00220907 0.00220308 0.00219216\n",
      " 0.00219216 0.00219782 0.00219216 0.00220145 0.00219216 0.00220652\n",
      " 0.00219216 0.00219216 0.00221915 0.0022037  0.00219216 0.00225201\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00220229 0.00219216 0.00219706 0.00219216 0.00219216 0.00219216\n",
      " 0.0022035  0.00219216 0.00219216 0.00219723 0.00219689 0.00219216\n",
      " 0.00221838 0.00219216 0.00219216 0.00219216 0.00219216 0.0022037\n",
      " 0.00219216 0.00220652 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.0021967\n",
      " 0.00226226 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219734\n",
      " 0.00219216 0.00219216 0.00219216 0.00221765 0.00220145 0.00219216\n",
      " 0.00219711 0.00219216 0.00219216 0.00219216 0.00221368 0.00220761\n",
      " 0.00219216 0.00219216 0.00220773 0.0022035  0.00222433 0.0021967\n",
      " 0.00220245 0.00219796 0.00219216 0.00219216 0.00220738 0.00219216\n",
      " 0.00221269 0.00219216 0.00219754 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00220242 0.00219216 0.00220251 0.00219216\n",
      " 0.00220263 0.00223048 0.0022067  0.00219216 0.00219754 0.00219216\n",
      " 0.00220794 0.00219216 0.00219216 0.00219216 0.00219216 0.00221158\n",
      " 0.00219216 0.00219216 0.00220327 0.00223454 0.00219216 0.00220868\n",
      " 0.00220202 0.00223047 0.00220685 0.00219216 0.00219216 0.00221763\n",
      " 0.00220224 0.0021967  0.00219216 0.00219216 0.00222431 0.00219754\n",
      " 0.00219216 0.00220305 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00220761 0.00219216 0.00220198 0.00220145\n",
      " 0.00219216 0.00219216 0.00220243 0.00219216 0.00220263 0.00219216\n",
      " 0.00219216 0.00219216 0.00220795 0.0021967  0.00219216 0.00219216\n",
      " 0.00219216 0.00220844 0.00219216 0.0021967  0.00219216 0.00219711\n",
      " 0.00219216 0.00219216 0.00223111 0.00219216 0.00222939 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00220285 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00220251 0.00219722 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.0021967  0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00220782 0.00219216\n",
      " 0.00222358 0.00220412 0.00219216 0.00219216 0.00219216 0.00219706\n",
      " 0.00219216 0.00220751 0.00219216 0.00221685 0.00219216 0.00220261\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219768\n",
      " 0.00219216 0.00219216 0.00220828 0.00221174 0.00219216 0.00222285\n",
      " 0.00223181 0.00220694 0.00219216 0.00219216 0.0021967  0.00221163\n",
      " 0.0021983  0.00222416 0.00219216 0.00223523 0.0021967  0.00219216\n",
      " 0.00219216 0.00219216 0.00221689 0.0021967  0.00219216 0.00221396\n",
      " 0.00219216 0.00220177 0.00220919 0.00219216 0.00220761 0.00220229\n",
      " 0.00219216 0.0021967  0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219782\n",
      " 0.00219768 0.00219216 0.00220765 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219754 0.00219216 0.00219216 0.00219768 0.00219706\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00223382 0.00220722 0.00219711\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00221896\n",
      " 0.00219216 0.00219216 0.00219754 0.00219216 0.00219216]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002304244228185672\n",
      "Boosting iter: 14 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 54/20\n",
      "random state: 53\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220259 0.00219216 0.00219734 0.00220744 0.00219216 0.00219782\n",
      " 0.00219216 0.00219689 0.00219216 0.00219216 0.00219216 0.00222428\n",
      " 0.00221852 0.00219216 0.00223035 0.00219216 0.00219796 0.00219216\n",
      " 0.00222428 0.00219706 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219782 0.00219216 0.00219216 0.00220888\n",
      " 0.00219216 0.00221378 0.00219216 0.00219216 0.00219216 0.00219706\n",
      " 0.00219216 0.00219216 0.00221466 0.00220767 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219711 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00221804 0.00219216 0.0022069  0.00222933 0.00219754\n",
      " 0.00219216 0.00219216 0.00219216 0.00220257 0.00219216 0.00220225\n",
      " 0.00219711 0.00219216 0.00224625 0.00219216 0.00221941 0.00219216\n",
      " 0.00219216 0.00221404 0.00221269 0.0021967  0.00219711 0.00219768\n",
      " 0.00220721 0.00219216 0.00219723 0.00219216 0.00220265 0.00219216\n",
      " 0.0021967  0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.0022035  0.0021967  0.00219216 0.00219216 0.00220819\n",
      " 0.00219796 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00221266 0.00221668 0.00219216 0.00224098 0.00219216 0.00219216\n",
      " 0.00219216 0.00219711 0.00219216 0.00219216 0.00219216 0.0021967\n",
      " 0.00220145 0.00219216 0.00219216 0.00219216 0.00219706 0.00219216\n",
      " 0.00219216 0.00219216 0.0022189  0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219689 0.00221357 0.00219711 0.00220337 0.00219216\n",
      " 0.00219216 0.00221239 0.00219216 0.00222923 0.00221669 0.00219711\n",
      " 0.00219711 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219723 0.00219722 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00220831 0.00219216 0.00220907 0.00220308 0.00219216\n",
      " 0.00219216 0.00219782 0.00219216 0.00220145 0.00219216 0.00220652\n",
      " 0.00219216 0.00219216 0.00221915 0.0022037  0.00219216 0.00225201\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00220229 0.00219216 0.00219706 0.00219216 0.00219216 0.00219216\n",
      " 0.0022035  0.00219216 0.00219216 0.00219723 0.00219689 0.00219216\n",
      " 0.00221838 0.00219216 0.00219216 0.00219216 0.00219216 0.0022037\n",
      " 0.00219216 0.00220652 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.0021967\n",
      " 0.00226226 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219734\n",
      " 0.00219216 0.00219216 0.00219216 0.00221765 0.00220145 0.00219216\n",
      " 0.00219711 0.00219216 0.00219216 0.00219216 0.00221368 0.00220761\n",
      " 0.00219216 0.00219216 0.00220773 0.0022035  0.00222433 0.0021967\n",
      " 0.00220245 0.00219796 0.00219216 0.00219216 0.00220738 0.00219216\n",
      " 0.00221269 0.00219216 0.00219754 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00220242 0.00219216 0.00220251 0.00219216\n",
      " 0.00220263 0.00223048 0.0022067  0.00219216 0.00219754 0.00219216\n",
      " 0.00220794 0.00219216 0.00219216 0.00219216 0.00219216 0.00221158\n",
      " 0.00219216 0.00219216 0.00220327 0.00223454 0.00219216 0.00220868\n",
      " 0.00220202 0.00223047 0.00220685 0.00219216 0.00219216 0.00221763\n",
      " 0.00220224 0.0021967  0.00219216 0.00219216 0.00222431 0.00219754\n",
      " 0.00219216 0.00220305 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00220761 0.00219216 0.00220198 0.00220145\n",
      " 0.00219216 0.00219216 0.00220243 0.00219216 0.00220263 0.00219216\n",
      " 0.00219216 0.00219216 0.00220795 0.0021967  0.00219216 0.00219216\n",
      " 0.00219216 0.00220844 0.00219216 0.0021967  0.00219216 0.00219711\n",
      " 0.00219216 0.00219216 0.00223111 0.00219216 0.00222939 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00220285 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00220251 0.00219722 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.0021967  0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00220782 0.00219216\n",
      " 0.00222358 0.00220412 0.00219216 0.00219216 0.00219216 0.00219706\n",
      " 0.00219216 0.00220751 0.00219216 0.00221685 0.00219216 0.00220261\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219768\n",
      " 0.00219216 0.00219216 0.00220828 0.00221174 0.00219216 0.00222285\n",
      " 0.00223181 0.00220694 0.00219216 0.00219216 0.0021967  0.00221163\n",
      " 0.0021983  0.00222416 0.00219216 0.00223523 0.0021967  0.00219216\n",
      " 0.00219216 0.00219216 0.00221689 0.0021967  0.00219216 0.00221396\n",
      " 0.00219216 0.00220177 0.00220919 0.00219216 0.00220761 0.00220229\n",
      " 0.00219216 0.0021967  0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219782\n",
      " 0.00219768 0.00219216 0.00220765 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219754 0.00219216 0.00219216 0.00219768 0.00219706\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216\n",
      " 0.00219216 0.00219216 0.00219216 0.00223382 0.00220722 0.00219711\n",
      " 0.00219216 0.00219216 0.00219216 0.00219216 0.00219216 0.00221896\n",
      " 0.00219216 0.00219216 0.00219754 0.00219216 0.00219216]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  80,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        184, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([212, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████████████████████████████████████████████▎                                                                          | 1049/2000 [02:18<02:05,  7.55it/s]\n",
      "[2023-12-17T23:11:33.893292+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:11:33.895441+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:11:33.897193+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T23:11:33.899332+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T23:11:33.903147+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:11:33.904908+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:11:33.906693+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_13__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 13 accuracy:  0.9098901098901099\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220213 0.0021917  0.00219688 0.00220698 0.0021917  0.00219736\n",
      " 0.0021917  0.00219644 0.0021917  0.0021917  0.0021917  0.00222895\n",
      " 0.00222317 0.0021917  0.00223502 0.0021917  0.0021975  0.0021917\n",
      " 0.00222382 0.0021966  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219736 0.0021917  0.0021917  0.00220842\n",
      " 0.0021917  0.00221843 0.0021917  0.0021917  0.0021917  0.0021966\n",
      " 0.0021917  0.0021917  0.0022142  0.0022123  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219665 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0022227  0.0021917  0.00221153 0.002234   0.00219708\n",
      " 0.0021917  0.0021917  0.0021917  0.00220211 0.0021917  0.00220179\n",
      " 0.00219665 0.0021917  0.00225096 0.0021917  0.00221895 0.0021917\n",
      " 0.0021917  0.00221357 0.00221733 0.00219624 0.00219665 0.00219722\n",
      " 0.00220675 0.0021917  0.00219677 0.0021917  0.00220218 0.0021917\n",
      " 0.00219624 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00220304 0.00219624 0.0021917  0.0021917  0.00220772\n",
      " 0.0021975  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0022122  0.00221622 0.0021917  0.00224568 0.0021917  0.0021917\n",
      " 0.0021917  0.00219665 0.0021917  0.0021917  0.0021917  0.00219624\n",
      " 0.00220099 0.0021917  0.0021917  0.0021917  0.0021966  0.0021917\n",
      " 0.0021917  0.0021917  0.00222356 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00219644 0.0022131  0.00219665 0.00220291 0.0021917\n",
      " 0.0021917  0.00221703 0.0021917  0.00222876 0.00221623 0.00219665\n",
      " 0.00219665 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.00220184 0.00219676 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00220784 0.0021917  0.0022137  0.00220262 0.0021917\n",
      " 0.0021917  0.00219736 0.0021917  0.00220099 0.0021917  0.00220606\n",
      " 0.0021917  0.0021917  0.00221868 0.00220324 0.0021917  0.00225673\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.00220183 0.0021917  0.0021966  0.0021917  0.0021917  0.0021917\n",
      " 0.00220304 0.0021917  0.0021917  0.00219677 0.00219644 0.0021917\n",
      " 0.00222303 0.0021917  0.0021917  0.0021917  0.0021917  0.00220832\n",
      " 0.0021917  0.00220606 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00219676 0.0021917  0.00219624\n",
      " 0.00226179 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219688\n",
      " 0.0021917  0.0021917  0.0021917  0.0022223  0.00220099 0.0021917\n",
      " 0.00219665 0.0021917  0.0021917  0.0021917  0.00221321 0.00220715\n",
      " 0.0021917  0.0021917  0.00220727 0.00220304 0.00222386 0.00219624\n",
      " 0.00220199 0.0021975  0.0021917  0.0021917  0.00220692 0.0021917\n",
      " 0.00221223 0.0021917  0.00219708 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00220196 0.0021917  0.00220205 0.0021917\n",
      " 0.00220217 0.00223001 0.00220624 0.0021917  0.00219708 0.0021917\n",
      " 0.00220748 0.0021917  0.0021917  0.0021917  0.0021917  0.00221111\n",
      " 0.0021917  0.0021917  0.00220789 0.00223408 0.0021917  0.00220822\n",
      " 0.00220156 0.00223    0.00221148 0.0021917  0.0021917  0.00221717\n",
      " 0.00220177 0.00219624 0.0021917  0.0021917  0.00222897 0.00219708\n",
      " 0.0021917  0.00220259 0.0021917  0.0021917  0.0021917  0.00219676\n",
      " 0.0021917  0.0021917  0.00221224 0.0021917  0.00220152 0.00220099\n",
      " 0.0021917  0.0021917  0.00220197 0.0021917  0.00220217 0.0021917\n",
      " 0.0021917  0.0021917  0.00221258 0.00219624 0.0021917  0.0021917\n",
      " 0.0021917  0.00220798 0.0021917  0.00219624 0.0021917  0.00219665\n",
      " 0.0021917  0.0021917  0.00223579 0.0021917  0.00223407 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00220239 0.00219676 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00220205 0.00220182 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00219624 0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219676 0.0021917  0.00221245 0.0021917\n",
      " 0.00222311 0.00220366 0.0021917  0.0021917  0.0021917  0.0021966\n",
      " 0.0021917  0.00221214 0.0021917  0.0022215  0.0021917  0.00220215\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219722\n",
      " 0.0021917  0.0021917  0.00220782 0.00221638 0.0021917  0.00222239\n",
      " 0.00223135 0.00220647 0.0021917  0.0021917  0.00219624 0.00221117\n",
      " 0.00219784 0.00222883 0.0021917  0.00223476 0.00219624 0.0021917\n",
      " 0.0021917  0.0021917  0.00222154 0.00219624 0.0021917  0.00221349\n",
      " 0.0021917  0.00220131 0.00220873 0.0021917  0.00220715 0.00220691\n",
      " 0.0021917  0.00219624 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219736\n",
      " 0.00219722 0.0021917  0.00221228 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00219708 0.0021917  0.0021917  0.00219722 0.0021966\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0022385  0.00220676 0.00219665\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00221849\n",
      " 0.0021917  0.0021917  0.00219708 0.0021917  0.00219676]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002304204351201144\n",
      "Boosting iter: 15 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 55/20\n",
      "random state: 54\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220213 0.0021917  0.00219688 0.00220698 0.0021917  0.00219736\n",
      " 0.0021917  0.00219644 0.0021917  0.0021917  0.0021917  0.00222895\n",
      " 0.00222317 0.0021917  0.00223502 0.0021917  0.0021975  0.0021917\n",
      " 0.00222382 0.0021966  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219736 0.0021917  0.0021917  0.00220842\n",
      " 0.0021917  0.00221843 0.0021917  0.0021917  0.0021917  0.0021966\n",
      " 0.0021917  0.0021917  0.0022142  0.0022123  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219665 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0022227  0.0021917  0.00221153 0.002234   0.00219708\n",
      " 0.0021917  0.0021917  0.0021917  0.00220211 0.0021917  0.00220179\n",
      " 0.00219665 0.0021917  0.00225096 0.0021917  0.00221895 0.0021917\n",
      " 0.0021917  0.00221357 0.00221733 0.00219624 0.00219665 0.00219722\n",
      " 0.00220675 0.0021917  0.00219677 0.0021917  0.00220218 0.0021917\n",
      " 0.00219624 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00220304 0.00219624 0.0021917  0.0021917  0.00220772\n",
      " 0.0021975  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0022122  0.00221622 0.0021917  0.00224568 0.0021917  0.0021917\n",
      " 0.0021917  0.00219665 0.0021917  0.0021917  0.0021917  0.00219624\n",
      " 0.00220099 0.0021917  0.0021917  0.0021917  0.0021966  0.0021917\n",
      " 0.0021917  0.0021917  0.00222356 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00219644 0.0022131  0.00219665 0.00220291 0.0021917\n",
      " 0.0021917  0.00221703 0.0021917  0.00222876 0.00221623 0.00219665\n",
      " 0.00219665 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.00220184 0.00219676 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00220784 0.0021917  0.0022137  0.00220262 0.0021917\n",
      " 0.0021917  0.00219736 0.0021917  0.00220099 0.0021917  0.00220606\n",
      " 0.0021917  0.0021917  0.00221868 0.00220324 0.0021917  0.00225673\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.00220183 0.0021917  0.0021966  0.0021917  0.0021917  0.0021917\n",
      " 0.00220304 0.0021917  0.0021917  0.00219677 0.00219644 0.0021917\n",
      " 0.00222303 0.0021917  0.0021917  0.0021917  0.0021917  0.00220832\n",
      " 0.0021917  0.00220606 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00219676 0.0021917  0.00219624\n",
      " 0.00226179 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219688\n",
      " 0.0021917  0.0021917  0.0021917  0.0022223  0.00220099 0.0021917\n",
      " 0.00219665 0.0021917  0.0021917  0.0021917  0.00221321 0.00220715\n",
      " 0.0021917  0.0021917  0.00220727 0.00220304 0.00222386 0.00219624\n",
      " 0.00220199 0.0021975  0.0021917  0.0021917  0.00220692 0.0021917\n",
      " 0.00221223 0.0021917  0.00219708 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00220196 0.0021917  0.00220205 0.0021917\n",
      " 0.00220217 0.00223001 0.00220624 0.0021917  0.00219708 0.0021917\n",
      " 0.00220748 0.0021917  0.0021917  0.0021917  0.0021917  0.00221111\n",
      " 0.0021917  0.0021917  0.00220789 0.00223408 0.0021917  0.00220822\n",
      " 0.00220156 0.00223    0.00221148 0.0021917  0.0021917  0.00221717\n",
      " 0.00220177 0.00219624 0.0021917  0.0021917  0.00222897 0.00219708\n",
      " 0.0021917  0.00220259 0.0021917  0.0021917  0.0021917  0.00219676\n",
      " 0.0021917  0.0021917  0.00221224 0.0021917  0.00220152 0.00220099\n",
      " 0.0021917  0.0021917  0.00220197 0.0021917  0.00220217 0.0021917\n",
      " 0.0021917  0.0021917  0.00221258 0.00219624 0.0021917  0.0021917\n",
      " 0.0021917  0.00220798 0.0021917  0.00219624 0.0021917  0.00219665\n",
      " 0.0021917  0.0021917  0.00223579 0.0021917  0.00223407 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00220239 0.00219676 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00220205 0.00220182 0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.00219624 0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.00219676 0.0021917  0.00221245 0.0021917\n",
      " 0.00222311 0.00220366 0.0021917  0.0021917  0.0021917  0.0021966\n",
      " 0.0021917  0.00221214 0.0021917  0.0022215  0.0021917  0.00220215\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219722\n",
      " 0.0021917  0.0021917  0.00220782 0.00221638 0.0021917  0.00222239\n",
      " 0.00223135 0.00220647 0.0021917  0.0021917  0.00219624 0.00221117\n",
      " 0.00219784 0.00222883 0.0021917  0.00223476 0.00219624 0.0021917\n",
      " 0.0021917  0.0021917  0.00222154 0.00219624 0.0021917  0.00221349\n",
      " 0.0021917  0.00220131 0.00220873 0.0021917  0.00220715 0.00220691\n",
      " 0.0021917  0.00219624 0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00219736\n",
      " 0.00219722 0.0021917  0.00221228 0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.00219708 0.0021917  0.0021917  0.00219722 0.0021966\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.0021917\n",
      " 0.0021917  0.0021917  0.0021917  0.0022385  0.00220676 0.00219665\n",
      " 0.0021917  0.0021917  0.0021917  0.0021917  0.0021917  0.00221849\n",
      " 0.0021917  0.0021917  0.00219708 0.0021917  0.00219676]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 303,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 209 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  67 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False, False, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([212, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████████████████████████████████████                                                                                           | 849/2000 [01:50<02:29,  7.67it/s]\n",
      "[2023-12-17T23:13:30.603768+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:13:30.605869+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:13:30.607593+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T23:13:30.609637+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T23:13:30.613225+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:13:30.614968+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:13:30.616537+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_14__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 14 accuracy:  0.9230769230769231\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220171 0.00219128 0.00219646 0.00220655 0.00219128 0.00219694\n",
      " 0.00219128 0.00219601 0.00219128 0.00219128 0.00219128 0.00222852\n",
      " 0.00222825 0.00219128 0.00224013 0.00219128 0.00219708 0.00219128\n",
      " 0.00222339 0.00219617 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219694 0.00219128 0.00219128 0.00220799\n",
      " 0.00219128 0.002218   0.00219128 0.00219128 0.00219128 0.00219617\n",
      " 0.00219128 0.00219128 0.00221377 0.00221187 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219623 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00222227 0.00219128 0.0022111  0.00223357 0.00219666\n",
      " 0.00219128 0.00219128 0.00219128 0.00220169 0.00219128 0.00220136\n",
      " 0.00219623 0.00219128 0.0022561  0.00219128 0.00222402 0.00219128\n",
      " 0.00219128 0.00221315 0.00222239 0.00219582 0.00219623 0.0021968\n",
      " 0.00220632 0.00219128 0.00219635 0.00219128 0.00220722 0.00219128\n",
      " 0.00219582 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00220261 0.00219582 0.00219128 0.00219128 0.0022073\n",
      " 0.00219708 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00221725 0.00221579 0.00219128 0.00225081 0.00219128 0.00219128\n",
      " 0.00219128 0.00219623 0.00219128 0.00219128 0.00219128 0.00219582\n",
      " 0.00220056 0.00219128 0.00219128 0.00219128 0.00219617 0.00219128\n",
      " 0.00219128 0.00219128 0.00222864 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219601 0.00221268 0.00219623 0.00220249 0.00219128\n",
      " 0.00219128 0.0022166  0.00219128 0.00222834 0.00222129 0.00219623\n",
      " 0.00219623 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00220141 0.00219633 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00220742 0.00219128 0.00221328 0.00220765 0.00219128\n",
      " 0.00219128 0.00219694 0.00219128 0.00220056 0.00219128 0.00220564\n",
      " 0.00219128 0.00219128 0.00221825 0.00220282 0.00219128 0.00226189\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00220141 0.00219128 0.00219617 0.00219128 0.00219128 0.00219128\n",
      " 0.00220261 0.00219128 0.00219128 0.00219635 0.00219601 0.00219128\n",
      " 0.0022226  0.00219128 0.00219128 0.00219128 0.00219128 0.0022079\n",
      " 0.00219128 0.00220564 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219633 0.00219128 0.00219582\n",
      " 0.00226696 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219646\n",
      " 0.00219128 0.00219128 0.00219128 0.00222737 0.00220056 0.00219128\n",
      " 0.00220167 0.00219128 0.00219128 0.00219128 0.00221827 0.00220672\n",
      " 0.00219128 0.00219128 0.00221231 0.00220261 0.00222343 0.00219582\n",
      " 0.00220157 0.00220252 0.00219128 0.00219128 0.00220649 0.00219128\n",
      " 0.00221181 0.00219128 0.00219666 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00220154 0.00219128 0.00220708 0.00219128\n",
      " 0.00220174 0.00222958 0.00221128 0.00219128 0.00219666 0.00219128\n",
      " 0.00220705 0.00219128 0.00219128 0.00219128 0.00219128 0.00221069\n",
      " 0.00219128 0.00219128 0.00221293 0.00223918 0.00219128 0.00220779\n",
      " 0.00220114 0.00222957 0.00221106 0.00219128 0.00219128 0.00222223\n",
      " 0.00220135 0.00219582 0.00219128 0.00219128 0.00223406 0.00219666\n",
      " 0.00219128 0.00220216 0.00219128 0.00219128 0.00219128 0.00219633\n",
      " 0.00219128 0.00219128 0.00221181 0.00219128 0.00220109 0.00220056\n",
      " 0.00219128 0.00219128 0.00220155 0.00219128 0.00220174 0.00219128\n",
      " 0.00219128 0.00219128 0.00221216 0.00219582 0.00219128 0.00219128\n",
      " 0.00219128 0.00220756 0.00219128 0.00219582 0.00219128 0.00219623\n",
      " 0.00219128 0.00219128 0.00223536 0.00219128 0.00223917 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00220197 0.00219633 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00220708 0.0022014  0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219582 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219633 0.00219128 0.00221202 0.00219128\n",
      " 0.00222268 0.00220324 0.00219128 0.00219128 0.00219128 0.00219617\n",
      " 0.00219128 0.00221171 0.00219128 0.00222658 0.00219671 0.00220173\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.0021968\n",
      " 0.00219128 0.00219128 0.0022074  0.00222144 0.00219128 0.00222196\n",
      " 0.00223644 0.00220605 0.00219128 0.00219128 0.00219582 0.00221074\n",
      " 0.00220286 0.00223392 0.00219128 0.00223986 0.00219582 0.00219128\n",
      " 0.00219128 0.00219128 0.00222111 0.00219582 0.00219128 0.00221307\n",
      " 0.00219128 0.00220088 0.00220831 0.00219128 0.00221219 0.00220648\n",
      " 0.00219128 0.00219582 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219694\n",
      " 0.0021968  0.00219128 0.00221186 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219666 0.00219128 0.00219128 0.0021968  0.00219617\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00223807 0.00220634 0.00219623\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00222356\n",
      " 0.00219128 0.00219128 0.00219666 0.00219128 0.00219633]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002474240651679884\n",
      "Boosting iter: 16 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 56/20\n",
      "random state: 55\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220171 0.00219128 0.00219646 0.00220655 0.00219128 0.00219694\n",
      " 0.00219128 0.00219601 0.00219128 0.00219128 0.00219128 0.00222852\n",
      " 0.00222825 0.00219128 0.00224013 0.00219128 0.00219708 0.00219128\n",
      " 0.00222339 0.00219617 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219694 0.00219128 0.00219128 0.00220799\n",
      " 0.00219128 0.002218   0.00219128 0.00219128 0.00219128 0.00219617\n",
      " 0.00219128 0.00219128 0.00221377 0.00221187 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219623 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00222227 0.00219128 0.0022111  0.00223357 0.00219666\n",
      " 0.00219128 0.00219128 0.00219128 0.00220169 0.00219128 0.00220136\n",
      " 0.00219623 0.00219128 0.0022561  0.00219128 0.00222402 0.00219128\n",
      " 0.00219128 0.00221315 0.00222239 0.00219582 0.00219623 0.0021968\n",
      " 0.00220632 0.00219128 0.00219635 0.00219128 0.00220722 0.00219128\n",
      " 0.00219582 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00220261 0.00219582 0.00219128 0.00219128 0.0022073\n",
      " 0.00219708 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00221725 0.00221579 0.00219128 0.00225081 0.00219128 0.00219128\n",
      " 0.00219128 0.00219623 0.00219128 0.00219128 0.00219128 0.00219582\n",
      " 0.00220056 0.00219128 0.00219128 0.00219128 0.00219617 0.00219128\n",
      " 0.00219128 0.00219128 0.00222864 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219601 0.00221268 0.00219623 0.00220249 0.00219128\n",
      " 0.00219128 0.0022166  0.00219128 0.00222834 0.00222129 0.00219623\n",
      " 0.00219623 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00220141 0.00219633 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00220742 0.00219128 0.00221328 0.00220765 0.00219128\n",
      " 0.00219128 0.00219694 0.00219128 0.00220056 0.00219128 0.00220564\n",
      " 0.00219128 0.00219128 0.00221825 0.00220282 0.00219128 0.00226189\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00220141 0.00219128 0.00219617 0.00219128 0.00219128 0.00219128\n",
      " 0.00220261 0.00219128 0.00219128 0.00219635 0.00219601 0.00219128\n",
      " 0.0022226  0.00219128 0.00219128 0.00219128 0.00219128 0.0022079\n",
      " 0.00219128 0.00220564 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219633 0.00219128 0.00219582\n",
      " 0.00226696 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219646\n",
      " 0.00219128 0.00219128 0.00219128 0.00222737 0.00220056 0.00219128\n",
      " 0.00220167 0.00219128 0.00219128 0.00219128 0.00221827 0.00220672\n",
      " 0.00219128 0.00219128 0.00221231 0.00220261 0.00222343 0.00219582\n",
      " 0.00220157 0.00220252 0.00219128 0.00219128 0.00220649 0.00219128\n",
      " 0.00221181 0.00219128 0.00219666 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00220154 0.00219128 0.00220708 0.00219128\n",
      " 0.00220174 0.00222958 0.00221128 0.00219128 0.00219666 0.00219128\n",
      " 0.00220705 0.00219128 0.00219128 0.00219128 0.00219128 0.00221069\n",
      " 0.00219128 0.00219128 0.00221293 0.00223918 0.00219128 0.00220779\n",
      " 0.00220114 0.00222957 0.00221106 0.00219128 0.00219128 0.00222223\n",
      " 0.00220135 0.00219582 0.00219128 0.00219128 0.00223406 0.00219666\n",
      " 0.00219128 0.00220216 0.00219128 0.00219128 0.00219128 0.00219633\n",
      " 0.00219128 0.00219128 0.00221181 0.00219128 0.00220109 0.00220056\n",
      " 0.00219128 0.00219128 0.00220155 0.00219128 0.00220174 0.00219128\n",
      " 0.00219128 0.00219128 0.00221216 0.00219582 0.00219128 0.00219128\n",
      " 0.00219128 0.00220756 0.00219128 0.00219582 0.00219128 0.00219623\n",
      " 0.00219128 0.00219128 0.00223536 0.00219128 0.00223917 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00220197 0.00219633 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00220708 0.0022014  0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219582 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219633 0.00219128 0.00221202 0.00219128\n",
      " 0.00222268 0.00220324 0.00219128 0.00219128 0.00219128 0.00219617\n",
      " 0.00219128 0.00221171 0.00219128 0.00222658 0.00219671 0.00220173\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.0021968\n",
      " 0.00219128 0.00219128 0.0022074  0.00222144 0.00219128 0.00222196\n",
      " 0.00223644 0.00220605 0.00219128 0.00219128 0.00219582 0.00221074\n",
      " 0.00220286 0.00223392 0.00219128 0.00223986 0.00219582 0.00219128\n",
      " 0.00219128 0.00219128 0.00222111 0.00219582 0.00219128 0.00221307\n",
      " 0.00219128 0.00220088 0.00220831 0.00219128 0.00221219 0.00220648\n",
      " 0.00219128 0.00219582 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219694\n",
      " 0.0021968  0.00219128 0.00221186 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219666 0.00219128 0.00219128 0.0021968  0.00219617\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128\n",
      " 0.00219128 0.00219128 0.00219128 0.00223807 0.00220634 0.00219623\n",
      " 0.00219128 0.00219128 0.00219128 0.00219128 0.00219128 0.00222356\n",
      " 0.00219128 0.00219128 0.00219666 0.00219128 0.00219633]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 210 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 1599/2000 [03:15<00:48,  8.19it/s]\n",
      "[2023-12-17T23:16:52.047822+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:16:52.049978+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:16:52.051705+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T23:16:52.053793+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T23:16:52.057546+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:16:52.059357+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:16:52.061088+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_15__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 15 accuracy:  0.9318681318681319\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00220705 0.00219089 0.00219606 0.00220615 0.00219089 0.00219655\n",
      " 0.00219089 0.00219562 0.00219089 0.00219089 0.00219089 0.00223393\n",
      " 0.00222785 0.00219089 0.00224557 0.00219089 0.00219668 0.00219089\n",
      " 0.00222299 0.00219578 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219655 0.00219089 0.00219089 0.00220759\n",
      " 0.00219089 0.0022176  0.00219089 0.00219089 0.00219089 0.00219578\n",
      " 0.00219089 0.00219089 0.00221915 0.00221147 0.0021966  0.00219089\n",
      " 0.00219089 0.00219089 0.00219583 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00222187 0.00219089 0.00221647 0.00223317 0.00219627\n",
      " 0.00219089 0.00219089 0.00219089 0.00220129 0.00219089 0.00220097\n",
      " 0.00219583 0.00219089 0.00226158 0.00219089 0.00222362 0.00219089\n",
      " 0.00219089 0.00221852 0.00222199 0.00219542 0.00219583 0.0021964\n",
      " 0.00220593 0.00219089 0.00219595 0.00219089 0.00220682 0.00219089\n",
      " 0.00219542 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00220222 0.00219542 0.00219089 0.00219089 0.0022069\n",
      " 0.00219668 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00221685 0.00221539 0.00219089 0.00225628 0.00219089 0.00219089\n",
      " 0.00219089 0.00219583 0.00219089 0.00219089 0.00219089 0.00219542\n",
      " 0.00220017 0.00219089 0.00219089 0.00219089 0.00219578 0.00219089\n",
      " 0.00219089 0.00219089 0.00223405 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219562 0.00221228 0.00219583 0.00220784 0.00219089\n",
      " 0.00219089 0.00221621 0.00219089 0.00222794 0.00222089 0.00219583\n",
      " 0.00219583 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00220102 0.00219594 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00220702 0.00219089 0.00221288 0.00221301 0.00219089\n",
      " 0.00219089 0.00219655 0.00219089 0.00220017 0.00219089 0.00220524\n",
      " 0.00219089 0.00219089 0.00221786 0.00220242 0.00219089 0.00226738\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00220101 0.00219089 0.00219578 0.00219089 0.00219089 0.00219089\n",
      " 0.00220796 0.00219089 0.00219089 0.00219595 0.00219562 0.00219089\n",
      " 0.0022222  0.00219089 0.00219089 0.00219089 0.00219089 0.0022075\n",
      " 0.00219089 0.00220524 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219594 0.00219089 0.00219542\n",
      " 0.00227246 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219606\n",
      " 0.00219089 0.00219089 0.00219089 0.00222697 0.00220017 0.00219089\n",
      " 0.00220127 0.00219089 0.00219089 0.00219089 0.00222365 0.00220633\n",
      " 0.00219089 0.00219089 0.00221768 0.00220222 0.00222303 0.00219542\n",
      " 0.00220117 0.00220213 0.00219089 0.00219089 0.0022061  0.0021966\n",
      " 0.00221141 0.00219089 0.00219627 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00220688 0.00219089 0.00220668 0.00219089\n",
      " 0.00220135 0.00222918 0.00221088 0.00219089 0.00219627 0.00219089\n",
      " 0.00220666 0.00219089 0.00219089 0.00219089 0.00219089 0.00221029\n",
      " 0.00219089 0.00219089 0.00221254 0.00224462 0.00219089 0.0022074\n",
      " 0.00220074 0.00222917 0.00221066 0.00219089 0.00219089 0.00222183\n",
      " 0.00220096 0.00219542 0.00219089 0.00219089 0.00223949 0.00219627\n",
      " 0.00219089 0.00220177 0.00219089 0.00219089 0.00219089 0.00219594\n",
      " 0.00219089 0.00219089 0.00221142 0.00219089 0.0022007  0.00220017\n",
      " 0.00219089 0.00219089 0.00220115 0.00219089 0.00220135 0.00219089\n",
      " 0.00219089 0.0021966  0.00221176 0.00219542 0.00219089 0.00219089\n",
      " 0.00219089 0.00220716 0.00219089 0.00219542 0.00219089 0.00219583\n",
      " 0.00219089 0.00219089 0.00224079 0.00219089 0.00224461 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00220157 0.00219594 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00221244 0.00220101 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219542 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219594 0.00219089 0.00221162 0.00219089\n",
      " 0.00222228 0.00220859 0.00219089 0.00219089 0.00219089 0.00219578\n",
      " 0.00219089 0.00221132 0.00219089 0.00222618 0.00219631 0.00220133\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.0021964\n",
      " 0.00219089 0.00219089 0.002207   0.00222104 0.00219089 0.00222156\n",
      " 0.00223604 0.00220565 0.00219089 0.00219089 0.00219542 0.00221034\n",
      " 0.00220247 0.00223352 0.00219089 0.0022453  0.00219542 0.00219089\n",
      " 0.00219089 0.00219089 0.00222071 0.00219542 0.00219089 0.00221267\n",
      " 0.00219089 0.00220049 0.00221367 0.00219089 0.00221756 0.00220609\n",
      " 0.00219089 0.00219542 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219655\n",
      " 0.0021964  0.00219089 0.00221146 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219627 0.00219089 0.00219089 0.0021964  0.00219578\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.0021966  0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00223767 0.00220594 0.00219583\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00222896\n",
      " 0.00219089 0.00219089 0.00219627 0.00219089 0.00219594]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0026048839357009812\n",
      "Boosting iter: 17 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 57/20\n",
      "random state: 56\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00220705 0.00219089 0.00219606 0.00220615 0.00219089 0.00219655\n",
      " 0.00219089 0.00219562 0.00219089 0.00219089 0.00219089 0.00223393\n",
      " 0.00222785 0.00219089 0.00224557 0.00219089 0.00219668 0.00219089\n",
      " 0.00222299 0.00219578 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219655 0.00219089 0.00219089 0.00220759\n",
      " 0.00219089 0.0022176  0.00219089 0.00219089 0.00219089 0.00219578\n",
      " 0.00219089 0.00219089 0.00221915 0.00221147 0.0021966  0.00219089\n",
      " 0.00219089 0.00219089 0.00219583 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00222187 0.00219089 0.00221647 0.00223317 0.00219627\n",
      " 0.00219089 0.00219089 0.00219089 0.00220129 0.00219089 0.00220097\n",
      " 0.00219583 0.00219089 0.00226158 0.00219089 0.00222362 0.00219089\n",
      " 0.00219089 0.00221852 0.00222199 0.00219542 0.00219583 0.0021964\n",
      " 0.00220593 0.00219089 0.00219595 0.00219089 0.00220682 0.00219089\n",
      " 0.00219542 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00220222 0.00219542 0.00219089 0.00219089 0.0022069\n",
      " 0.00219668 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00221685 0.00221539 0.00219089 0.00225628 0.00219089 0.00219089\n",
      " 0.00219089 0.00219583 0.00219089 0.00219089 0.00219089 0.00219542\n",
      " 0.00220017 0.00219089 0.00219089 0.00219089 0.00219578 0.00219089\n",
      " 0.00219089 0.00219089 0.00223405 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219562 0.00221228 0.00219583 0.00220784 0.00219089\n",
      " 0.00219089 0.00221621 0.00219089 0.00222794 0.00222089 0.00219583\n",
      " 0.00219583 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00220102 0.00219594 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00220702 0.00219089 0.00221288 0.00221301 0.00219089\n",
      " 0.00219089 0.00219655 0.00219089 0.00220017 0.00219089 0.00220524\n",
      " 0.00219089 0.00219089 0.00221786 0.00220242 0.00219089 0.00226738\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00220101 0.00219089 0.00219578 0.00219089 0.00219089 0.00219089\n",
      " 0.00220796 0.00219089 0.00219089 0.00219595 0.00219562 0.00219089\n",
      " 0.0022222  0.00219089 0.00219089 0.00219089 0.00219089 0.0022075\n",
      " 0.00219089 0.00220524 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219594 0.00219089 0.00219542\n",
      " 0.00227246 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219606\n",
      " 0.00219089 0.00219089 0.00219089 0.00222697 0.00220017 0.00219089\n",
      " 0.00220127 0.00219089 0.00219089 0.00219089 0.00222365 0.00220633\n",
      " 0.00219089 0.00219089 0.00221768 0.00220222 0.00222303 0.00219542\n",
      " 0.00220117 0.00220213 0.00219089 0.00219089 0.0022061  0.0021966\n",
      " 0.00221141 0.00219089 0.00219627 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00220688 0.00219089 0.00220668 0.00219089\n",
      " 0.00220135 0.00222918 0.00221088 0.00219089 0.00219627 0.00219089\n",
      " 0.00220666 0.00219089 0.00219089 0.00219089 0.00219089 0.00221029\n",
      " 0.00219089 0.00219089 0.00221254 0.00224462 0.00219089 0.0022074\n",
      " 0.00220074 0.00222917 0.00221066 0.00219089 0.00219089 0.00222183\n",
      " 0.00220096 0.00219542 0.00219089 0.00219089 0.00223949 0.00219627\n",
      " 0.00219089 0.00220177 0.00219089 0.00219089 0.00219089 0.00219594\n",
      " 0.00219089 0.00219089 0.00221142 0.00219089 0.0022007  0.00220017\n",
      " 0.00219089 0.00219089 0.00220115 0.00219089 0.00220135 0.00219089\n",
      " 0.00219089 0.0021966  0.00221176 0.00219542 0.00219089 0.00219089\n",
      " 0.00219089 0.00220716 0.00219089 0.00219542 0.00219089 0.00219583\n",
      " 0.00219089 0.00219089 0.00224079 0.00219089 0.00224461 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00220157 0.00219594 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00221244 0.00220101 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219542 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219594 0.00219089 0.00221162 0.00219089\n",
      " 0.00222228 0.00220859 0.00219089 0.00219089 0.00219089 0.00219578\n",
      " 0.00219089 0.00221132 0.00219089 0.00222618 0.00219631 0.00220133\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.0021964\n",
      " 0.00219089 0.00219089 0.002207   0.00222104 0.00219089 0.00222156\n",
      " 0.00223604 0.00220565 0.00219089 0.00219089 0.00219542 0.00221034\n",
      " 0.00220247 0.00223352 0.00219089 0.0022453  0.00219542 0.00219089\n",
      " 0.00219089 0.00219089 0.00222071 0.00219542 0.00219089 0.00221267\n",
      " 0.00219089 0.00220049 0.00221367 0.00219089 0.00221756 0.00220609\n",
      " 0.00219089 0.00219542 0.00219089 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00219655\n",
      " 0.0021964  0.00219089 0.00221146 0.00219089 0.00219089 0.00219089\n",
      " 0.00219089 0.00219627 0.00219089 0.00219089 0.0021964  0.00219578\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.0021966  0.00219089\n",
      " 0.00219089 0.00219089 0.00219089 0.00223767 0.00220594 0.00219583\n",
      " 0.00219089 0.00219089 0.00219089 0.00219089 0.00219089 0.00222896\n",
      " 0.00219089 0.00219089 0.00219627 0.00219089 0.00219594]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 210 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  35 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                           | 1249/2000 [02:24<01:26,  8.67it/s]\n",
      "[2023-12-17T23:19:22.333862+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:19:22.335977+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:19:22.337747+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T23:19:22.339845+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T23:19:22.343466+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:19:22.345295+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:19:22.346932+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_16__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 16 accuracy:  0.9296703296703297\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00221233 0.00219048 0.00219566 0.00220575 0.00219048 0.00219614\n",
      " 0.00219048 0.00219522 0.00219048 0.00219048 0.00219048 0.00223927\n",
      " 0.00222745 0.00219048 0.00224516 0.00219048 0.00219628 0.00219048\n",
      " 0.0022283  0.00219538 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219614 0.00219048 0.00219048 0.00221287\n",
      " 0.00219048 0.00221719 0.00219048 0.00219048 0.00219048 0.00219538\n",
      " 0.00219048 0.00219048 0.00222445 0.00221107 0.0021962  0.00219048\n",
      " 0.00219048 0.00219048 0.00219543 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00222146 0.00219048 0.00221606 0.00223276 0.00219586\n",
      " 0.00219048 0.00219048 0.00219048 0.00220089 0.00219048 0.00220057\n",
      " 0.00219543 0.00219048 0.00226117 0.00219048 0.00222321 0.00219048\n",
      " 0.00219048 0.00222382 0.00222159 0.00219502 0.00219543 0.002196\n",
      " 0.0022112  0.00219048 0.00219555 0.00219048 0.00220642 0.00219048\n",
      " 0.00219502 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00220182 0.00219502 0.00219048 0.00219048 0.0022065\n",
      " 0.00220193 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00221645 0.00221499 0.00219048 0.00226167 0.00219048 0.00219048\n",
      " 0.00219048 0.00219543 0.00219048 0.00219048 0.00219048 0.00219502\n",
      " 0.00219976 0.00219048 0.00219048 0.00219048 0.00219538 0.00219048\n",
      " 0.00219048 0.00219048 0.00223939 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219522 0.00221187 0.00219543 0.00220743 0.00219048\n",
      " 0.00219048 0.0022158  0.00219048 0.00223326 0.00222049 0.00219543\n",
      " 0.00219543 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00220062 0.00219554 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00220662 0.00219048 0.00221247 0.0022183  0.00219048\n",
      " 0.00219048 0.00219614 0.00219048 0.00219976 0.00219048 0.00220484\n",
      " 0.00219048 0.00219048 0.00221745 0.00220202 0.00219048 0.0022728\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00220061 0.00219048 0.00219538 0.00219048 0.00219048 0.00219048\n",
      " 0.00220756 0.00219048 0.00219048 0.00219555 0.00219522 0.00219048\n",
      " 0.0022218  0.00219048 0.00219048 0.00219048 0.00219048 0.0022071\n",
      " 0.00219048 0.00220484 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219554 0.00219048 0.00219502\n",
      " 0.00227789 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219566\n",
      " 0.00219048 0.00219048 0.00219048 0.00222657 0.00219976 0.00219048\n",
      " 0.00220087 0.00219048 0.00219048 0.00219048 0.00222897 0.0022116\n",
      " 0.00219048 0.00219048 0.00222298 0.00220182 0.00222834 0.00219502\n",
      " 0.00220077 0.00220172 0.00219048 0.00219048 0.0022057  0.0021962\n",
      " 0.002211   0.00219048 0.00219586 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00220648 0.00219048 0.00220628 0.00219048\n",
      " 0.00220094 0.00222877 0.00221048 0.00219048 0.00219586 0.00219048\n",
      " 0.00220625 0.00219048 0.00219048 0.00219048 0.00219048 0.00220989\n",
      " 0.00219048 0.00219048 0.00221213 0.00224998 0.00219048 0.00220699\n",
      " 0.00220034 0.00222876 0.00221025 0.00219048 0.00219048 0.00222143\n",
      " 0.00220055 0.00219502 0.00219048 0.00219048 0.00224484 0.00219586\n",
      " 0.00219048 0.00220136 0.00219048 0.00219048 0.00219048 0.00219554\n",
      " 0.00219048 0.00219048 0.0022167  0.00219048 0.00220029 0.00219976\n",
      " 0.00219048 0.00219048 0.00220075 0.00219048 0.00220094 0.00219048\n",
      " 0.00219048 0.0021962  0.00221136 0.00219502 0.00219048 0.00219048\n",
      " 0.00219048 0.00220676 0.00219048 0.00219502 0.00219048 0.00219543\n",
      " 0.00219048 0.00219048 0.00224038 0.00219048 0.0022442  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00220683 0.00219554 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00221203 0.0022006  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219502 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219554 0.00219048 0.00221122 0.00219048\n",
      " 0.00222188 0.00220818 0.00219048 0.00219048 0.00219048 0.00219538\n",
      " 0.00219048 0.0022166  0.00219048 0.00222577 0.00219591 0.00220093\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00220165\n",
      " 0.00219048 0.00219048 0.0022066  0.00222063 0.00219048 0.00222687\n",
      " 0.00224138 0.00220525 0.00219048 0.00219048 0.00219502 0.00220994\n",
      " 0.00220207 0.00223885 0.00219048 0.00225067 0.00219502 0.00219048\n",
      " 0.00219048 0.00219048 0.0022203  0.00219502 0.00219048 0.00221227\n",
      " 0.00219048 0.00220009 0.00221326 0.00219048 0.00222286 0.00220568\n",
      " 0.00219048 0.00219502 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219614\n",
      " 0.00220165 0.00219048 0.00221106 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219586 0.00219048 0.00219048 0.002196   0.00219538\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.0021962  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00224302 0.00220554 0.00219543\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00223429\n",
      " 0.00219048 0.00219048 0.00219586 0.00219048 0.00219554]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0025687711105727555\n",
      "Boosting iter: 18 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 58/20\n",
      "random state: 57\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00221233 0.00219048 0.00219566 0.00220575 0.00219048 0.00219614\n",
      " 0.00219048 0.00219522 0.00219048 0.00219048 0.00219048 0.00223927\n",
      " 0.00222745 0.00219048 0.00224516 0.00219048 0.00219628 0.00219048\n",
      " 0.0022283  0.00219538 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219614 0.00219048 0.00219048 0.00221287\n",
      " 0.00219048 0.00221719 0.00219048 0.00219048 0.00219048 0.00219538\n",
      " 0.00219048 0.00219048 0.00222445 0.00221107 0.0021962  0.00219048\n",
      " 0.00219048 0.00219048 0.00219543 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00222146 0.00219048 0.00221606 0.00223276 0.00219586\n",
      " 0.00219048 0.00219048 0.00219048 0.00220089 0.00219048 0.00220057\n",
      " 0.00219543 0.00219048 0.00226117 0.00219048 0.00222321 0.00219048\n",
      " 0.00219048 0.00222382 0.00222159 0.00219502 0.00219543 0.002196\n",
      " 0.0022112  0.00219048 0.00219555 0.00219048 0.00220642 0.00219048\n",
      " 0.00219502 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00220182 0.00219502 0.00219048 0.00219048 0.0022065\n",
      " 0.00220193 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00221645 0.00221499 0.00219048 0.00226167 0.00219048 0.00219048\n",
      " 0.00219048 0.00219543 0.00219048 0.00219048 0.00219048 0.00219502\n",
      " 0.00219976 0.00219048 0.00219048 0.00219048 0.00219538 0.00219048\n",
      " 0.00219048 0.00219048 0.00223939 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219522 0.00221187 0.00219543 0.00220743 0.00219048\n",
      " 0.00219048 0.0022158  0.00219048 0.00223326 0.00222049 0.00219543\n",
      " 0.00219543 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00220062 0.00219554 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00220662 0.00219048 0.00221247 0.0022183  0.00219048\n",
      " 0.00219048 0.00219614 0.00219048 0.00219976 0.00219048 0.00220484\n",
      " 0.00219048 0.00219048 0.00221745 0.00220202 0.00219048 0.0022728\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00220061 0.00219048 0.00219538 0.00219048 0.00219048 0.00219048\n",
      " 0.00220756 0.00219048 0.00219048 0.00219555 0.00219522 0.00219048\n",
      " 0.0022218  0.00219048 0.00219048 0.00219048 0.00219048 0.0022071\n",
      " 0.00219048 0.00220484 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219554 0.00219048 0.00219502\n",
      " 0.00227789 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219566\n",
      " 0.00219048 0.00219048 0.00219048 0.00222657 0.00219976 0.00219048\n",
      " 0.00220087 0.00219048 0.00219048 0.00219048 0.00222897 0.0022116\n",
      " 0.00219048 0.00219048 0.00222298 0.00220182 0.00222834 0.00219502\n",
      " 0.00220077 0.00220172 0.00219048 0.00219048 0.0022057  0.0021962\n",
      " 0.002211   0.00219048 0.00219586 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00220648 0.00219048 0.00220628 0.00219048\n",
      " 0.00220094 0.00222877 0.00221048 0.00219048 0.00219586 0.00219048\n",
      " 0.00220625 0.00219048 0.00219048 0.00219048 0.00219048 0.00220989\n",
      " 0.00219048 0.00219048 0.00221213 0.00224998 0.00219048 0.00220699\n",
      " 0.00220034 0.00222876 0.00221025 0.00219048 0.00219048 0.00222143\n",
      " 0.00220055 0.00219502 0.00219048 0.00219048 0.00224484 0.00219586\n",
      " 0.00219048 0.00220136 0.00219048 0.00219048 0.00219048 0.00219554\n",
      " 0.00219048 0.00219048 0.0022167  0.00219048 0.00220029 0.00219976\n",
      " 0.00219048 0.00219048 0.00220075 0.00219048 0.00220094 0.00219048\n",
      " 0.00219048 0.0021962  0.00221136 0.00219502 0.00219048 0.00219048\n",
      " 0.00219048 0.00220676 0.00219048 0.00219502 0.00219048 0.00219543\n",
      " 0.00219048 0.00219048 0.00224038 0.00219048 0.0022442  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00220683 0.00219554 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00221203 0.0022006  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219502 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219554 0.00219048 0.00221122 0.00219048\n",
      " 0.00222188 0.00220818 0.00219048 0.00219048 0.00219048 0.00219538\n",
      " 0.00219048 0.0022166  0.00219048 0.00222577 0.00219591 0.00220093\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00220165\n",
      " 0.00219048 0.00219048 0.0022066  0.00222063 0.00219048 0.00222687\n",
      " 0.00224138 0.00220525 0.00219048 0.00219048 0.00219502 0.00220994\n",
      " 0.00220207 0.00223885 0.00219048 0.00225067 0.00219502 0.00219048\n",
      " 0.00219048 0.00219048 0.0022203  0.00219502 0.00219048 0.00221227\n",
      " 0.00219048 0.00220009 0.00221326 0.00219048 0.00222286 0.00220568\n",
      " 0.00219048 0.00219502 0.00219048 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00219614\n",
      " 0.00220165 0.00219048 0.00221106 0.00219048 0.00219048 0.00219048\n",
      " 0.00219048 0.00219586 0.00219048 0.00219048 0.002196   0.00219538\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.0021962  0.00219048\n",
      " 0.00219048 0.00219048 0.00219048 0.00224302 0.00220554 0.00219543\n",
      " 0.00219048 0.00219048 0.00219048 0.00219048 0.00219048 0.00223429\n",
      " 0.00219048 0.00219048 0.00219586 0.00219048 0.00219554]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 360,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 210 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  67 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 266 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  34 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 1499/2000 [02:57<00:59,  8.46it/s]\n",
      "[2023-12-17T23:22:25.586521+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:22:25.588699+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:22:25.590430+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T23:22:25.592499+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T23:22:25.596184+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:22:25.597941+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:22:25.599628+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_17__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 17 accuracy:  0.9362637362637363\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00221194 0.00219011 0.00219528 0.00220537 0.00219011 0.00219576\n",
      " 0.00219011 0.00219484 0.00219011 0.00219011 0.00219011 0.00224487\n",
      " 0.00222706 0.00219011 0.00225077 0.00219011 0.0021959  0.00219011\n",
      " 0.00222792 0.002195   0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219576 0.00219011 0.00219011 0.00221248\n",
      " 0.00219011 0.00221681 0.00219011 0.00219011 0.00219011 0.002195\n",
      " 0.00219011 0.00219011 0.00223001 0.00221069 0.00219582 0.00219011\n",
      " 0.00219011 0.00219011 0.00219505 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00222108 0.00219011 0.00221568 0.00223237 0.00219548\n",
      " 0.00219011 0.00219011 0.00219011 0.00220051 0.00219011 0.00220018\n",
      " 0.00219505 0.00219011 0.00226682 0.00219011 0.00222283 0.00219011\n",
      " 0.00219011 0.00222344 0.0022212  0.00219464 0.00219505 0.00219562\n",
      " 0.00221673 0.00219011 0.00219517 0.00219011 0.00220603 0.00219011\n",
      " 0.00219464 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00220143 0.00219464 0.00219011 0.00219011 0.00220612\n",
      " 0.00220155 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00222199 0.0022146  0.00219011 0.00226732 0.00219011 0.00219011\n",
      " 0.00219011 0.00219505 0.00219011 0.00219011 0.00219011 0.00219464\n",
      " 0.00219938 0.00219011 0.00219011 0.00219011 0.002195   0.00219011\n",
      " 0.00219011 0.00219011 0.002239   0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219484 0.00221149 0.00219505 0.00220705 0.00219011\n",
      " 0.00219011 0.00221542 0.00219011 0.00223884 0.0022201  0.00219505\n",
      " 0.00219505 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00220024 0.00219516 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00220624 0.00219011 0.00221209 0.00222385 0.00219011\n",
      " 0.00219011 0.00219576 0.00219011 0.00219938 0.00219011 0.00220446\n",
      " 0.00219011 0.00219011 0.00221707 0.00220164 0.00219011 0.00227848\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00220023 0.00219011 0.002195   0.00219011 0.00219011 0.00219011\n",
      " 0.00220718 0.00219011 0.00219011 0.00219517 0.00219484 0.00219011\n",
      " 0.00222141 0.00219011 0.00219011 0.00219011 0.00219011 0.00220672\n",
      " 0.00219011 0.00220446 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219516 0.00219011 0.00219464\n",
      " 0.00228359 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219528\n",
      " 0.00219011 0.00219011 0.00219596 0.00223214 0.00219938 0.00219011\n",
      " 0.00220049 0.00219011 0.00219011 0.00219011 0.00222858 0.00221713\n",
      " 0.00219011 0.00219011 0.00222854 0.00220143 0.00222796 0.00219464\n",
      " 0.00220039 0.00220134 0.00219011 0.00219011 0.00220531 0.00219582\n",
      " 0.00221062 0.00219011 0.00219548 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.0022061  0.00219011 0.00220589 0.00219011\n",
      " 0.00220056 0.00223435 0.0022101  0.00219011 0.00219548 0.00219011\n",
      " 0.00220587 0.00219011 0.00219011 0.00219011 0.00219011 0.00220951\n",
      " 0.00219011 0.00219011 0.00221175 0.00225561 0.00219011 0.00220661\n",
      " 0.00219996 0.00223433 0.00220987 0.00219011 0.00219011 0.00222104\n",
      " 0.00220017 0.00219464 0.00219011 0.00219011 0.00225045 0.00219548\n",
      " 0.00219011 0.00220098 0.00219011 0.00219011 0.00219011 0.00219516\n",
      " 0.00219011 0.00219011 0.00221632 0.00219011 0.00219991 0.00219938\n",
      " 0.00219011 0.00219011 0.00220037 0.00219011 0.00220056 0.00219011\n",
      " 0.00219011 0.00219582 0.00221689 0.00219464 0.00219011 0.00219011\n",
      " 0.00219011 0.00221228 0.00219011 0.00219464 0.00219011 0.00219505\n",
      " 0.00219011 0.00219011 0.00224598 0.00219011 0.00224981 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00220645 0.00219516 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00221165 0.00220022 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219464 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00220103 0.00219011 0.00221084 0.00219011\n",
      " 0.00222149 0.0022078  0.00219011 0.00219011 0.00219011 0.002195\n",
      " 0.00219011 0.00221622 0.00219011 0.00222539 0.00219553 0.00220055\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00220127\n",
      " 0.00219011 0.00219011 0.00220622 0.00222025 0.00219011 0.00223244\n",
      " 0.00224699 0.00220487 0.00219011 0.00219011 0.00219464 0.00220956\n",
      " 0.00220168 0.00224445 0.00219011 0.00225028 0.00219464 0.00219011\n",
      " 0.00219011 0.00219011 0.00221992 0.00219464 0.00219011 0.00221188\n",
      " 0.00219011 0.00219971 0.00221288 0.00219011 0.00222247 0.0022053\n",
      " 0.00219011 0.00219464 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219576\n",
      " 0.00220716 0.00219011 0.00221067 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219548 0.00219011 0.00219011 0.00219562 0.002195\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219582 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00224862 0.00220515 0.00219505\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.0022339\n",
      " 0.00219011 0.00219011 0.00219548 0.00219011 0.00219516]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002670849097163872\n",
      "Boosting iter: 19 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 59/20\n",
      "random state: 58\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00221194 0.00219011 0.00219528 0.00220537 0.00219011 0.00219576\n",
      " 0.00219011 0.00219484 0.00219011 0.00219011 0.00219011 0.00224487\n",
      " 0.00222706 0.00219011 0.00225077 0.00219011 0.0021959  0.00219011\n",
      " 0.00222792 0.002195   0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219576 0.00219011 0.00219011 0.00221248\n",
      " 0.00219011 0.00221681 0.00219011 0.00219011 0.00219011 0.002195\n",
      " 0.00219011 0.00219011 0.00223001 0.00221069 0.00219582 0.00219011\n",
      " 0.00219011 0.00219011 0.00219505 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00222108 0.00219011 0.00221568 0.00223237 0.00219548\n",
      " 0.00219011 0.00219011 0.00219011 0.00220051 0.00219011 0.00220018\n",
      " 0.00219505 0.00219011 0.00226682 0.00219011 0.00222283 0.00219011\n",
      " 0.00219011 0.00222344 0.0022212  0.00219464 0.00219505 0.00219562\n",
      " 0.00221673 0.00219011 0.00219517 0.00219011 0.00220603 0.00219011\n",
      " 0.00219464 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00220143 0.00219464 0.00219011 0.00219011 0.00220612\n",
      " 0.00220155 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00222199 0.0022146  0.00219011 0.00226732 0.00219011 0.00219011\n",
      " 0.00219011 0.00219505 0.00219011 0.00219011 0.00219011 0.00219464\n",
      " 0.00219938 0.00219011 0.00219011 0.00219011 0.002195   0.00219011\n",
      " 0.00219011 0.00219011 0.002239   0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219484 0.00221149 0.00219505 0.00220705 0.00219011\n",
      " 0.00219011 0.00221542 0.00219011 0.00223884 0.0022201  0.00219505\n",
      " 0.00219505 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00220024 0.00219516 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00220624 0.00219011 0.00221209 0.00222385 0.00219011\n",
      " 0.00219011 0.00219576 0.00219011 0.00219938 0.00219011 0.00220446\n",
      " 0.00219011 0.00219011 0.00221707 0.00220164 0.00219011 0.00227848\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00220023 0.00219011 0.002195   0.00219011 0.00219011 0.00219011\n",
      " 0.00220718 0.00219011 0.00219011 0.00219517 0.00219484 0.00219011\n",
      " 0.00222141 0.00219011 0.00219011 0.00219011 0.00219011 0.00220672\n",
      " 0.00219011 0.00220446 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219516 0.00219011 0.00219464\n",
      " 0.00228359 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219528\n",
      " 0.00219011 0.00219011 0.00219596 0.00223214 0.00219938 0.00219011\n",
      " 0.00220049 0.00219011 0.00219011 0.00219011 0.00222858 0.00221713\n",
      " 0.00219011 0.00219011 0.00222854 0.00220143 0.00222796 0.00219464\n",
      " 0.00220039 0.00220134 0.00219011 0.00219011 0.00220531 0.00219582\n",
      " 0.00221062 0.00219011 0.00219548 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.0022061  0.00219011 0.00220589 0.00219011\n",
      " 0.00220056 0.00223435 0.0022101  0.00219011 0.00219548 0.00219011\n",
      " 0.00220587 0.00219011 0.00219011 0.00219011 0.00219011 0.00220951\n",
      " 0.00219011 0.00219011 0.00221175 0.00225561 0.00219011 0.00220661\n",
      " 0.00219996 0.00223433 0.00220987 0.00219011 0.00219011 0.00222104\n",
      " 0.00220017 0.00219464 0.00219011 0.00219011 0.00225045 0.00219548\n",
      " 0.00219011 0.00220098 0.00219011 0.00219011 0.00219011 0.00219516\n",
      " 0.00219011 0.00219011 0.00221632 0.00219011 0.00219991 0.00219938\n",
      " 0.00219011 0.00219011 0.00220037 0.00219011 0.00220056 0.00219011\n",
      " 0.00219011 0.00219582 0.00221689 0.00219464 0.00219011 0.00219011\n",
      " 0.00219011 0.00221228 0.00219011 0.00219464 0.00219011 0.00219505\n",
      " 0.00219011 0.00219011 0.00224598 0.00219011 0.00224981 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00220645 0.00219516 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00221165 0.00220022 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219464 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00220103 0.00219011 0.00221084 0.00219011\n",
      " 0.00222149 0.0022078  0.00219011 0.00219011 0.00219011 0.002195\n",
      " 0.00219011 0.00221622 0.00219011 0.00222539 0.00219553 0.00220055\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00220127\n",
      " 0.00219011 0.00219011 0.00220622 0.00222025 0.00219011 0.00223244\n",
      " 0.00224699 0.00220487 0.00219011 0.00219011 0.00219464 0.00220956\n",
      " 0.00220168 0.00224445 0.00219011 0.00225028 0.00219464 0.00219011\n",
      " 0.00219011 0.00219011 0.00221992 0.00219464 0.00219011 0.00221188\n",
      " 0.00219011 0.00219971 0.00221288 0.00219011 0.00222247 0.0022053\n",
      " 0.00219011 0.00219464 0.00219011 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.00219576\n",
      " 0.00220716 0.00219011 0.00221067 0.00219011 0.00219011 0.00219011\n",
      " 0.00219011 0.00219548 0.00219011 0.00219011 0.00219562 0.002195\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219582 0.00219011\n",
      " 0.00219011 0.00219011 0.00219011 0.00224862 0.00220515 0.00219505\n",
      " 0.00219011 0.00219011 0.00219011 0.00219011 0.00219011 0.0022339\n",
      " 0.00219011 0.00219011 0.00219548 0.00219011 0.00219516]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 360,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 245,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 271, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 210 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  34 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True, False,  True, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                               | 1399/2000 [02:42<01:09,  8.62it/s]\n",
      "[2023-12-17T23:25:13.889782+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:25:13.891929+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2023-12-17T23:25:13.893632+0000][31803][CRITICAL] module plugin_great load failed\n",
      "[2023-12-17T23:25:13.895736+0000][31803][CRITICAL] module disabled: /home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2023-12-17T23:25:13.899401+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:25:13.901124+0000][31803][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2023-12-17T23:25:13.902809+0000][31803][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_18__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 18 accuracy:  0.9252747252747253\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00221706 0.00218969 0.00219486 0.00220495 0.00218969 0.00219535\n",
      " 0.00218969 0.00219442 0.00218969 0.00218969 0.00218969 0.00225007\n",
      " 0.00223222 0.00218969 0.00225598 0.00218969 0.00219549 0.00218969\n",
      " 0.00223307 0.00219458 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00219535 0.00218969 0.00218969 0.00221206\n",
      " 0.00218969 0.00221639 0.00218969 0.00218969 0.00218969 0.00219458\n",
      " 0.00218969 0.00218969 0.00222959 0.00221027 0.0021954  0.00218969\n",
      " 0.00218969 0.00218969 0.00219464 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00222066 0.00218969 0.00221526 0.00223195 0.00219507\n",
      " 0.00218969 0.00218969 0.00218969 0.00220009 0.00218969 0.00219977\n",
      " 0.00219464 0.00218969 0.00227207 0.00218969 0.00222797 0.00218969\n",
      " 0.00218969 0.00222858 0.00222078 0.00219423 0.00219464 0.00219521\n",
      " 0.00221631 0.00218969 0.00219476 0.00218969 0.00221114 0.00218969\n",
      " 0.00219423 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00220102 0.00219423 0.00218969 0.00218969 0.00221122\n",
      " 0.00220113 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00222157 0.00221973 0.00218969 0.00227257 0.00218969 0.00218969\n",
      " 0.00218969 0.00219464 0.00218969 0.00218969 0.00218969 0.00219423\n",
      " 0.00219897 0.00218969 0.00218969 0.00218969 0.00219458 0.00218969\n",
      " 0.00218969 0.00218969 0.00223857 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00219442 0.00221107 0.00219464 0.00220663 0.00218969\n",
      " 0.00218969 0.002215   0.00218969 0.00224403 0.00221968 0.00219464\n",
      " 0.00219464 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00219982 0.00219474 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00220582 0.00218969 0.00221167 0.00222342 0.00218969\n",
      " 0.00218969 0.00219535 0.00218969 0.00219897 0.00218969 0.00220404\n",
      " 0.00218969 0.00218969 0.0022222  0.00220122 0.00218969 0.00228376\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00220532 0.00218969 0.00219458 0.00218969 0.00218969 0.00218969\n",
      " 0.00220676 0.00218969 0.00218969 0.00219476 0.00219442 0.00218969\n",
      " 0.00222099 0.00218969 0.00218969 0.00218969 0.00218969 0.0022063\n",
      " 0.00218969 0.00220404 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00219474 0.00218969 0.00219423\n",
      " 0.00228887 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00219486\n",
      " 0.00218969 0.00218969 0.00219555 0.00223171 0.00219897 0.00218969\n",
      " 0.00220007 0.00218969 0.00218969 0.00218969 0.00223374 0.00221671\n",
      " 0.00218969 0.00218969 0.0022337  0.00220102 0.00222754 0.00219423\n",
      " 0.00219997 0.00220092 0.00218969 0.00218969 0.0022049  0.0021954\n",
      " 0.0022102  0.00218969 0.00219507 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00220568 0.00218969 0.00220548 0.00218969\n",
      " 0.00220015 0.00223952 0.00220968 0.00218969 0.00219507 0.00218969\n",
      " 0.00220545 0.00218969 0.00218969 0.00218969 0.00218969 0.00220909\n",
      " 0.00218969 0.00218969 0.00221687 0.00225518 0.00218969 0.00220619\n",
      " 0.00219954 0.00223391 0.00220945 0.00218969 0.00218969 0.00222618\n",
      " 0.00219975 0.00219423 0.00218969 0.00218969 0.00225003 0.00219507\n",
      " 0.00218969 0.00220056 0.00218969 0.00218969 0.00218969 0.00219474\n",
      " 0.00219518 0.00218969 0.0022159  0.00218969 0.0021995  0.00219897\n",
      " 0.00218969 0.00218969 0.00219995 0.00218969 0.00220566 0.00218969\n",
      " 0.00218969 0.0021954  0.00222202 0.00219423 0.00218969 0.00218969\n",
      " 0.00218969 0.00221186 0.00218969 0.00219423 0.00218969 0.00219464\n",
      " 0.00218969 0.00218969 0.00225118 0.00218969 0.00225502 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00220603 0.00219474 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00221677 0.0021998  0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00219423 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00220061 0.00218969 0.00221042 0.00218969\n",
      " 0.00222107 0.00220738 0.00218969 0.00218969 0.00218969 0.00219458\n",
      " 0.00218969 0.0022158  0.00218969 0.00223054 0.00219511 0.00220013\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00220085\n",
      " 0.00218969 0.00219518 0.0022058  0.00221983 0.00218969 0.00223761\n",
      " 0.00224656 0.00220445 0.00218969 0.00218969 0.00219423 0.00220914\n",
      " 0.00220678 0.00224402 0.00218969 0.00224985 0.00219423 0.00218969\n",
      " 0.00218969 0.00218969 0.0022195  0.00219423 0.00218969 0.00221146\n",
      " 0.00218969 0.00219929 0.00221246 0.00219518 0.00222205 0.00220488\n",
      " 0.00218969 0.00219423 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00219535\n",
      " 0.00220674 0.00218969 0.00221025 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00219507 0.00218969 0.00218969 0.00219521 0.00219458\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.0021954  0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.0022482  0.00220474 0.00219464\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00223907\n",
      " 0.00218969 0.00218969 0.00219507 0.00218969 0.00219474]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.0025022473149690356\n",
      "Boosting iter: 20 / 20\n",
      "Boost generative model training and synthetic data generation\n",
      "Training model 60/20\n",
      "random state: 59\n",
      "self._plugins:  {'uniform_sampler': <class 'synthcity.plugins.generic.plugin_uniform_sampler.UniformSamplerPlugin'>, 'bayesian_network': <class 'synthcity.plugins.generic.plugin_bayesian_network.BayesianNetworkPlugin'>, 'ctgan': <class 'synthcity.plugins.generic.plugin_ctgan.CTGANPlugin'>, 'marginal_distributions': <class 'synthcity.plugins.generic.plugin_marginal_distributions.MarginalDistributionPlugin'>, 'dummy_sampler': <class 'synthcity.plugins.generic.plugin_dummy_sampler.DummySamplerPlugin'>, 'arf': <class 'synthcity.plugins.generic.plugin_arf.ARFPlugin'>, 'ddpm': <class 'synthcity.plugins.generic.plugin_ddpm.TabDDPMPlugin'>, 'rtvae': <class 'synthcity.plugins.generic.plugin_rtvae.RTVAEPlugin'>, 'nflow': <class 'synthcity.plugins.generic.plugin_nflow.NormalizingFlowsPlugin'>, 'tvae': <class 'synthcity.plugins.generic.plugin_tvae.TVAEPlugin'>}\n",
      "self._available_plugins:  {'uniform_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_uniform_sampler.py', 'bayesian_network': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_bayesian_network.py', 'ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ctgan.py', 'marginal_distributions': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_marginal_distributions.py', 'dummy_sampler': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_dummy_sampler.py', 'arf': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_arf.py', 'ddpm': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_ddpm.py', 'rtvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_rtvae.py', 'nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_nflow.py', 'tvae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/generic/plugin_tvae.py', 'adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_adsgan.py', 'dpgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_dpgan.py', 'pategan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_pategan.py', 'aim': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_aim.py', 'privbayes': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/privacy/plugin_privbayes.py', 'survae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survae.py', 'survival_gan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_gan.py', 'survival_nflow': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_nflow.py', 'survival_ctgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/survival_analysis/plugin_survival_ctgan.py', 'timevae': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timevae.py', 'timegan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_timegan.py', 'fflows': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/time_series/plugin_fflows.py', 'radialgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/domain_adaptation/plugin_radialgan.py', 'image_adsgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_adsgan.py', 'image_cgan': '/home/JacquelineYau/deep_generative_ensemble/synthcity/src/synthcity/plugins/images/plugin_image_cgan.py'}\n",
      "*******************Training CTGAN plugin**************************\n",
      "Training with weights\n",
      "data_weights passed into ctgan:  [0.00221706 0.00218969 0.00219486 0.00220495 0.00218969 0.00219535\n",
      " 0.00218969 0.00219442 0.00218969 0.00218969 0.00218969 0.00225007\n",
      " 0.00223222 0.00218969 0.00225598 0.00218969 0.00219549 0.00218969\n",
      " 0.00223307 0.00219458 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00219535 0.00218969 0.00218969 0.00221206\n",
      " 0.00218969 0.00221639 0.00218969 0.00218969 0.00218969 0.00219458\n",
      " 0.00218969 0.00218969 0.00222959 0.00221027 0.0021954  0.00218969\n",
      " 0.00218969 0.00218969 0.00219464 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00222066 0.00218969 0.00221526 0.00223195 0.00219507\n",
      " 0.00218969 0.00218969 0.00218969 0.00220009 0.00218969 0.00219977\n",
      " 0.00219464 0.00218969 0.00227207 0.00218969 0.00222797 0.00218969\n",
      " 0.00218969 0.00222858 0.00222078 0.00219423 0.00219464 0.00219521\n",
      " 0.00221631 0.00218969 0.00219476 0.00218969 0.00221114 0.00218969\n",
      " 0.00219423 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00220102 0.00219423 0.00218969 0.00218969 0.00221122\n",
      " 0.00220113 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00222157 0.00221973 0.00218969 0.00227257 0.00218969 0.00218969\n",
      " 0.00218969 0.00219464 0.00218969 0.00218969 0.00218969 0.00219423\n",
      " 0.00219897 0.00218969 0.00218969 0.00218969 0.00219458 0.00218969\n",
      " 0.00218969 0.00218969 0.00223857 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00219442 0.00221107 0.00219464 0.00220663 0.00218969\n",
      " 0.00218969 0.002215   0.00218969 0.00224403 0.00221968 0.00219464\n",
      " 0.00219464 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00219982 0.00219474 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00220582 0.00218969 0.00221167 0.00222342 0.00218969\n",
      " 0.00218969 0.00219535 0.00218969 0.00219897 0.00218969 0.00220404\n",
      " 0.00218969 0.00218969 0.0022222  0.00220122 0.00218969 0.00228376\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00220532 0.00218969 0.00219458 0.00218969 0.00218969 0.00218969\n",
      " 0.00220676 0.00218969 0.00218969 0.00219476 0.00219442 0.00218969\n",
      " 0.00222099 0.00218969 0.00218969 0.00218969 0.00218969 0.0022063\n",
      " 0.00218969 0.00220404 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00219474 0.00218969 0.00219423\n",
      " 0.00228887 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00219486\n",
      " 0.00218969 0.00218969 0.00219555 0.00223171 0.00219897 0.00218969\n",
      " 0.00220007 0.00218969 0.00218969 0.00218969 0.00223374 0.00221671\n",
      " 0.00218969 0.00218969 0.0022337  0.00220102 0.00222754 0.00219423\n",
      " 0.00219997 0.00220092 0.00218969 0.00218969 0.0022049  0.0021954\n",
      " 0.0022102  0.00218969 0.00219507 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00220568 0.00218969 0.00220548 0.00218969\n",
      " 0.00220015 0.00223952 0.00220968 0.00218969 0.00219507 0.00218969\n",
      " 0.00220545 0.00218969 0.00218969 0.00218969 0.00218969 0.00220909\n",
      " 0.00218969 0.00218969 0.00221687 0.00225518 0.00218969 0.00220619\n",
      " 0.00219954 0.00223391 0.00220945 0.00218969 0.00218969 0.00222618\n",
      " 0.00219975 0.00219423 0.00218969 0.00218969 0.00225003 0.00219507\n",
      " 0.00218969 0.00220056 0.00218969 0.00218969 0.00218969 0.00219474\n",
      " 0.00219518 0.00218969 0.0022159  0.00218969 0.0021995  0.00219897\n",
      " 0.00218969 0.00218969 0.00219995 0.00218969 0.00220566 0.00218969\n",
      " 0.00218969 0.0021954  0.00222202 0.00219423 0.00218969 0.00218969\n",
      " 0.00218969 0.00221186 0.00218969 0.00219423 0.00218969 0.00219464\n",
      " 0.00218969 0.00218969 0.00225118 0.00218969 0.00225502 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00220603 0.00219474 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00221677 0.0021998  0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00219423 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00220061 0.00218969 0.00221042 0.00218969\n",
      " 0.00222107 0.00220738 0.00218969 0.00218969 0.00218969 0.00219458\n",
      " 0.00218969 0.0022158  0.00218969 0.00223054 0.00219511 0.00220013\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00220085\n",
      " 0.00218969 0.00219518 0.0022058  0.00221983 0.00218969 0.00223761\n",
      " 0.00224656 0.00220445 0.00218969 0.00218969 0.00219423 0.00220914\n",
      " 0.00220678 0.00224402 0.00218969 0.00224985 0.00219423 0.00218969\n",
      " 0.00218969 0.00218969 0.0022195  0.00219423 0.00218969 0.00221146\n",
      " 0.00218969 0.00219929 0.00221246 0.00219518 0.00222205 0.00220488\n",
      " 0.00218969 0.00219423 0.00218969 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00219535\n",
      " 0.00220674 0.00218969 0.00221025 0.00218969 0.00218969 0.00218969\n",
      " 0.00218969 0.00219507 0.00218969 0.00218969 0.00219521 0.00219458\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.0021954  0.00218969\n",
      " 0.00218969 0.00218969 0.00218969 0.0022482  0.00220474 0.00219464\n",
      " 0.00218969 0.00218969 0.00218969 0.00218969 0.00218969 0.00223907\n",
      " 0.00218969 0.00218969 0.00219507 0.00218969 0.00219474]\n",
      "using dataloader sampler\n",
      "Full X shape: torch.Size([455, 332]), X_train shape: torch.Size([364, 332]), X_val shape: torch.Size([91, 332])\n",
      "Sampling with data weights!\n",
      "train indices:  tensor([441, 322, 209, 418, 293, 359,  81, 159, 264, 131, 206,  80, 161, 282,\n",
      "        219, 200, 185,  93, 302, 357,  95, 307,  49, 238, 102, 254, 267, 310,\n",
      "        339, 103, 368, 286,  89,  69, 219, 417, 260, 218, 362, 167, 123,  18,\n",
      "        340, 155, 244, 212, 392,  18, 453, 400, 347, 116,  86, 449, 354, 164,\n",
      "        257, 337,   2, 265, 259,  21,  74, 454, 273,  67, 179, 392,  50, 368,\n",
      "        359, 362, 185, 329,   5, 116,  85,  73, 225,  70, 104, 186, 170,  83,\n",
      "        181, 235, 278, 177, 244,  90, 195, 389, 419,  17, 320,  79,  81,  81,\n",
      "        304, 280,  76, 444, 308, 255, 203, 441, 228, 442, 396, 104, 324, 202,\n",
      "        242,  68, 299,  19, 227, 203, 361, 138, 145, 324,  26, 405,  25, 406,\n",
      "        139, 284,  16,  35, 316,  53, 205, 401, 131,  48,  99, 343, 230, 247,\n",
      "         57, 348, 296, 299,  38, 256, 120,  45, 348, 290,  31, 419, 357, 302,\n",
      "        265, 327, 177, 235, 414, 297, 152, 389, 350, 159, 394, 311, 450, 106,\n",
      "          9, 226,  37, 129, 269, 424, 224, 272, 127, 323, 291,  93, 133, 358,\n",
      "         74,  93, 122, 183, 444,  61, 131, 392, 253, 345, 147,  33, 273, 209,\n",
      "        339, 419, 383, 311, 253,  50, 289, 376, 246, 330, 180,  77, 415, 174,\n",
      "         97,  93, 447, 129, 133,  72, 179, 151, 397, 449,  70,  85,  97, 181,\n",
      "         82, 144, 444, 163,  97, 360,  32, 392, 125, 253, 408, 343, 136, 183,\n",
      "        265, 334,  80, 320, 269, 216,  58,  59, 447, 162, 294, 245, 134,   2,\n",
      "        175, 119, 372, 386, 404,   3,  20, 144,  98, 182, 294, 307, 450, 451,\n",
      "        447, 440, 446, 257, 414,  37, 250, 134, 238,  93, 428, 348,  71, 246,\n",
      "         48, 289, 187,  49,  61, 178, 357, 319, 299, 291, 391, 169, 317, 367,\n",
      "         82, 182, 175, 349, 245, 359, 284, 113, 127,  43,  13, 280, 152, 190,\n",
      "          7, 183,  67, 430, 391, 230, 161, 233, 120, 223, 186, 448, 287, 125,\n",
      "        185, 306, 372,  79, 163, 291, 294,  41, 453, 428, 193, 204, 349,  59,\n",
      "        135, 259, 183, 336, 230, 258, 357, 166, 446, 276, 261, 157, 367, 418,\n",
      "         58, 192, 211, 234,  41, 223, 235, 412,  90, 327, 111, 163, 325, 343])\n",
      "np version train indices:  [249 325 274 247 192 293 199 405 438 174 360 240 258 421  32  39   9 378\n",
      " 354 395 445 363 210 355  53 291  65 429 237 188 120 352 207 258   8 281\n",
      " 278 280 429 310 163 198 317  27 303 305  95  58 143 165 259 199 449  46\n",
      "  95  73 297 115 212 111  72  50 298  62  89 167 373  44 381  43 444 213\n",
      " 444 275 336  17 128  54 134  54 144 188  29 315 257 120 238  42 262 422\n",
      " 144 303  59 325 131  83 266   9 377   2 308 122 334 437 113 262 269 260\n",
      " 101 433 203 385 318 135 370 180 400 264 401 315 329 228 435 292 192 275\n",
      "   8 137 300 131 281 195  61 135 259 268 261 297 296 196 407 167 198 405\n",
      " 366 320  45 418 324 454  68 394  73 280  56 385 367 258 185  31 317 206\n",
      " 328 394 443 389   5 163 332  78 237  24  90   8 361 101 157 422 320  14\n",
      "  74 282 262 108 425 279 243 268 332 141 181  95  84 429 336 223 103 115\n",
      "  26 197 141 316 171  81  11  30 309 206 244 407 450  98 301 119   9 345\n",
      " 145 174 267 378 286 397 124 363  84 433 312  98 431 332 115  97 235  11\n",
      "  94 193 170 210 126 267 393  53 235  60 326 180 257  83  65 222 161 427\n",
      " 348 340 411  37 251 265 437 132 109  45   7 422 304 357 128 266  29 220\n",
      " 444 398 153 437 105 431 428 363 286 397 133 386 281   6 157  67 446 217\n",
      " 226 290 167  62 374  86 232 102  44 392 442 437 412 352 151  36 185 105\n",
      "  60  24 330   5 350  66  36  40 305 111 191 253 391 330 122  59  25 137\n",
      " 119 207 310 316 128 172  82 358  25 317 354 353 118 170 267 124 168  89\n",
      " 209  20 363  34 236 139 262 436 293  16 195 232 243 310 126  58 178 435\n",
      "  85 411 247 207]\n",
      "val indices:  tensor([ True,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True, False, False, False,  True, False,  True, False, False,  True,\n",
      "         True, False,  True, False,  True, False,  True,  True, False, False,\n",
      "        False,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False,  True,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True, False,  True,  True, False,  True,  True, False,\n",
      "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True,  True, False, False,  True, False,  True,  True,\n",
      "         True, False, False,  True,  True, False,  True, False,  True, False,\n",
      "         True, False, False, False, False,  True, False, False,  True, False,\n",
      "        False,  True,  True,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False,  True, False,  True,  True,  True,  True,\n",
      "        False,  True, False, False, False, False, False,  True,  True, False,\n",
      "         True, False, False,  True,  True,  True, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False,  True,  True, False, False, False,  True,  True, False,  True,\n",
      "         True,  True, False,  True, False, False, False, False,  True,  True,\n",
      "        False,  True,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True, False,  True, False,\n",
      "         True,  True, False, False,  True,  True, False,  True, False,  True,\n",
      "        False,  True, False,  True, False,  True, False, False,  True, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "         True,  True, False,  True, False,  True, False, False, False,  True,\n",
      "        False, False,  True,  True,  True,  True, False, False,  True, False,\n",
      "        False,  True, False, False, False, False,  True, False,  True, False,\n",
      "        False,  True,  True,  True, False,  True, False, False,  True, False,\n",
      "        False,  True,  True, False,  True, False,  True, False, False, False,\n",
      "        False,  True,  True,  True, False,  True,  True, False, False, False,\n",
      "        False, False, False,  True,  True,  True,  True, False, False,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True, False,  True,  True, False,\n",
      "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
      "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False,  True, False,  True, False, False, False, False,\n",
      "        False, False,  True, False, False])\n",
      "X_train after sampling: torch.Size([364, 332]) and X_val: torch.Size([213, 332])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████████████████████████████████████                                                                                       | 899/2000 [01:57<02:24,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_DGE_19__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (455,)\n",
      "Boosting iter 19 accuracy:  0.9340659340659341\n",
      "boost with SAMME\n",
      "normalized data_weights:  [0.00222252 0.0021893  0.00219448 0.00220456 0.0021893  0.00219496\n",
      " 0.0021893  0.00219403 0.0021893  0.0021893  0.0021893  0.0022556\n",
      " 0.00223182 0.0021893  0.00226153 0.0021893  0.0021951  0.0021893\n",
      " 0.00223268 0.00219419 0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.00220075 0.0021893  0.0021893  0.00221167\n",
      " 0.0021893  0.002216   0.0021893  0.0021893  0.0021893  0.00219419\n",
      " 0.0021893  0.0021893  0.00223507 0.00220988 0.00219501 0.0021893\n",
      " 0.0021893  0.0021893  0.00219425 0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.00222027 0.0021893  0.00221487 0.00223156 0.00219468\n",
      " 0.0021893  0.0021893  0.0021893  0.0021997  0.0021893  0.00219938\n",
      " 0.00219425 0.0021893  0.00227766 0.0021893  0.00222758 0.0021893\n",
      " 0.0021893  0.00222819 0.00222039 0.00219384 0.00219425 0.00219482\n",
      " 0.00222176 0.0021893  0.00219437 0.0021893  0.00221658 0.0021893\n",
      " 0.00219384 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.00220063 0.00219384 0.0021893  0.0021893  0.00221083\n",
      " 0.00220074 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.00222118 0.00221934 0.0021893  0.00227816 0.0021893  0.0021893\n",
      " 0.0021893  0.00219425 0.0021893  0.0021893  0.0021893  0.00219962\n",
      " 0.00219858 0.0021893  0.0021893  0.0021893  0.00219419 0.0021893\n",
      " 0.0021893  0.0021893  0.00223818 0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.00219403 0.00221068 0.00219425 0.00220624 0.0021893\n",
      " 0.0021893  0.0022146  0.0021893  0.00224955 0.00221929 0.00219425\n",
      " 0.00219425 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.00219943 0.00220014 0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.00220543 0.0021893  0.00221128 0.00222889 0.0021893\n",
      " 0.0021893  0.00219496 0.0021893  0.00219858 0.0021893  0.00220365\n",
      " 0.0021893  0.0021893  0.00222181 0.00220083 0.0021893  0.00228937\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.00220493 0.0021893  0.00219419 0.0021893  0.0021893  0.0021893\n",
      " 0.00220637 0.0021893  0.0021893  0.00219437 0.00219403 0.0021893\n",
      " 0.0022206  0.0021893  0.0021893  0.0021893  0.0021893  0.00220591\n",
      " 0.0021893  0.00220946 0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.00219435 0.0021893  0.00219384\n",
      " 0.0022945  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.00219448\n",
      " 0.0021893  0.0021893  0.00219516 0.00223132 0.00219858 0.0021893\n",
      " 0.00219968 0.0021893  0.0021893  0.0021893  0.00223923 0.00221632\n",
      " 0.0021893  0.0021893  0.0022333  0.00220063 0.00222714 0.00219384\n",
      " 0.00219958 0.00220054 0.0021893  0.0021893  0.00220451 0.00219501\n",
      " 0.00220981 0.0021893  0.00219468 0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0022111  0.0021893  0.00220509 0.0021893\n",
      " 0.00219976 0.00224503 0.00220929 0.0021893  0.00219468 0.0021893\n",
      " 0.00221088 0.0021893  0.0021893  0.0021893  0.0021893  0.0022087\n",
      " 0.0021893  0.0021893  0.00221648 0.00226072 0.0021893  0.0022058\n",
      " 0.00219915 0.00223352 0.00220906 0.0021893  0.0021893  0.00222579\n",
      " 0.00219937 0.00219384 0.0021893  0.0021893  0.00225556 0.00219468\n",
      " 0.0021893  0.00220018 0.0021893  0.0021893  0.0021893  0.00219435\n",
      " 0.00219479 0.0021893  0.0022155  0.0021893  0.00219911 0.00219858\n",
      " 0.0021893  0.0021893  0.00219956 0.0021893  0.00220527 0.0021893\n",
      " 0.0021893  0.00219501 0.00222163 0.00219384 0.0021893  0.0021893\n",
      " 0.0021893  0.00221147 0.0021893  0.00219384 0.0021893  0.00219425\n",
      " 0.0021893  0.0021893  0.00225672 0.0021893  0.00226057 0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.00220564 0.00219435 0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.00222222 0.00219942 0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.00219384 0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.00220022 0.0021893  0.00221003 0.0021893\n",
      " 0.00222068 0.00220699 0.0021893  0.0021893  0.0021893  0.00219419\n",
      " 0.0021893  0.0022154  0.0021893  0.00223602 0.00219473 0.00219974\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.00220046\n",
      " 0.0021893  0.00219479 0.00220541 0.00221944 0.0021893  0.00224311\n",
      " 0.00224616 0.00220987 0.0021893  0.0021893  0.00219384 0.00220875\n",
      " 0.00220639 0.00224954 0.0021893  0.00224945 0.00219384 0.0021893\n",
      " 0.0021893  0.0021893  0.00221911 0.00219384 0.0021893  0.00221107\n",
      " 0.0021893  0.0021989  0.00221207 0.00219479 0.00222166 0.0022045\n",
      " 0.0021893  0.00219384 0.0021893  0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.00219496\n",
      " 0.00220635 0.0021893  0.00220986 0.0021893  0.0021893  0.0021893\n",
      " 0.0021893  0.00219468 0.0021893  0.0021893  0.00219482 0.00219419\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.00219501 0.0021893\n",
      " 0.0021893  0.0021893  0.0021893  0.0022478  0.00220435 0.00219425\n",
      " 0.0021893  0.0021893  0.0021893  0.0021893  0.0021893  0.00224458\n",
      " 0.0021893  0.0021893  0.00219468 0.0021893  0.00219435]\n",
      "are all weights equal?:  0\n",
      "estimator weight:  0.002633369102196049\n",
      "Finished run 2 / 3\n",
      "Start final evaluation...\n",
      "run:  0\n",
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__1.pkl\n",
      "Train model in aggregate\n",
      "Train model 2/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__2.pkl\n",
      "Train model in aggregate\n",
      "Train model 3/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__3.pkl\n",
      "Train model in aggregate\n",
      "Train model 4/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__4.pkl\n",
      "Train model in aggregate\n",
      "Train model 5/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__5.pkl\n",
      "Train model in aggregate\n",
      "Train model 6/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__6.pkl\n",
      "Train model in aggregate\n",
      "Train model 7/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__7.pkl\n",
      "Train model in aggregate\n",
      "Train model 8/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__8.pkl\n",
      "Train model in aggregate\n",
      "Train model 9/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__9.pkl\n",
      "Train model in aggregate\n",
      "Train model 10/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__10.pkl\n",
      "Train model in aggregate\n",
      "Train model 11/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__11.pkl\n",
      "Train model in aggregate\n",
      "Train model 12/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__12.pkl\n",
      "Train model in aggregate\n",
      "Train model 13/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__13.pkl\n",
      "Train model in aggregate\n",
      "Train model 14/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__14.pkl\n",
      "Train model in aggregate\n",
      "Train model 15/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__15.pkl\n",
      "Train model in aggregate\n",
      "Train model 16/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__16.pkl\n",
      "Train model in aggregate\n",
      "Train model 17/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__17.pkl\n",
      "Train model in aggregate\n",
      "Train model 18/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__18.pkl\n",
      "Train model in aggregate\n",
      "Train model 19/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_0__19.pkl\n",
      "Train model in aggregate\n",
      "Train model 20/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__1.pkl\n",
      "Train model in aggregate\n",
      "Train model 2/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__2.pkl\n",
      "Train model in aggregate\n",
      "Train model 3/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__3.pkl\n",
      "Train model in aggregate\n",
      "Train model 4/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__4.pkl\n",
      "Train model in aggregate\n",
      "Train model 5/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__5.pkl\n",
      "Train model in aggregate\n",
      "Train model 6/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__6.pkl\n",
      "Train model in aggregate\n",
      "Train model 7/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__7.pkl\n",
      "Train model in aggregate\n",
      "Train model 8/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__8.pkl\n",
      "Train model in aggregate\n",
      "Train model 9/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__9.pkl\n",
      "Train model in aggregate\n",
      "Train model 10/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__10.pkl\n",
      "Train model in aggregate\n",
      "Train model 11/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__11.pkl\n",
      "Train model in aggregate\n",
      "Train model 12/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__12.pkl\n",
      "Train model in aggregate\n",
      "Train model 13/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__13.pkl\n",
      "Train model in aggregate\n",
      "Train model 14/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__14.pkl\n",
      "Train model in aggregate\n",
      "Train model 15/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__15.pkl\n",
      "Train model in aggregate\n",
      "Train model 16/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__16.pkl\n",
      "Train model in aggregate\n",
      "Train model 17/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__17.pkl\n",
      "Train model in aggregate\n",
      "Train model 18/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__18.pkl\n",
      "Train model in aggregate\n",
      "Train model 19/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m0__19.pkl\n",
      "Train model in aggregate\n",
      "Train model 20/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Test accuracy for individual downstream model 0 / 20: 0.9210526315789473\n",
      "Test accuracy for individual downstream model 1 / 20: 0.8508771929824561\n",
      "Test accuracy for individual downstream model 2 / 20: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 3 / 20: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 4 / 20: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 5 / 20: 0.9035087719298246\n",
      "Test accuracy for individual downstream model 6 / 20: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 7 / 20: 0.9649122807017544\n",
      "Test accuracy for individual downstream model 8 / 20: 0.8947368421052632\n",
      "Test accuracy for individual downstream model 9 / 20: 0.9298245614035088\n",
      "Test accuracy for individual downstream model 10 / 20: 0.8596491228070176\n",
      "Test accuracy for individual downstream model 11 / 20: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 12 / 20: 0.9210526315789473\n",
      "Test accuracy for individual downstream model 13 / 20: 0.9035087719298246\n",
      "Test accuracy for individual downstream model 14 / 20: 0.9210526315789473\n",
      "Test accuracy for individual downstream model 15 / 20: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 16 / 20: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 17 / 20: 0.956140350877193\n",
      "Test accuracy for individual downstream model 18 / 20: 0.9298245614035088\n",
      "Test accuracy for individual downstream model 19 / 20: 0.9210526315789473\n",
      "shape of 20 DGE y predictions:  (114,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 20, weight shape: 20\n",
      "weighted means:  [8.27655485e-02 4.41760273e-03 2.00422641e-01 9.99973421e-01\n",
      " 1.15411721e-02 9.65098924e-01 2.81629943e-02 9.97509497e-01\n",
      " 9.99729219e-01 1.38828114e-02 1.48027281e-01 9.97875346e-01\n",
      " 8.32150869e-01 9.98429159e-01 6.85633799e-01 1.75287292e-06\n",
      " 2.09943488e-04 9.99999420e-01 1.66281456e-04 4.94199506e-01\n",
      " 9.99885936e-01 7.19564955e-01 9.95845936e-01 9.99525706e-01\n",
      " 9.99996379e-01 5.52277774e-03 1.93931182e-04 6.16528793e-01\n",
      " 7.57505361e-04 9.54641515e-01 4.32027420e-02 9.95958895e-01\n",
      " 3.27085538e-02 9.98590444e-01 9.99910823e-01 9.99999641e-01\n",
      " 9.98929119e-01 1.90662704e-04 9.29404506e-01 9.99267904e-01\n",
      " 5.07725389e-02 9.99839138e-01 5.73603586e-01 9.53881919e-01\n",
      " 9.99984980e-01 8.80348775e-01 5.36924022e-01 9.17178895e-01\n",
      " 9.99891695e-01 9.99742139e-01 7.45438332e-02 8.74148397e-01\n",
      " 1.46959776e-06 5.92648813e-02 9.51415445e-01 9.99601181e-01\n",
      " 6.85394897e-01 9.23727839e-01 1.76164129e-02 9.12520363e-03\n",
      " 5.29085934e-03 9.88268343e-01 9.98766353e-01 9.16628868e-01\n",
      " 9.78432095e-01 9.96784034e-01 8.37031134e-01 6.02143478e-01\n",
      " 9.99683267e-01 9.99999881e-01 1.45294780e-01 9.57956705e-01\n",
      " 1.81917589e-01 8.79209323e-01 6.10985062e-01 9.99937910e-01\n",
      " 9.12370361e-01 9.99494911e-01 9.99999966e-01 3.36007873e-01\n",
      " 9.24008207e-02 9.76710791e-01 1.62397788e-02 9.37203826e-01\n",
      " 9.99982697e-01 9.99389019e-01 9.99510672e-01 2.58833488e-02\n",
      " 9.99997264e-01 9.75465849e-01 5.55364566e-06 9.14364925e-01\n",
      " 9.43139341e-01 4.36410398e-02 4.90729669e-04 1.48071448e-01\n",
      " 9.99997400e-01 9.99999842e-01 1.19089386e-01 5.86785876e-01\n",
      " 9.72684272e-01 9.69770547e-01 9.99780245e-01 9.36368424e-01\n",
      " 9.99935046e-01 7.55461550e-02 9.99974472e-01 9.96447149e-01\n",
      " 9.99999963e-01 9.83401634e-02 4.30435803e-03 8.95377186e-01\n",
      " 9.50107290e-01 9.99982763e-01]\n",
      "Test accuracy for individual downstream model 0 / 10: 0.9210526315789473\n",
      "Test accuracy for individual downstream model 1 / 10: 0.8508771929824561\n",
      "Test accuracy for individual downstream model 2 / 10: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 3 / 10: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 4 / 10: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 5 / 10: 0.9035087719298246\n",
      "Test accuracy for individual downstream model 6 / 10: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 7 / 10: 0.9649122807017544\n",
      "Test accuracy for individual downstream model 8 / 10: 0.8947368421052632\n",
      "Test accuracy for individual downstream model 9 / 10: 0.9298245614035088\n",
      "shape of 10 DGE y predictions:  (114,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 10, weight shape: 10\n",
      "weighted means:  [2.02019847e-02 1.51736148e-08 2.14990175e-01 9.99946219e-01\n",
      " 1.57009124e-02 9.72364376e-01 5.50838796e-02 9.99244322e-01\n",
      " 9.99448438e-01 2.82437851e-02 2.80296910e-02 9.96817728e-01\n",
      " 6.87720890e-01 9.97095129e-01 6.14341717e-01 2.16343702e-06\n",
      " 1.68158125e-04 9.99999300e-01 8.81627395e-05 4.92854049e-01\n",
      " 9.99768923e-01 7.09080111e-01 9.91671756e-01 9.99055003e-01\n",
      " 9.99993299e-01 1.12357248e-02 2.43803271e-05 6.68119964e-01\n",
      " 1.93922540e-05 9.15653661e-01 8.59153128e-02 9.91768318e-01\n",
      " 1.36913188e-02 9.97205773e-01 9.99918414e-01 9.99999350e-01\n",
      " 9.97822908e-01 4.70132847e-05 9.22395205e-01 9.98623401e-01\n",
      " 5.49035856e-04 9.99767675e-01 3.95713631e-01 9.65072544e-01\n",
      " 9.99969753e-01 8.67752016e-01 4.44968882e-01 8.66414719e-01\n",
      " 9.99788039e-01 9.99689976e-01 4.11660178e-03 8.90585390e-01\n",
      " 2.96630475e-10 7.51873626e-02 9.17153314e-01 9.99229932e-01\n",
      " 5.35972169e-01 8.55427970e-01 3.01005928e-03 9.11210794e-03\n",
      " 4.48195324e-05 9.97820605e-01 9.97594316e-01 9.87193461e-01\n",
      " 9.57714766e-01 9.93699929e-01 7.81499778e-01 5.53002035e-01\n",
      " 9.99359553e-01 9.99999760e-01 2.19283348e-01 9.34534837e-01\n",
      " 1.34270403e-01 8.69376627e-01 6.38611867e-01 9.99876308e-01\n",
      " 8.99432247e-01 9.98979985e-01 9.99999961e-01 1.96544394e-01\n",
      " 1.21364145e-01 9.57336567e-01 3.17574919e-02 8.76417407e-01\n",
      " 9.99965534e-01 9.99995741e-01 9.99283935e-01 2.13860367e-02\n",
      " 9.99994429e-01 9.68242260e-01 6.58904543e-06 9.95763759e-01\n",
      " 9.75779938e-01 8.86579926e-02 4.09839591e-05 1.18486744e-01\n",
      " 9.99997196e-01 9.99999966e-01 1.46444368e-01 5.37749090e-01\n",
      " 9.76702706e-01 9.99717700e-01 9.99585236e-01 8.95061782e-01\n",
      " 9.99867702e-01 3.01311748e-02 9.99999792e-01 9.93196517e-01\n",
      " 9.99999925e-01 4.01565863e-02 3.23692208e-03 8.95914119e-01\n",
      " 8.98749775e-01 9.99964925e-01]\n",
      "Test accuracy for individual downstream model 0 / 5: 0.9210526315789473\n",
      "Test accuracy for individual downstream model 1 / 5: 0.8508771929824561\n",
      "Test accuracy for individual downstream model 2 / 5: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 3 / 5: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 4 / 5: 0.9122807017543859\n",
      "shape of 5 DGE y predictions:  (114,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 5, weight shape: 5\n",
      "weighted means:  [3.75917467e-02 2.92606491e-09 8.55714199e-02 9.99980682e-01\n",
      " 2.63419179e-02 9.54119311e-01 4.12025656e-02 9.98698744e-01\n",
      " 9.98890490e-01 1.45353727e-05 3.88041857e-02 9.95567792e-01\n",
      " 6.08772983e-01 9.94778289e-01 4.66604979e-01 5.52204272e-08\n",
      " 5.50864944e-06 9.99999116e-01 1.56159107e-04 5.83471615e-01\n",
      " 9.99993747e-01 5.91437256e-01 9.83367100e-01 9.98170961e-01\n",
      " 9.99987058e-01 2.26609566e-02 1.89517579e-06 7.07953485e-01\n",
      " 5.02240171e-09 9.85263260e-01 6.59939301e-06 9.83379100e-01\n",
      " 7.01234634e-04 9.94338917e-01 9.99982438e-01 9.99999750e-01\n",
      " 9.95645579e-01 5.63766651e-05 8.48408454e-01 9.97214828e-01\n",
      " 3.12982478e-05 9.99990127e-01 4.88596849e-01 9.78201047e-01\n",
      " 9.99939815e-01 7.66227135e-01 4.31693165e-01 7.94395110e-01\n",
      " 9.99966225e-01 9.99374118e-01 8.26846440e-03 8.44172924e-01\n",
      " 1.07269866e-11 4.80586003e-02 8.67678281e-01 9.99777569e-01\n",
      " 3.61956733e-01 7.37751875e-01 1.10053028e-03 2.83882258e-04\n",
      " 2.96230558e-05 9.99870127e-01 9.95515501e-01 9.76894054e-01\n",
      " 9.24186063e-01 9.93229009e-01 7.94111133e-01 4.37322303e-01\n",
      " 9.98965512e-01 9.99999714e-01 1.58858448e-01 8.73486772e-01\n",
      " 1.76407667e-01 8.26535600e-01 5.72324022e-01 9.99750900e-01\n",
      " 8.00430372e-01 9.99730153e-01 9.99999967e-01 2.89007174e-01\n",
      " 2.16119988e-01 9.13621577e-01 1.19567491e-04 8.13471145e-01\n",
      " 9.99931054e-01 9.99996470e-01 9.99513870e-01 2.10724587e-02\n",
      " 9.99992334e-01 9.51891568e-01 4.59083684e-07 9.92835244e-01\n",
      " 9.50930501e-01 1.07405141e-05 2.17968361e-07 2.01075444e-01\n",
      " 9.99994433e-01 9.99999958e-01 5.74797559e-03 6.75604634e-01\n",
      " 9.53174059e-01 9.99448822e-01 9.99164623e-01 8.21676588e-01\n",
      " 9.99997436e-01 3.40684580e-04 9.99999917e-01 9.99646170e-01\n",
      " 9.99999847e-01 8.05254006e-02 5.45288019e-03 7.89121067e-01\n",
      " 7.99023691e-01 9.99928945e-01]\n",
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_concat_run0_0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "run:  1\n",
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__1.pkl\n",
      "Train model in aggregate\n",
      "Train model 2/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__2.pkl\n",
      "Train model in aggregate\n",
      "Train model 3/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__3.pkl\n",
      "Train model in aggregate\n",
      "Train model 4/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__4.pkl\n",
      "Train model in aggregate\n",
      "Train model 5/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__5.pkl\n",
      "Train model in aggregate\n",
      "Train model 6/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__6.pkl\n",
      "Train model in aggregate\n",
      "Train model 7/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__7.pkl\n",
      "Train model in aggregate\n",
      "Train model 8/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__8.pkl\n",
      "Train model in aggregate\n",
      "Train model 9/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__9.pkl\n",
      "Train model in aggregate\n",
      "Train model 10/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__10.pkl\n",
      "Train model in aggregate\n",
      "Train model 11/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__11.pkl\n",
      "Train model in aggregate\n",
      "Train model 12/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__12.pkl\n",
      "Train model in aggregate\n",
      "Train model 13/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__13.pkl\n",
      "Train model in aggregate\n",
      "Train model 14/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__14.pkl\n",
      "Train model in aggregate\n",
      "Train model 15/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__15.pkl\n",
      "Train model in aggregate\n",
      "Train model 16/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__16.pkl\n",
      "Train model in aggregate\n",
      "Train model 17/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__17.pkl\n",
      "Train model in aggregate\n",
      "Train model 18/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__18.pkl\n",
      "Train model in aggregate\n",
      "Train model 19/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_1__19.pkl\n",
      "Train model in aggregate\n",
      "Train model 20/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__1.pkl\n",
      "Train model in aggregate\n",
      "Train model 2/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__2.pkl\n",
      "Train model in aggregate\n",
      "Train model 3/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__3.pkl\n",
      "Train model in aggregate\n",
      "Train model 4/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__4.pkl\n",
      "Train model in aggregate\n",
      "Train model 5/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__5.pkl\n",
      "Train model in aggregate\n",
      "Train model 6/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__6.pkl\n",
      "Train model in aggregate\n",
      "Train model 7/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__7.pkl\n",
      "Train model in aggregate\n",
      "Train model 8/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__8.pkl\n",
      "Train model in aggregate\n",
      "Train model 9/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__9.pkl\n",
      "Train model in aggregate\n",
      "Train model 10/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__10.pkl\n",
      "Train model in aggregate\n",
      "Train model 11/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__11.pkl\n",
      "Train model in aggregate\n",
      "Train model 12/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__12.pkl\n",
      "Train model in aggregate\n",
      "Train model 13/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__13.pkl\n",
      "Train model in aggregate\n",
      "Train model 14/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__14.pkl\n",
      "Train model in aggregate\n",
      "Train model 15/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__15.pkl\n",
      "Train model in aggregate\n",
      "Train model 16/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__16.pkl\n",
      "Train model in aggregate\n",
      "Train model 17/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__17.pkl\n",
      "Train model in aggregate\n",
      "Train model 18/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__18.pkl\n",
      "Train model in aggregate\n",
      "Train model 19/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m1__19.pkl\n",
      "Train model in aggregate\n",
      "Train model 20/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Test accuracy for individual downstream model 0 / 20: 0.9210526315789473\n",
      "Test accuracy for individual downstream model 1 / 20: 0.8508771929824561\n",
      "Test accuracy for individual downstream model 2 / 20: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 3 / 20: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 4 / 20: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 5 / 20: 0.9035087719298246\n",
      "Test accuracy for individual downstream model 6 / 20: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 7 / 20: 0.9649122807017544\n",
      "Test accuracy for individual downstream model 8 / 20: 0.8947368421052632\n",
      "Test accuracy for individual downstream model 9 / 20: 0.9298245614035088\n",
      "Test accuracy for individual downstream model 10 / 20: 0.8596491228070176\n",
      "Test accuracy for individual downstream model 11 / 20: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 12 / 20: 0.9210526315789473\n",
      "Test accuracy for individual downstream model 13 / 20: 0.9035087719298246\n",
      "Test accuracy for individual downstream model 14 / 20: 0.9210526315789473\n",
      "Test accuracy for individual downstream model 15 / 20: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 16 / 20: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 17 / 20: 0.956140350877193\n",
      "Test accuracy for individual downstream model 18 / 20: 0.9298245614035088\n",
      "Test accuracy for individual downstream model 19 / 20: 0.9210526315789473\n",
      "shape of 20 DGE y predictions:  (114,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 20, weight shape: 20\n",
      "weighted means:  [8.27655485e-02 4.41760273e-03 2.00422641e-01 9.99973421e-01\n",
      " 1.15411721e-02 9.65098924e-01 2.81629943e-02 9.97509497e-01\n",
      " 9.99729219e-01 1.38828114e-02 1.48027281e-01 9.97875346e-01\n",
      " 8.32150869e-01 9.98429159e-01 6.85633799e-01 1.75287292e-06\n",
      " 2.09943488e-04 9.99999420e-01 1.66281456e-04 4.94199506e-01\n",
      " 9.99885936e-01 7.19564955e-01 9.95845936e-01 9.99525706e-01\n",
      " 9.99996379e-01 5.52277774e-03 1.93931182e-04 6.16528793e-01\n",
      " 7.57505361e-04 9.54641515e-01 4.32027420e-02 9.95958895e-01\n",
      " 3.27085538e-02 9.98590444e-01 9.99910823e-01 9.99999641e-01\n",
      " 9.98929119e-01 1.90662704e-04 9.29404506e-01 9.99267904e-01\n",
      " 5.07725389e-02 9.99839138e-01 5.73603586e-01 9.53881919e-01\n",
      " 9.99984980e-01 8.80348775e-01 5.36924022e-01 9.17178895e-01\n",
      " 9.99891695e-01 9.99742139e-01 7.45438332e-02 8.74148397e-01\n",
      " 1.46959776e-06 5.92648813e-02 9.51415445e-01 9.99601181e-01\n",
      " 6.85394897e-01 9.23727839e-01 1.76164129e-02 9.12520363e-03\n",
      " 5.29085934e-03 9.88268343e-01 9.98766353e-01 9.16628868e-01\n",
      " 9.78432095e-01 9.96784034e-01 8.37031134e-01 6.02143478e-01\n",
      " 9.99683267e-01 9.99999881e-01 1.45294780e-01 9.57956705e-01\n",
      " 1.81917589e-01 8.79209323e-01 6.10985062e-01 9.99937910e-01\n",
      " 9.12370361e-01 9.99494911e-01 9.99999966e-01 3.36007873e-01\n",
      " 9.24008207e-02 9.76710791e-01 1.62397788e-02 9.37203826e-01\n",
      " 9.99982697e-01 9.99389019e-01 9.99510672e-01 2.58833488e-02\n",
      " 9.99997264e-01 9.75465849e-01 5.55364566e-06 9.14364925e-01\n",
      " 9.43139341e-01 4.36410398e-02 4.90729669e-04 1.48071448e-01\n",
      " 9.99997400e-01 9.99999842e-01 1.19089386e-01 5.86785876e-01\n",
      " 9.72684272e-01 9.69770547e-01 9.99780245e-01 9.36368424e-01\n",
      " 9.99935046e-01 7.55461550e-02 9.99974472e-01 9.96447149e-01\n",
      " 9.99999963e-01 9.83401634e-02 4.30435803e-03 8.95377186e-01\n",
      " 9.50107290e-01 9.99982763e-01]\n",
      "Test accuracy for individual downstream model 0 / 10: 0.9210526315789473\n",
      "Test accuracy for individual downstream model 1 / 10: 0.8508771929824561\n",
      "Test accuracy for individual downstream model 2 / 10: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 3 / 10: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 4 / 10: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 5 / 10: 0.9035087719298246\n",
      "Test accuracy for individual downstream model 6 / 10: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 7 / 10: 0.9649122807017544\n",
      "Test accuracy for individual downstream model 8 / 10: 0.8947368421052632\n",
      "Test accuracy for individual downstream model 9 / 10: 0.9298245614035088\n",
      "shape of 10 DGE y predictions:  (114,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 10, weight shape: 10\n",
      "weighted means:  [2.02019847e-02 1.51736148e-08 2.14990175e-01 9.99946219e-01\n",
      " 1.57009124e-02 9.72364376e-01 5.50838796e-02 9.99244322e-01\n",
      " 9.99448438e-01 2.82437851e-02 2.80296910e-02 9.96817728e-01\n",
      " 6.87720890e-01 9.97095129e-01 6.14341717e-01 2.16343702e-06\n",
      " 1.68158125e-04 9.99999300e-01 8.81627395e-05 4.92854049e-01\n",
      " 9.99768923e-01 7.09080111e-01 9.91671756e-01 9.99055003e-01\n",
      " 9.99993299e-01 1.12357248e-02 2.43803271e-05 6.68119964e-01\n",
      " 1.93922540e-05 9.15653661e-01 8.59153128e-02 9.91768318e-01\n",
      " 1.36913188e-02 9.97205773e-01 9.99918414e-01 9.99999350e-01\n",
      " 9.97822908e-01 4.70132847e-05 9.22395205e-01 9.98623401e-01\n",
      " 5.49035856e-04 9.99767675e-01 3.95713631e-01 9.65072544e-01\n",
      " 9.99969753e-01 8.67752016e-01 4.44968882e-01 8.66414719e-01\n",
      " 9.99788039e-01 9.99689976e-01 4.11660178e-03 8.90585390e-01\n",
      " 2.96630475e-10 7.51873626e-02 9.17153314e-01 9.99229932e-01\n",
      " 5.35972169e-01 8.55427970e-01 3.01005928e-03 9.11210794e-03\n",
      " 4.48195324e-05 9.97820605e-01 9.97594316e-01 9.87193461e-01\n",
      " 9.57714766e-01 9.93699929e-01 7.81499778e-01 5.53002035e-01\n",
      " 9.99359553e-01 9.99999760e-01 2.19283348e-01 9.34534837e-01\n",
      " 1.34270403e-01 8.69376627e-01 6.38611867e-01 9.99876308e-01\n",
      " 8.99432247e-01 9.98979985e-01 9.99999961e-01 1.96544394e-01\n",
      " 1.21364145e-01 9.57336567e-01 3.17574919e-02 8.76417407e-01\n",
      " 9.99965534e-01 9.99995741e-01 9.99283935e-01 2.13860367e-02\n",
      " 9.99994429e-01 9.68242260e-01 6.58904543e-06 9.95763759e-01\n",
      " 9.75779938e-01 8.86579926e-02 4.09839591e-05 1.18486744e-01\n",
      " 9.99997196e-01 9.99999966e-01 1.46444368e-01 5.37749090e-01\n",
      " 9.76702706e-01 9.99717700e-01 9.99585236e-01 8.95061782e-01\n",
      " 9.99867702e-01 3.01311748e-02 9.99999792e-01 9.93196517e-01\n",
      " 9.99999925e-01 4.01565863e-02 3.23692208e-03 8.95914119e-01\n",
      " 8.98749775e-01 9.99964925e-01]\n",
      "Test accuracy for individual downstream model 0 / 5: 0.9210526315789473\n",
      "Test accuracy for individual downstream model 1 / 5: 0.8508771929824561\n",
      "Test accuracy for individual downstream model 2 / 5: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 3 / 5: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 4 / 5: 0.9122807017543859\n",
      "shape of 5 DGE y predictions:  (114,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 5, weight shape: 5\n",
      "weighted means:  [3.75917467e-02 2.92606491e-09 8.55714199e-02 9.99980682e-01\n",
      " 2.63419179e-02 9.54119311e-01 4.12025656e-02 9.98698744e-01\n",
      " 9.98890490e-01 1.45353727e-05 3.88041857e-02 9.95567792e-01\n",
      " 6.08772983e-01 9.94778289e-01 4.66604979e-01 5.52204272e-08\n",
      " 5.50864944e-06 9.99999116e-01 1.56159107e-04 5.83471615e-01\n",
      " 9.99993747e-01 5.91437256e-01 9.83367100e-01 9.98170961e-01\n",
      " 9.99987058e-01 2.26609566e-02 1.89517579e-06 7.07953485e-01\n",
      " 5.02240171e-09 9.85263260e-01 6.59939301e-06 9.83379100e-01\n",
      " 7.01234634e-04 9.94338917e-01 9.99982438e-01 9.99999750e-01\n",
      " 9.95645579e-01 5.63766651e-05 8.48408454e-01 9.97214828e-01\n",
      " 3.12982478e-05 9.99990127e-01 4.88596849e-01 9.78201047e-01\n",
      " 9.99939815e-01 7.66227135e-01 4.31693165e-01 7.94395110e-01\n",
      " 9.99966225e-01 9.99374118e-01 8.26846440e-03 8.44172924e-01\n",
      " 1.07269866e-11 4.80586003e-02 8.67678281e-01 9.99777569e-01\n",
      " 3.61956733e-01 7.37751875e-01 1.10053028e-03 2.83882258e-04\n",
      " 2.96230558e-05 9.99870127e-01 9.95515501e-01 9.76894054e-01\n",
      " 9.24186063e-01 9.93229009e-01 7.94111133e-01 4.37322303e-01\n",
      " 9.98965512e-01 9.99999714e-01 1.58858448e-01 8.73486772e-01\n",
      " 1.76407667e-01 8.26535600e-01 5.72324022e-01 9.99750900e-01\n",
      " 8.00430372e-01 9.99730153e-01 9.99999967e-01 2.89007174e-01\n",
      " 2.16119988e-01 9.13621577e-01 1.19567491e-04 8.13471145e-01\n",
      " 9.99931054e-01 9.99996470e-01 9.99513870e-01 2.10724587e-02\n",
      " 9.99992334e-01 9.51891568e-01 4.59083684e-07 9.92835244e-01\n",
      " 9.50930501e-01 1.07405141e-05 2.17968361e-07 2.01075444e-01\n",
      " 9.99994433e-01 9.99999958e-01 5.74797559e-03 6.75604634e-01\n",
      " 9.53174059e-01 9.99448822e-01 9.99164623e-01 8.21676588e-01\n",
      " 9.99997436e-01 3.40684580e-04 9.99999917e-01 9.99646170e-01\n",
      " 9.99999847e-01 8.05254006e-02 5.45288019e-03 7.89121067e-01\n",
      " 7.99023691e-01 9.99928945e-01]\n",
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_concat_run1_0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "run:  2\n",
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__1.pkl\n",
      "Train model in aggregate\n",
      "Train model 2/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__2.pkl\n",
      "Train model in aggregate\n",
      "Train model 3/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__3.pkl\n",
      "Train model in aggregate\n",
      "Train model 4/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__4.pkl\n",
      "Train model in aggregate\n",
      "Train model 5/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__5.pkl\n",
      "Train model in aggregate\n",
      "Train model 6/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__6.pkl\n",
      "Train model in aggregate\n",
      "Train model 7/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__7.pkl\n",
      "Train model in aggregate\n",
      "Train model 8/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__8.pkl\n",
      "Train model in aggregate\n",
      "Train model 9/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__9.pkl\n",
      "Train model in aggregate\n",
      "Train model 10/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__10.pkl\n",
      "Train model in aggregate\n",
      "Train model 11/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__11.pkl\n",
      "Train model in aggregate\n",
      "Train model 12/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__12.pkl\n",
      "Train model in aggregate\n",
      "Train model 13/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__13.pkl\n",
      "Train model in aggregate\n",
      "Train model 14/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__14.pkl\n",
      "Train model in aggregate\n",
      "Train model 15/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__15.pkl\n",
      "Train model in aggregate\n",
      "Train model 16/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__16.pkl\n",
      "Train model in aggregate\n",
      "Train model 17/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__17.pkl\n",
      "Train model in aggregate\n",
      "Train model 18/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__18.pkl\n",
      "Train model in aggregate\n",
      "Train model 19/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_oracle_run_2__19.pkl\n",
      "Train model in aggregate\n",
      "Train model 20/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__0.pkl\n",
      "loading existing model...\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__1.pkl\n",
      "Train model in aggregate\n",
      "Train model 2/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__2.pkl\n",
      "Train model in aggregate\n",
      "Train model 3/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__3.pkl\n",
      "Train model in aggregate\n",
      "Train model 4/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__4.pkl\n",
      "Train model in aggregate\n",
      "Train model 5/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__5.pkl\n",
      "Train model in aggregate\n",
      "Train model 6/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__6.pkl\n",
      "Train model in aggregate\n",
      "Train model 7/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__7.pkl\n",
      "Train model in aggregate\n",
      "Train model 8/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__8.pkl\n",
      "Train model in aggregate\n",
      "Train model 9/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__9.pkl\n",
      "Train model in aggregate\n",
      "Train model 10/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__10.pkl\n",
      "Train model in aggregate\n",
      "Train model 11/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__11.pkl\n",
      "Train model in aggregate\n",
      "Train model 12/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__12.pkl\n",
      "Train model in aggregate\n",
      "Train model 13/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__13.pkl\n",
      "Train model in aggregate\n",
      "Train model 14/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__14.pkl\n",
      "Train model in aggregate\n",
      "Train model 15/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__15.pkl\n",
      "Train model in aggregate\n",
      "Train model 16/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__16.pkl\n",
      "Train model in aggregate\n",
      "Train model 17/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__17.pkl\n",
      "Train model in aggregate\n",
      "Train model 18/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__18.pkl\n",
      "Train model in aggregate\n",
      "Train model 19/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_naive_m2__19.pkl\n",
      "Train model in aggregate\n",
      "Train model 20/20\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "Test accuracy for individual downstream model 0 / 20: 0.9210526315789473\n",
      "Test accuracy for individual downstream model 1 / 20: 0.8508771929824561\n",
      "Test accuracy for individual downstream model 2 / 20: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 3 / 20: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 4 / 20: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 5 / 20: 0.9035087719298246\n",
      "Test accuracy for individual downstream model 6 / 20: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 7 / 20: 0.9649122807017544\n",
      "Test accuracy for individual downstream model 8 / 20: 0.8947368421052632\n",
      "Test accuracy for individual downstream model 9 / 20: 0.9298245614035088\n",
      "Test accuracy for individual downstream model 10 / 20: 0.8596491228070176\n",
      "Test accuracy for individual downstream model 11 / 20: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 12 / 20: 0.9210526315789473\n",
      "Test accuracy for individual downstream model 13 / 20: 0.9035087719298246\n",
      "Test accuracy for individual downstream model 14 / 20: 0.9210526315789473\n",
      "Test accuracy for individual downstream model 15 / 20: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 16 / 20: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 17 / 20: 0.956140350877193\n",
      "Test accuracy for individual downstream model 18 / 20: 0.9298245614035088\n",
      "Test accuracy for individual downstream model 19 / 20: 0.9210526315789473\n",
      "shape of 20 DGE y predictions:  (114,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 20, weight shape: 20\n",
      "weighted means:  [8.27655485e-02 4.41760273e-03 2.00422641e-01 9.99973421e-01\n",
      " 1.15411721e-02 9.65098924e-01 2.81629943e-02 9.97509497e-01\n",
      " 9.99729219e-01 1.38828114e-02 1.48027281e-01 9.97875346e-01\n",
      " 8.32150869e-01 9.98429159e-01 6.85633799e-01 1.75287292e-06\n",
      " 2.09943488e-04 9.99999420e-01 1.66281456e-04 4.94199506e-01\n",
      " 9.99885936e-01 7.19564955e-01 9.95845936e-01 9.99525706e-01\n",
      " 9.99996379e-01 5.52277774e-03 1.93931182e-04 6.16528793e-01\n",
      " 7.57505361e-04 9.54641515e-01 4.32027420e-02 9.95958895e-01\n",
      " 3.27085538e-02 9.98590444e-01 9.99910823e-01 9.99999641e-01\n",
      " 9.98929119e-01 1.90662704e-04 9.29404506e-01 9.99267904e-01\n",
      " 5.07725389e-02 9.99839138e-01 5.73603586e-01 9.53881919e-01\n",
      " 9.99984980e-01 8.80348775e-01 5.36924022e-01 9.17178895e-01\n",
      " 9.99891695e-01 9.99742139e-01 7.45438332e-02 8.74148397e-01\n",
      " 1.46959776e-06 5.92648813e-02 9.51415445e-01 9.99601181e-01\n",
      " 6.85394897e-01 9.23727839e-01 1.76164129e-02 9.12520363e-03\n",
      " 5.29085934e-03 9.88268343e-01 9.98766353e-01 9.16628868e-01\n",
      " 9.78432095e-01 9.96784034e-01 8.37031134e-01 6.02143478e-01\n",
      " 9.99683267e-01 9.99999881e-01 1.45294780e-01 9.57956705e-01\n",
      " 1.81917589e-01 8.79209323e-01 6.10985062e-01 9.99937910e-01\n",
      " 9.12370361e-01 9.99494911e-01 9.99999966e-01 3.36007873e-01\n",
      " 9.24008207e-02 9.76710791e-01 1.62397788e-02 9.37203826e-01\n",
      " 9.99982697e-01 9.99389019e-01 9.99510672e-01 2.58833488e-02\n",
      " 9.99997264e-01 9.75465849e-01 5.55364566e-06 9.14364925e-01\n",
      " 9.43139341e-01 4.36410398e-02 4.90729669e-04 1.48071448e-01\n",
      " 9.99997400e-01 9.99999842e-01 1.19089386e-01 5.86785876e-01\n",
      " 9.72684272e-01 9.69770547e-01 9.99780245e-01 9.36368424e-01\n",
      " 9.99935046e-01 7.55461550e-02 9.99974472e-01 9.96447149e-01\n",
      " 9.99999963e-01 9.83401634e-02 4.30435803e-03 8.95377186e-01\n",
      " 9.50107290e-01 9.99982763e-01]\n",
      "Test accuracy for individual downstream model 0 / 10: 0.9210526315789473\n",
      "Test accuracy for individual downstream model 1 / 10: 0.8508771929824561\n",
      "Test accuracy for individual downstream model 2 / 10: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 3 / 10: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 4 / 10: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 5 / 10: 0.9035087719298246\n",
      "Test accuracy for individual downstream model 6 / 10: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 7 / 10: 0.9649122807017544\n",
      "Test accuracy for individual downstream model 8 / 10: 0.8947368421052632\n",
      "Test accuracy for individual downstream model 9 / 10: 0.9298245614035088\n",
      "shape of 10 DGE y predictions:  (114,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 10, weight shape: 10\n",
      "weighted means:  [2.02019847e-02 1.51736148e-08 2.14990175e-01 9.99946219e-01\n",
      " 1.57009124e-02 9.72364376e-01 5.50838796e-02 9.99244322e-01\n",
      " 9.99448438e-01 2.82437851e-02 2.80296910e-02 9.96817728e-01\n",
      " 6.87720890e-01 9.97095129e-01 6.14341717e-01 2.16343702e-06\n",
      " 1.68158125e-04 9.99999300e-01 8.81627395e-05 4.92854049e-01\n",
      " 9.99768923e-01 7.09080111e-01 9.91671756e-01 9.99055003e-01\n",
      " 9.99993299e-01 1.12357248e-02 2.43803271e-05 6.68119964e-01\n",
      " 1.93922540e-05 9.15653661e-01 8.59153128e-02 9.91768318e-01\n",
      " 1.36913188e-02 9.97205773e-01 9.99918414e-01 9.99999350e-01\n",
      " 9.97822908e-01 4.70132847e-05 9.22395205e-01 9.98623401e-01\n",
      " 5.49035856e-04 9.99767675e-01 3.95713631e-01 9.65072544e-01\n",
      " 9.99969753e-01 8.67752016e-01 4.44968882e-01 8.66414719e-01\n",
      " 9.99788039e-01 9.99689976e-01 4.11660178e-03 8.90585390e-01\n",
      " 2.96630475e-10 7.51873626e-02 9.17153314e-01 9.99229932e-01\n",
      " 5.35972169e-01 8.55427970e-01 3.01005928e-03 9.11210794e-03\n",
      " 4.48195324e-05 9.97820605e-01 9.97594316e-01 9.87193461e-01\n",
      " 9.57714766e-01 9.93699929e-01 7.81499778e-01 5.53002035e-01\n",
      " 9.99359553e-01 9.99999760e-01 2.19283348e-01 9.34534837e-01\n",
      " 1.34270403e-01 8.69376627e-01 6.38611867e-01 9.99876308e-01\n",
      " 8.99432247e-01 9.98979985e-01 9.99999961e-01 1.96544394e-01\n",
      " 1.21364145e-01 9.57336567e-01 3.17574919e-02 8.76417407e-01\n",
      " 9.99965534e-01 9.99995741e-01 9.99283935e-01 2.13860367e-02\n",
      " 9.99994429e-01 9.68242260e-01 6.58904543e-06 9.95763759e-01\n",
      " 9.75779938e-01 8.86579926e-02 4.09839591e-05 1.18486744e-01\n",
      " 9.99997196e-01 9.99999966e-01 1.46444368e-01 5.37749090e-01\n",
      " 9.76702706e-01 9.99717700e-01 9.99585236e-01 8.95061782e-01\n",
      " 9.99867702e-01 3.01311748e-02 9.99999792e-01 9.93196517e-01\n",
      " 9.99999925e-01 4.01565863e-02 3.23692208e-03 8.95914119e-01\n",
      " 8.98749775e-01 9.99964925e-01]\n",
      "Test accuracy for individual downstream model 0 / 5: 0.9210526315789473\n",
      "Test accuracy for individual downstream model 1 / 5: 0.8508771929824561\n",
      "Test accuracy for individual downstream model 2 / 5: 0.9385964912280702\n",
      "Test accuracy for individual downstream model 3 / 5: 0.9122807017543859\n",
      "Test accuracy for individual downstream model 4 / 5: 0.9122807017543859\n",
      "shape of 5 DGE y predictions:  (114,)\n",
      "model/estimator weights shape: 20\n",
      "calculated weighted means/stds with numpy\n",
      "A shape: 5, weight shape: 5\n",
      "weighted means:  [3.75917467e-02 2.92606491e-09 8.55714199e-02 9.99980682e-01\n",
      " 2.63419179e-02 9.54119311e-01 4.12025656e-02 9.98698744e-01\n",
      " 9.98890490e-01 1.45353727e-05 3.88041857e-02 9.95567792e-01\n",
      " 6.08772983e-01 9.94778289e-01 4.66604979e-01 5.52204272e-08\n",
      " 5.50864944e-06 9.99999116e-01 1.56159107e-04 5.83471615e-01\n",
      " 9.99993747e-01 5.91437256e-01 9.83367100e-01 9.98170961e-01\n",
      " 9.99987058e-01 2.26609566e-02 1.89517579e-06 7.07953485e-01\n",
      " 5.02240171e-09 9.85263260e-01 6.59939301e-06 9.83379100e-01\n",
      " 7.01234634e-04 9.94338917e-01 9.99982438e-01 9.99999750e-01\n",
      " 9.95645579e-01 5.63766651e-05 8.48408454e-01 9.97214828e-01\n",
      " 3.12982478e-05 9.99990127e-01 4.88596849e-01 9.78201047e-01\n",
      " 9.99939815e-01 7.66227135e-01 4.31693165e-01 7.94395110e-01\n",
      " 9.99966225e-01 9.99374118e-01 8.26846440e-03 8.44172924e-01\n",
      " 1.07269866e-11 4.80586003e-02 8.67678281e-01 9.99777569e-01\n",
      " 3.61956733e-01 7.37751875e-01 1.10053028e-03 2.83882258e-04\n",
      " 2.96230558e-05 9.99870127e-01 9.95515501e-01 9.76894054e-01\n",
      " 9.24186063e-01 9.93229009e-01 7.94111133e-01 4.37322303e-01\n",
      " 9.98965512e-01 9.99999714e-01 1.58858448e-01 8.73486772e-01\n",
      " 1.76407667e-01 8.26535600e-01 5.72324022e-01 9.99750900e-01\n",
      " 8.00430372e-01 9.99730153e-01 9.99999967e-01 2.89007174e-01\n",
      " 2.16119988e-01 9.13621577e-01 1.19567491e-04 8.13471145e-01\n",
      " 9.99931054e-01 9.99996470e-01 9.99513870e-01 2.10724587e-02\n",
      " 9.99992334e-01 9.51891568e-01 4.59083684e-07 9.92835244e-01\n",
      " 9.50930501e-01 1.07405141e-05 2.17968361e-07 2.01075444e-01\n",
      " 9.99994433e-01 9.99999958e-01 5.74797559e-03 6.75604634e-01\n",
      " 9.53174059e-01 9.99448822e-01 9.99164623e-01 8.21676588e-01\n",
      " 9.99997436e-01 3.40684580e-04 9.99999917e-01 9.99646170e-01\n",
      " 9.99999847e-01 8.05254006e-02 5.45288019e-03 7.89121067e-01\n",
      " 7.99023691e-01 9.99928945e-01]\n",
      "fileroot in aggregate:  workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp\n",
      "task function name:  supervised_task\n",
      "task type:  deepish_mlp\n",
      "Saving model as workspace/breast_cancer/ctgan/nmax_2000_nsyn_2000_SAMME_observe/supervised_task_deepish_mlp_concat_run2_0.pkl\n",
      "Train model in aggregate\n",
      "Train model 1/1\n",
      "supervised task:  classification\n",
      "model type:  deepish_mlp\n",
      "shape of pred in supervised task:  (114,)\n",
      "printing weighted avg means to latex:\n",
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "{} &       AUC &       Acc &        F1 &  Precision &    Recall &       NLL &     Brier \\\\\n",
      "\\midrule\n",
      "Oracle            &  0.992945 &  0.956140 &  0.965517 &   0.958904 &  0.972222 &  0.151943 &  0.033201 \\\\\n",
      "Naive (S)         &  0.972884 &  0.923977 &  0.940819 &   0.924168 &  0.958333 &  0.380287 &  0.066452 \\\\\n",
      "Naive (E)         &  0.982253 &  0.921053 &  0.937642 &   0.935559 &  0.939815 &  0.217960 &  0.054265 \\\\\n",
      "DGE\\$\\_\\{5\\}\\$         &  0.983135 &  0.912281 &  0.930556 &   0.930556 &  0.930556 &  0.147125 &  0.046217 \\\\\n",
      "DGE\\$\\_\\{10\\}\\$        &  0.986111 &  0.947368 &  0.958904 &   0.945946 &  0.972222 &  0.134878 &  0.039572 \\\\\n",
      "DGE\\$\\_\\{20\\}\\$        &  0.984458 &  0.964912 &  0.972973 &   0.947368 &  1.000000 &  0.137758 &  0.036921 \\\\\n",
      "DGE\\$\\_20\\$ (concat) &  0.970459 &  0.918129 &  0.933939 &   0.948147 &  0.921296 &  0.544184 &  0.072310 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "printing weighted stds to latex:\n",
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "{} &       AUC &           Acc &            F1 &     Precision &        Recall &       NLL &     Brier \\\\\n",
      "\\midrule\n",
      "Oracle            &  0.000412 &  0.000000e+00 &  0.000000e+00 &  0.000000e+00 &  0.000000e+00 &  0.004358 &  0.000951 \\\\\n",
      "Naive (S)         &  0.002576 &  1.094052e-02 &  9.017098e-03 &  5.347273e-03 &  1.964186e-02 &  0.052850 &  0.008975 \\\\\n",
      "Naive (E)         &  0.001535 &  0.000000e+00 &  4.092250e-04 &  5.729980e-03 &  6.547285e-03 &  0.007487 &  0.002045 \\\\\n",
      "DGE\\$\\_\\{5\\}\\$         &  0.000000 &  1.110223e-16 &  1.110223e-16 &  1.110223e-16 &  1.110223e-16 &  0.000000 &  0.000000 \\\\\n",
      "DGE\\$\\_\\{10\\}\\$        &  0.000000 &  0.000000e+00 &  1.110223e-16 &  0.000000e+00 &  0.000000e+00 &  0.000000 &  0.000000 \\\\\n",
      "DGE\\$\\_\\{20\\}\\$        &  0.000000 &  0.000000e+00 &  1.110223e-16 &  0.000000e+00 &  0.000000e+00 &  0.000000 &  0.000000 \\\\\n",
      "DGE\\$\\_20\\$ (concat) &  0.010161 &  1.490941e-02 &  1.341504e-02 &  1.047796e-02 &  3.645374e-02 &  0.125298 &  0.016751 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "size of means:  (7, 7)\n",
      "mean elements:                          AUC       Acc        F1  Precision    Recall  \\\n",
      "Oracle             0.992945  0.956140  0.965517   0.958904  0.972222   \n",
      "Naive (S)          0.972884  0.923977  0.940819   0.924168  0.958333   \n",
      "Naive (E)          0.982253  0.921053  0.937642   0.935559  0.939815   \n",
      "DGE$_{5}$          0.983135  0.912281  0.930556   0.930556  0.930556   \n",
      "DGE$_{10}$         0.986111  0.947368  0.958904   0.945946  0.972222   \n",
      "DGE$_{20}$         0.984458  0.964912  0.972973   0.947368  1.000000   \n",
      "DGE$_20$ (concat)  0.970459  0.918129  0.933939   0.948147  0.921296   \n",
      "\n",
      "                        NLL     Brier  \n",
      "Oracle             0.151943  0.033201  \n",
      "Naive (S)          0.380287  0.066452  \n",
      "Naive (E)          0.217960  0.054265  \n",
      "DGE$_{5}$          0.147125  0.046217  \n",
      "DGE$_{10}$         0.134878  0.039572  \n",
      "DGE$_{20}$         0.137758  0.036921  \n",
      "DGE$_20$ (concat)  0.544184  0.072310  \n",
      "Time it took to run the experiment:  35068.099162340164\n"
     ]
    }
   ],
   "source": [
    "# Run boosting experiment\n",
    "from DGE_experiments import predictive_experiment, predictive_experiment_stacking, boosting_DGE\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "all_means = {}\n",
    "all_stds = {}\n",
    "\n",
    "#datasets = ['moons', 'circles', 'breast_cancer', 'adult', 'covid']\n",
    "datasets = ['covid', 'breast_cancer']\n",
    "test_only_dataset = ['adult']\n",
    "#model_names = ['ctgan']\n",
    "#num_runs=1\n",
    "#model_type = ['deepish_mlp', 'largest_mlp', 'rf', 'svm', 'xgboost', 'knn']\n",
    "model_type = 'deepish_mlp'\n",
    "#mixed_models = True\n",
    "#meta_model='lr'\n",
    "boosting = \"SAMME\"\n",
    "\n",
    "print(\"Model to run: \", model_name)\n",
    "print(\"Downstream classifier model type: \", model_type)\n",
    "print(\"boosting method: \", boosting)\n",
    "print(\"n_models: \", n_models)\n",
    "print(\"num_runs: \", num_runs)\n",
    "print(\"datasets: \", datasets)\n",
    "print(\"model string: \", model_name)\n",
    "print(\"verbose: \", verbose)\n",
    "\n",
    "start_time = time.time()\n",
    "for dataset in datasets:\n",
    "    workspace_folder, results_folder = get_folder_names(\n",
    "        dataset, model_name, max_n=max_n, nsyn=nsyn)\n",
    "    # For toy runs\n",
    "    workspace_folder = f\"{workspace_folder}_{boosting}_observe\"\n",
    "    results_folder = f\"{results_folder}_{boosting}_observe\"\n",
    "\n",
    "    print(f'Dataset {dataset}\\n')\n",
    "    print(\"workspace_folder: \", workspace_folder)\n",
    "    print(\"results_folder: \", results_folder)\n",
    "\n",
    "    means, stds, _ = boosting_DGE(dataset, model_name, num_runs=num_runs, num_iter=n_models, boosting=boosting, p_train=0.8, \n",
    "                                  max_n=max_n, nsyn=nsyn, reduce_to=20000, task_type=model_type, workspace_folder=workspace_folder, \n",
    "                                  save=save, load=load, verbose=verbose)\n",
    "    print(\"printing weighted avg means to latex:\")\n",
    "    print(means.to_latex())\n",
    "    print(\"printing weighted stds to latex:\")\n",
    "    print(stds.to_latex())\n",
    "\n",
    "    all_means[dataset] = means\n",
    "    all_stds[dataset] = stds\n",
    "\n",
    "    print(\"size of means: \", means.shape)\n",
    "    print(\"mean elements: \", means)\n",
    "\n",
    "end_time = time.time()\n",
    "time_elapsed = end_time - start_time\n",
    "print(\"Time it took to run the experiment: \", time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f972b897-a543-4d8c-9bd9-6cd7a535f5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "{} &  Breast Cancer &       COVID-19 &   Mean \\\\\n",
      "\\midrule\n",
      "Oracle            &    0.993 ± 0.0 &  0.928 ± 0.001 &  0.961 \\\\\n",
      "Naive (S)         &  0.973 ± 0.003 &     0.82 ± 0.0 &  0.897 \\\\\n",
      "Naive (E)         &  0.982 ± 0.002 &  0.861 ± 0.002 &  0.922 \\\\\n",
      "DGE\\$\\_\\{5\\}\\$         &    0.983 ± 0.0 &    0.915 ± 0.0 &  0.949 \\\\\n",
      "DGE\\$\\_\\{10\\}\\$        &    0.986 ± 0.0 &    0.933 ± 0.0 &   0.96 \\\\\n",
      "DGE\\$\\_\\{20\\}\\$        &    0.984 ± 0.0 &    0.939 ± 0.0 &  0.961 \\\\\n",
      "DGE\\$\\_20\\$ (concat) &    0.97 ± 0.01 &  0.872 ± 0.013 &  0.921 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "# Print results, aggregated over different datasets\n",
    "means_consolidated = metric_different_datasets(all_means, to_print=False)\n",
    "if num_runs>1:\n",
    "    stds_consolidated = metric_different_datasets(all_stds, to_print=False)\n",
    "    stds_consolidated.drop(columns=['Mean'], inplace=True)\n",
    "    print(add_std(means_consolidated, stds_consolidated).to_latex())\n",
    "else:\n",
    "    print(means_consolidated.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3920ed1f-7197-40f2-be26-8088b32d86af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
